{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-29T14:48:28.140018Z",
     "iopub.status.busy": "2021-08-29T14:48:28.138885Z",
     "iopub.status.idle": "2021-08-29T14:48:57.827252Z",
     "shell.execute_reply": "2021-08-29T14:48:57.827756Z",
     "shell.execute_reply.started": "2021-08-29T11:59:44.302366Z"
    },
    "papermill": {
     "duration": 29.704225,
     "end_time": "2021-08-29T14:48:57.828063",
     "exception": false,
     "start_time": "2021-08-29T14:48:28.123838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset-sat-on/FinaldatasetN.csv\n",
      "/kaggle/input/corrected-online-det/FinaldatasetN2.csv\n",
      "/kaggle/input/corrected-online-det/FinaldatasetN.csv\n",
      "improt time 25.788908004760742\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import os\n",
    "\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    " #   for filename in filenames:\n",
    "  #      print(os.path.join(dirname, filename))\n",
    "a=time.time()\n",
    "path0 ='../'\n",
    "df = pd.read_csv(path0+\"FinaldatasetN1.csv\")\n",
    "print('improt time '+str(time.time()-a))\n",
    "\n",
    "a=time.time()\n",
    "df=df[['channel','Next_Current_diff','Next_Pre_diff','size','snir','throughput','packet_type','SNext_Current_diff','SNext_Pre_diff','Flow Bytes_s','Flow Packets_s','meanT_b_2P','minT_b_2P','maxT_b_2P','label']]     \n",
    "\n",
    "\n",
    "\n",
    "df_Normal=df[0:354961].copy()\n",
    "\n",
    "df_UDP1=df[354961:763730].copy()\n",
    "\n",
    "df_UDP2=df[763730:1573000].copy()\n",
    "\n",
    "df_jam1=df[1573000:1696992].copy()\n",
    "df_jam2=df[1696992:2714727].copy()\n",
    "\n",
    "df_pluies=df[2714727:-1].copy()\n",
    "\n",
    "del(df)\n",
    "\n",
    "X=df_Normal.drop(columns = ['label']).copy()\n",
    "y=df_Normal[['label']].copy()\n",
    "#print(y.columns)\n",
    "X1=df_UDP1.drop(columns = ['label']).copy()\n",
    "y1=df_UDP1[['label']].copy()\n",
    "X2=df_UDP2.drop(columns = ['label']).copy()\n",
    "y2=df_UDP2[['label']].copy()\n",
    "X3=df_jam1.drop(columns = ['label']).copy()\n",
    "y3=df_jam1[['label']].copy()\n",
    "X4=df_jam2.drop(columns = ['label']).copy()\n",
    "y4=df_jam2[['label']].copy()\n",
    "X5=df_pluies.drop(columns = ['label']).copy()\n",
    "y5=df_pluies[['label']].copy()\n",
    "\n",
    "train=0.7\n",
    "#train=0.01\n",
    "\n",
    "del(df_Normal)\n",
    "del(df_UDP1)\n",
    "del(df_UDP2)\n",
    "del(df_jam1)\n",
    "del(df_jam2)\n",
    "del(df_pluies)\n",
    "\n",
    "\n",
    "xcol=X.columns\n",
    "ycol=y.columns\n",
    "\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=train,shuffle=False)\n",
    "X_train1, X_rem1, y_train1, y_rem1 = train_test_split(X1,y1, train_size=train,shuffle=False)\n",
    "X_train2, X_rem2, y_train2, y_rem2 = train_test_split(X2,y2, train_size=train,shuffle=False)\n",
    "X_train3, X_rem3, y_train3, y_rem3 = train_test_split(X3,y3, train_size=train,shuffle=False)\n",
    "X_train4, X_rem4, y_train4, y_rem4 = train_test_split(X4,y4, train_size=train,shuffle=False)\n",
    "X_train5, X_rem5, y_train5, y_rem5 = train_test_split(X5,y5, train_size=train,shuffle=False)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.57,shuffle=False)\n",
    "X_valid1, X_test1, y_valid1, y_test1 = train_test_split(X_rem1,y_rem1, test_size=0.57,shuffle=False)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_rem2,y_rem2, test_size=0.57,shuffle=False)\n",
    "X_valid3, X_test3, y_valid3, y_test3 = train_test_split(X_rem3,y_rem3, test_size=0.57,shuffle=False)\n",
    "X_valid4, X_test4, y_valid4, y_test4 = train_test_split(X_rem4,y_rem4, test_size=0.57,shuffle=False)\n",
    "X_valid5, X_test5, y_valid5, y_test5 = train_test_split(X_rem5,y_rem5, test_size=0.57,shuffle=False)\n",
    "\n",
    "\n",
    "X_train=np.concatenate((X_train, X_train1, X_train2,X_train3, X_train4,X_train5))\n",
    "X_valid=np.concatenate((X_valid, X_valid1, X_valid2,X_valid3, X_valid4,X_valid5))\n",
    "X_test=np.concatenate((X_test, X_test1, X_test2,X_test3, X_test4,X_test5))\n",
    "\n",
    "y_train=np.concatenate((y_train, y_train1, y_train2,y_train3, y_train4,y_train5))\n",
    "y_valid=np.concatenate((y_valid, y_valid1, y_valid2,y_valid3, y_valid4,y_valid5))\n",
    "y_test=np.concatenate((y_test, y_test1, y_test2,y_test3, y_test4,y_test5))\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns= xcol)\n",
    "X_valid = pd.DataFrame(X_valid, columns= xcol)\n",
    "X_test = pd.DataFrame(X_test, columns= xcol)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= ycol)\n",
    "y_valid = pd.DataFrame(y_valid, columns= ycol)\n",
    "y_test = pd.DataFrame(y_test, columns= ycol)\n",
    "\n",
    "#########333\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T14:48:57.854549Z",
     "iopub.status.busy": "2021-08-29T14:48:57.853639Z",
     "iopub.status.idle": "2021-08-29T14:48:57.861669Z",
     "shell.execute_reply": "2021-08-29T14:48:57.862140Z",
     "shell.execute_reply.started": "2021-08-29T12:00:02.53539Z"
    },
    "papermill": {
     "duration": 0.022611,
     "end_time": "2021-08-29T14:48:57.862320",
     "exception": false,
     "start_time": "2021-08-29T14:48:57.839709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b5eb607897a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(X_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train22\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train222\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#print(X_train)\n",
    "y_train2=y_train.to_numpy()\n",
    "y_train22=y_valid.to_numpy()\n",
    "y_train222=y_test.to_numpy()\n",
    "print(y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T14:48:57.944451Z",
     "iopub.status.busy": "2021-08-29T14:48:57.898916Z",
     "iopub.status.idle": "2021-08-29T14:49:25.252331Z",
     "shell.execute_reply": "2021-08-29T14:49:25.297334Z",
     "shell.execute_reply.started": "2021-08-29T12:00:02.549217Z"
    },
    "papermill": {
     "duration": 27.423736,
     "end_time": "2021-08-29T14:49:25.297557",
     "exception": false,
     "start_time": "2021-08-29T14:48:57.873821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2381331\n",
      "-------------------------\n",
      "normal 54.43875714883819 and of 34.5121278814243\n",
      "udp 29.252590253097953 and of 29.252590253097953\n",
      "pluies 11.049114969737513 and of 11.049114969737513\n",
      "jam 5.259537628326344 and of 5.259537628326344\n",
      "438845\n",
      "-------------------------\n",
      "normal 54.98524535997904 and of 34.5310986794882\n",
      "udp 29.281864895350296 and of 29.281864895350296\n",
      "pluies 10.483655960532761 and of 10.483655960532761\n",
      "jam 5.249233784137908 and of 5.249233784137908\n",
      "581729\n",
      "-------------------------\n",
      "normal 54.595352818924276 and of 34.50438262489922\n",
      "udp 29.250561687658685 and of 29.250561687658685\n",
      "pluies 10.900264556176502 and of 10.900264556176502\n",
      "jam 5.253820937240536 and of 5.253820937240536\n",
      "3401905\n",
      "creating input data time 5.309639930725098\n",
      "263116\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "2381331\n",
      "438845\n",
      "581729\n",
      "tensor(821848)\n",
      "tensor(151538)\n",
      "tensor(200722)\n",
      "28.600934505462646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a-time.time()\n",
    "X_train1=X_train.values\n",
    "y_train1=y_train.values\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "torch_tensor = torch.tensor(X_train1)\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "t=[]\n",
    "test=0\n",
    "test0=0\n",
    "\n",
    "for j in y_train1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        test0+=1\n",
    "    #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(0))\n",
    "        test+=1\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(1))\n",
    "print(test)\n",
    "labels = torch.LongTensor(t)\n",
    "#print(torch_tensor[-1])\n",
    "#print(labels[-1])\n",
    "print(labels)\n",
    "#print(df_label)\n",
    "#print(labels.shape)\n",
    "\n",
    "#df00 = pd.read_csv(path0+\"small/testbed3/Dataset_S03Filtrer.csv\")\n",
    "#bigX = df00[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','channel','throughput']]         \n",
    "#bigY = df00['label']\n",
    "bigX = X_valid\n",
    "#[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','throughput']]  ,'channel'       \n",
    "bigY = y_valid['label']\n",
    "#print(bigY)\n",
    "\n",
    "X_valid1=bigX.values\n",
    "y_valid1=bigY.values\n",
    "\n",
    "#X_valid1=X_test.values\n",
    "#y_valid1=y_test.values\n",
    "#X_train1=X_train1.astype(float)\n",
    "del(bigX)\n",
    "del(bigY)\n",
    "vtorch_tensor = torch.tensor(X_valid1)\n",
    "v=[]\n",
    "\n",
    "for i in y_valid1:\n",
    "    #i=j[0]\n",
    "    #print(i)\n",
    "    if (i=='Normal'):\n",
    "        v.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        v.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        v.append(int(0))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        v.append(int(1))\n",
    "\n",
    "vlabels = torch.LongTensor(v)\n",
    "\n",
    "\n",
    "X_test1=X_test.values\n",
    "y_test1=y_test.values\n",
    "\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "ttorch_tensor = torch.tensor(X_test1)\n",
    "\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "t=[]\n",
    "\n",
    "for j in y_test1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(0))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(1))\n",
    "\n",
    "tlabels = torch.LongTensor(t)\n",
    "#print(torch_tensor[-1])\n",
    "#print(labels[-1])\n",
    "print(len(labels))\n",
    "print(len(vlabels))\n",
    "print(len(tlabels))\n",
    "\n",
    "del(X)\n",
    "del(y)\n",
    "del(X1)\n",
    "del(y1)\n",
    "del(X2)\n",
    "del(y2)\n",
    "del(X3)\n",
    "del(y3)\n",
    "del(X4)\n",
    "del(y4)\n",
    "del(X5)\n",
    "del(y5)\n",
    "del(X_train1); del(X_train2);del(X_train3); del(X_train4);del(X_train5)\n",
    "del(y_train1); del(y_train2);del(y_train3); del(y_train4);del(y_train5)\n",
    "del(y_rem);del(y_rem1); del(y_rem2);del(y_rem3); del(y_rem4);del(y_rem5)\n",
    "del(X_rem);del(X_rem1); del(X_rem2);del(X_rem3); del(X_rem4);del(X_rem5)\n",
    "\n",
    "#X_rem1, y_train1, y_rem1\n",
    "del(X_train)\n",
    "del(X_valid)\n",
    "del(X_valid1); del(X_valid2);del(X_valid3); del(X_valid4);del(X_valid5)\n",
    "del(y_valid1); del(y_valid2);del(y_valid3); del(y_valid4);del(y_valid5)\n",
    "\n",
    "\n",
    "del(X_test)\n",
    "del(X_test1); del(X_test2);del(X_test3); del(X_test4);del(X_test5)\n",
    "del(y_test1); del(y_test2);del(y_test3); del(y_test4);del(y_test5)\n",
    "\n",
    "del(y_train)\n",
    "del(y_valid)\n",
    "del(y_test)\n",
    "del(t)\n",
    "del(v)\n",
    "\n",
    "inputs=torch_tensor[:,:] \n",
    "labels1=labels[:]\n",
    "del(torch_tensor)\n",
    "del(labels)\n",
    "#print(len(inputs))\n",
    "#print(len(labels1))\n",
    "vinputs =vtorch_tensor[:,:]\n",
    "vlabels1=vlabels[:]\n",
    "del(vtorch_tensor)\n",
    "del(vlabels)\n",
    "tinputs =ttorch_tensor[:,:] \n",
    "tlabels1=tlabels[:]\n",
    "del(ttorch_tensor)\n",
    "del(tlabels)\n",
    "\n",
    "print(time.time()-a)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T14:49:25.339743Z",
     "iopub.status.busy": "2021-08-29T14:49:25.339059Z",
     "iopub.status.idle": "2021-08-29T14:49:25.350696Z",
     "shell.execute_reply": "2021-08-29T14:49:25.351198Z",
     "shell.execute_reply.started": "2021-08-29T12:00:30.033457Z"
    },
    "papermill": {
     "duration": 0.039001,
     "end_time": "2021-08-29T14:49:25.351382",
     "exception": false,
     "start_time": "2021-08-29T14:49:25.312381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 2\n",
    "#num_epochs = 2\n",
    "batch_size = 600\n",
    "\n",
    "input_size = 14\n",
    "sequence_length = 28\n",
    "hidden_size = 132\n",
    "num_layers = 2\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers,batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        x=x.view(-1,1,14)\n",
    "        #print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        #out = self.fc(out)\n",
    "        x = F.log_softmax(self.fc(out), dim=1)\n",
    "        # out: (n, 10)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "\n",
    "\n",
    "Fonction_de_perte = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "#indices = [0,3, 299:303]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T14:49:25.383596Z",
     "iopub.status.busy": "2021-08-29T14:49:25.382892Z",
     "iopub.status.idle": "2021-08-29T21:02:23.124839Z",
     "shell.execute_reply": "2021-08-29T21:02:23.125752Z"
    },
    "papermill": {
     "duration": 22377.760073,
     "end_time": "2021-08-29T21:02:23.126020",
     "exception": false,
     "start_time": "2021-08-29T14:49:25.365947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  : valid accuracy :65.46890259 with total prob : 51.07397461 \n",
      "Epoch 0 : Training loss 0.00052328 and valid loss : -0.71509830 :  \n",
      "Epoch 0 : valid accuracy :65.46890259 with total prob : 92.52917480 \n",
      "28.985070943832397\n",
      "validation loss decreased , saving model (inf ==> -0.71509830)\n",
      "Epoch 1 : Training loss 0.00023641 and valid loss : -0.89652790 :  \n",
      "Epoch 1 : valid accuracy :89.87683868 with total prob : 98.72951508 \n",
      "28.71040678024292\n",
      "validation loss decreased , saving model (-0.71509830 ==> -0.89652790)\n",
      "Epoch 2 : Training loss 0.00017504 and valid loss : -0.90143686 :  \n",
      "Epoch 2 : valid accuracy :89.87638092 with total prob : 98.18190002 \n",
      "29.131640911102295\n",
      "validation loss decreased , saving model (-0.89652790 ==> -0.90143686)\n",
      "Epoch 3 : Training loss 0.00015133 and valid loss : -0.90539811 :  \n",
      "Epoch 3 : valid accuracy :89.87638092 with total prob : 97.45836639 \n",
      "28.598362684249878\n",
      "validation loss decreased , saving model (-0.90143686 ==> -0.90539811)\n",
      "Epoch 4 : Training loss 0.00013381 and valid loss : -0.90886002 :  \n",
      "Epoch 4 : valid accuracy :90.04569244 with total prob : 97.04280090 \n",
      "29.065831422805786\n",
      "validation loss decreased , saving model (-0.90539811 ==> -0.90886002)\n",
      "Epoch 5 : Training loss 0.00012019 and valid loss : -0.91087194 :  \n",
      "Epoch 5 : valid accuracy :90.33007050 with total prob : 97.05129242 \n",
      "28.61086916923523\n",
      "validation loss decreased , saving model (-0.90886002 ==> -0.91087194)\n",
      "Epoch 6 : Training loss 0.00010949 and valid loss : -0.91158067 :  \n",
      "Epoch 6 : valid accuracy :90.44309235 with total prob : 97.23720551 \n",
      "28.5697979927063\n",
      "validation loss decreased , saving model (-0.91087194 ==> -0.91158067)\n",
      "Epoch 7 : Training loss 0.00010119 and valid loss : -0.91161438 :  \n",
      "Epoch 7 : valid accuracy :90.46998596 with total prob : 97.44097900 \n",
      "28.393375873565674\n",
      "validation loss decreased , saving model (-0.91158067 ==> -0.91161438)\n",
      "Epoch 8 : Training loss 0.00009483 and valid loss : -0.91147903 :  \n",
      "Epoch 8 : valid accuracy :90.45175171 with total prob : 97.60684204 \n",
      "28.56850528717041\n",
      "Epoch 9 : Training loss 0.00009001 and valid loss : -0.91142117 :  \n",
      "Epoch 9 : valid accuracy :90.49482727 with total prob : 97.72814178 \n",
      "28.323634147644043\n",
      "Epoch 10 : Training loss 0.00008633 and valid loss : -0.91151165 :  \n",
      "Epoch 10 : valid accuracy :90.50758362 with total prob : 97.81217194 \n",
      "28.541725635528564\n",
      "Epoch 11 : Training loss 0.00008348 and valid loss : -0.91174136 :  \n",
      "Epoch 11 : valid accuracy :90.57776642 with total prob : 97.86784363 \n",
      "28.065726280212402\n",
      "validation loss decreased , saving model (-0.91161438 ==> -0.91174136)\n",
      "Epoch 12 : Training loss 0.00008125 and valid loss : -0.91207607 :  \n",
      "Epoch 12 : valid accuracy :90.63314056 with total prob : 97.90582275 \n",
      "41.11151123046875\n",
      "validation loss decreased , saving model (-0.91174136 ==> -0.91207607)\n",
      "Epoch 13 : Training loss 0.00007945 and valid loss : -0.91247989 :  \n",
      "Epoch 13 : valid accuracy :90.69078827 with total prob : 97.93148804 \n",
      "32.58870029449463\n",
      "validation loss decreased , saving model (-0.91207607 ==> -0.91247989)\n",
      "Epoch 14 : Training loss 0.00007798 and valid loss : -0.91292298 :  \n",
      "Epoch 14 : valid accuracy :90.75345612 with total prob : 97.94855499 \n",
      "29.79761052131653\n",
      "validation loss decreased , saving model (-0.91247989 ==> -0.91292298)\n",
      "Epoch 15 : Training loss 0.00007674 and valid loss : -0.91338294 :  \n",
      "Epoch 15 : valid accuracy :90.81588745 with total prob : 97.95951843 \n",
      "29.76505732536316\n",
      "validation loss decreased , saving model (-0.91292298 ==> -0.91338294)\n",
      "Epoch 16 : Training loss 0.00007567 and valid loss : -0.91384379 :  \n",
      "Epoch 16 : valid accuracy :90.87947083 with total prob : 97.96706390 \n",
      "29.217241764068604\n",
      "validation loss decreased , saving model (-0.91338294 ==> -0.91384379)\n",
      "Epoch 17 : Training loss 0.00007473 and valid loss : -0.91429460 :  \n",
      "Epoch 17 : valid accuracy :90.94395447 with total prob : 97.97160339 \n",
      "28.444714307785034\n",
      "validation loss decreased , saving model (-0.91384379 ==> -0.91429460)\n",
      "Epoch 18 : Training loss 0.00007389 and valid loss : -0.91472811 :  \n",
      "Epoch 18 : valid accuracy :90.98519897 with total prob : 97.97356415 \n",
      "28.80200743675232\n",
      "validation loss decreased , saving model (-0.91429460 ==> -0.91472811)\n",
      "Epoch 19 : Training loss 0.00007312 and valid loss : -0.91513968 :  \n",
      "Epoch 19 : valid accuracy :91.05332947 with total prob : 97.97412109 \n",
      "28.810401678085327\n",
      "validation loss decreased , saving model (-0.91472811 ==> -0.91513968)\n",
      "Epoch 20 : Training loss 0.00007240 and valid loss : -0.91552643 :  \n",
      "Epoch 20 : valid accuracy :91.11645508 with total prob : 97.97434235 \n",
      "28.765449047088623\n",
      "validation loss decreased , saving model (-0.91513968 ==> -0.91552643)\n",
      "Epoch 21 : Training loss 0.00007173 and valid loss : -0.91588671 :  \n",
      "Epoch 21 : valid accuracy :91.15405273 with total prob : 97.97407532 \n",
      "28.615724325180054\n",
      "validation loss decreased , saving model (-0.91552643 ==> -0.91588671)\n",
      "Epoch 22 : Training loss 0.00007108 and valid loss : -0.91621961 :  \n",
      "Epoch 22 : valid accuracy :91.21945190 with total prob : 97.97323608 \n",
      "29.212841033935547\n",
      "validation loss decreased , saving model (-0.91588671 ==> -0.91621961)\n",
      "Epoch 23 : Training loss 0.00007046 and valid loss : -0.91652467 :  \n",
      "Epoch 23 : valid accuracy :91.25294495 with total prob : 97.97251129 \n",
      "28.690303087234497\n",
      "validation loss decreased , saving model (-0.91621961 ==> -0.91652467)\n",
      "Epoch 24 : Training loss 0.00006985 and valid loss : -0.91680168 :  \n",
      "Epoch 24 : valid accuracy :91.29692841 with total prob : 97.97199249 \n",
      "28.73548674583435\n",
      "validation loss decreased , saving model (-0.91652467 ==> -0.91680168)\n",
      "Epoch 25 : Training loss 0.00006926 and valid loss : -0.91705054 :  \n",
      "Epoch 25 : valid accuracy :91.33361816 with total prob : 97.97167969 \n",
      "29.090179204940796\n",
      "validation loss decreased , saving model (-0.91680168 ==> -0.91705054)\n",
      "Epoch 26 : Training loss 0.00006866 and valid loss : -0.91727116 :  \n",
      "Epoch 26 : valid accuracy :91.36369324 with total prob : 97.97159576 \n",
      "29.216015100479126\n",
      "validation loss decreased , saving model (-0.91705054 ==> -0.91727116)\n",
      "Epoch 27 : Training loss 0.00006807 and valid loss : -0.91746337 :  \n",
      "Epoch 27 : valid accuracy :91.37485504 with total prob : 97.97184753 \n",
      "29.07417368888855\n",
      "validation loss decreased , saving model (-0.91727116 ==> -0.91746337)\n",
      "Epoch 28 : Training loss 0.00006747 and valid loss : -0.91762687 :  \n",
      "Epoch 28 : valid accuracy :91.39195251 with total prob : 97.97252655 \n",
      "29.090914249420166\n",
      "validation loss decreased , saving model (-0.91746337 ==> -0.91762687)\n",
      "Epoch 29 : Training loss 0.00006687 and valid loss : -0.91776126 :  \n",
      "Epoch 29 : valid accuracy :91.40037537 with total prob : 97.97357941 \n",
      "28.75772500038147\n",
      "validation loss decreased , saving model (-0.91762687 ==> -0.91776126)\n",
      "Epoch 30 : Training loss 0.00006626 and valid loss : -0.91786594 :  \n",
      "Epoch 30 : valid accuracy :91.41155243 with total prob : 97.97508240 \n",
      "29.286775827407837\n",
      "validation loss decreased , saving model (-0.91776126 ==> -0.91786594)\n",
      "Epoch 31 : Training loss 0.00006564 and valid loss : -0.91794015 :  \n",
      "Epoch 31 : valid accuracy :91.42498779 with total prob : 97.97714996 \n",
      "29.157626152038574\n",
      "validation loss decreased , saving model (-0.91786594 ==> -0.91794015)\n",
      "Epoch 32 : Training loss 0.00006499 and valid loss : -0.91798295 :  \n",
      "Epoch 32 : valid accuracy :91.43479156 with total prob : 97.97992706 \n",
      "31.912421464920044\n",
      "validation loss decreased , saving model (-0.91794015 ==> -0.91798295)\n",
      "Epoch 33 : Training loss 0.00006433 and valid loss : -0.91799330 :  \n",
      "Epoch 33 : valid accuracy :91.43775177 with total prob : 97.98351288 \n",
      "33.67607402801514\n",
      "validation loss decreased , saving model (-0.91798295 ==> -0.91799330)\n",
      "Epoch 34 : Training loss 0.00006364 and valid loss : -0.91797011 :  \n",
      "Epoch 34 : valid accuracy :91.44345093 with total prob : 97.98794556 \n",
      "28.107091426849365\n",
      "Epoch 35 : Training loss 0.00006292 and valid loss : -0.91791256 :  \n",
      "Epoch 35 : valid accuracy :91.44276428 with total prob : 97.99328613 \n",
      "27.83332061767578\n",
      "Epoch 36 : Training loss 0.00006217 and valid loss : -0.91782072 :  \n",
      "Epoch 36 : valid accuracy :91.44207764 with total prob : 97.99964142 \n",
      "28.032259702682495\n",
      "Epoch 37 : Training loss 0.00006136 and valid loss : -0.91769714 :  \n",
      "Epoch 37 : valid accuracy :91.43957520 with total prob : 98.00715637 \n",
      "27.675419807434082\n",
      "Epoch 38 : Training loss 0.00006050 and valid loss : -0.91755025 :  \n",
      "Epoch 38 : valid accuracy :91.42636108 with total prob : 98.01559448 \n",
      "27.781131744384766\n",
      "Epoch 39 : Training loss 0.00005955 and valid loss : -0.91740000 :  \n",
      "Epoch 39 : valid accuracy :91.41747284 with total prob : 98.02471161 \n",
      "27.730376720428467\n",
      "Epoch 40 : Training loss 0.00005853 and valid loss : -0.91728083 :  \n",
      "Epoch 40 : valid accuracy :91.40106201 with total prob : 98.03370667 \n",
      "27.864768505096436\n",
      "Epoch 41 : Training loss 0.00005750 and valid loss : -0.91723039 :  \n",
      "Epoch 41 : valid accuracy :91.39012909 with total prob : 98.04192352 \n",
      "28.09718632698059\n",
      "Epoch 42 : Training loss 0.00005656 and valid loss : -0.91726890 :  \n",
      "Epoch 42 : valid accuracy :91.40151978 with total prob : 98.04878235 \n",
      "27.763906955718994\n",
      "Epoch 43 : Training loss 0.00005579 and valid loss : -0.91739278 :  \n",
      "Epoch 43 : valid accuracy :91.42340088 with total prob : 98.05447388 \n",
      "28.12222385406494\n",
      "Epoch 44 : Training loss 0.00005517 and valid loss : -0.91758325 :  \n",
      "Epoch 44 : valid accuracy :91.45416260 with total prob : 98.05925751 \n",
      "28.05534791946411\n",
      "Epoch 45 : Training loss 0.00005466 and valid loss : -0.91781701 :  \n",
      "Epoch 45 : valid accuracy :91.50497437 with total prob : 98.06372833 \n",
      "27.50718593597412\n",
      "Epoch 46 : Training loss 0.00005424 and valid loss : -0.91807344 :  \n",
      "Epoch 46 : valid accuracy :91.54872131 with total prob : 98.06863403 \n",
      "27.19269824028015\n",
      "validation loss decreased , saving model (-0.91799330 ==> -0.91807344)\n",
      "Epoch 47 : Training loss 0.00005389 and valid loss : -0.91833753 :  \n",
      "Epoch 47 : valid accuracy :91.57698059 with total prob : 98.07360840 \n",
      "27.403140783309937\n",
      "validation loss decreased , saving model (-0.91807344 ==> -0.91833753)\n",
      "Epoch 48 : Training loss 0.00005359 and valid loss : -0.91860004 :  \n",
      "Epoch 48 : valid accuracy :91.60797119 with total prob : 98.07857513 \n",
      "27.44682288169861\n",
      "validation loss decreased , saving model (-0.91833753 ==> -0.91860004)\n",
      "Epoch 49 : Training loss 0.00005332 and valid loss : -0.91885619 :  \n",
      "Epoch 49 : valid accuracy :91.62438202 with total prob : 98.08351135 \n",
      "26.881935358047485\n",
      "validation loss decreased , saving model (-0.91860004 ==> -0.91885619)\n",
      "Epoch 50 : Training loss 0.00005308 and valid loss : -0.91910415 :  \n",
      "Epoch 50 : valid accuracy :91.65810394 with total prob : 98.08827972 \n",
      "27.00673508644104\n",
      "validation loss decreased , saving model (-0.91885619 ==> -0.91910415)\n",
      "Epoch 51 : Training loss 0.00005287 and valid loss : -0.91934383 :  \n",
      "Epoch 51 : valid accuracy :91.69000244 with total prob : 98.09293365 \n",
      "27.24864435195923\n",
      "validation loss decreased , saving model (-0.91910415 ==> -0.91934383)\n",
      "Epoch 52 : Training loss 0.00005267 and valid loss : -0.91957599 :  \n",
      "Epoch 52 : valid accuracy :91.69501495 with total prob : 98.09715271 \n",
      "27.64040994644165\n",
      "validation loss decreased , saving model (-0.91934383 ==> -0.91957599)\n",
      "Epoch 53 : Training loss 0.00005249 and valid loss : -0.91980175 :  \n",
      "Epoch 53 : valid accuracy :91.71917725 with total prob : 98.10082245 \n",
      "27.041463613510132\n",
      "validation loss decreased , saving model (-0.91957599 ==> -0.91980175)\n",
      "Epoch 54 : Training loss 0.00005232 and valid loss : -0.92002224 :  \n",
      "Epoch 54 : valid accuracy :91.73421478 with total prob : 98.10418701 \n",
      "27.259179830551147\n",
      "validation loss decreased , saving model (-0.91980175 ==> -0.92002224)\n",
      "Epoch 55 : Training loss 0.00005216 and valid loss : -0.92023852 :  \n",
      "Epoch 55 : valid accuracy :91.75563049 with total prob : 98.10713196 \n",
      "32.2017388343811\n",
      "validation loss decreased , saving model (-0.92002224 ==> -0.92023852)\n",
      "Epoch 56 : Training loss 0.00005201 and valid loss : -0.92045149 :  \n",
      "Epoch 56 : valid accuracy :91.77682495 with total prob : 98.10968018 \n",
      "27.60746717453003\n",
      "validation loss decreased , saving model (-0.92023852 ==> -0.92045149)\n",
      "Epoch 57 : Training loss 0.00005187 and valid loss : -0.92066192 :  \n",
      "Epoch 57 : valid accuracy :91.80735779 with total prob : 98.11193085 \n",
      "28.375805139541626\n",
      "validation loss decreased , saving model (-0.92045149 ==> -0.92066192)\n",
      "Epoch 58 : Training loss 0.00005173 and valid loss : -0.92087044 :  \n",
      "Epoch 58 : valid accuracy :91.80963898 with total prob : 98.11389923 \n",
      "27.184574127197266\n",
      "validation loss decreased , saving model (-0.92066192 ==> -0.92087044)\n",
      "Epoch 59 : Training loss 0.00005160 and valid loss : -0.92107756 :  \n",
      "Epoch 59 : valid accuracy :91.82968903 with total prob : 98.11544800 \n",
      "26.434845447540283\n",
      "validation loss decreased , saving model (-0.92087044 ==> -0.92107756)\n",
      "Epoch 60 : Training loss 0.00005148 and valid loss : -0.92128372 :  \n",
      "Epoch 60 : valid accuracy :91.86637115 with total prob : 98.11685944 \n",
      "27.142386436462402\n",
      "validation loss decreased , saving model (-0.92107756 ==> -0.92128372)\n",
      "Epoch 61 : Training loss 0.00005136 and valid loss : -0.92148928 :  \n",
      "Epoch 61 : valid accuracy :91.87525940 with total prob : 98.11807251 \n",
      "27.972709894180298\n",
      "validation loss decreased , saving model (-0.92128372 ==> -0.92148928)\n",
      "Epoch 62 : Training loss 0.00005124 and valid loss : -0.92169454 :  \n",
      "Epoch 62 : valid accuracy :91.88050842 with total prob : 98.11889648 \n",
      "28.88947820663452\n",
      "validation loss decreased , saving model (-0.92148928 ==> -0.92169454)\n",
      "Epoch 63 : Training loss 0.00005113 and valid loss : -0.92189979 :  \n",
      "Epoch 63 : valid accuracy :91.90534210 with total prob : 98.11952972 \n",
      "28.590336322784424\n",
      "validation loss decreased , saving model (-0.92169454 ==> -0.92189979)\n",
      "Epoch 64 : Training loss 0.00005101 and valid loss : -0.92210527 :  \n",
      "Epoch 64 : valid accuracy :91.92470551 with total prob : 98.11975098 \n",
      "28.407593965530396\n",
      "validation loss decreased , saving model (-0.92189979 ==> -0.92210527)\n",
      "Epoch 65 : Training loss 0.00005090 and valid loss : -0.92231120 :  \n",
      "Epoch 65 : valid accuracy :91.93952179 with total prob : 98.11961365 \n",
      "29.797189474105835\n",
      "validation loss decreased , saving model (-0.92210527 ==> -0.92231120)\n",
      "Epoch 66 : Training loss 0.00005080 and valid loss : -0.92251778 :  \n",
      "Epoch 66 : valid accuracy :91.96891785 with total prob : 98.11934662 \n",
      "29.41817617416382\n",
      "validation loss decreased , saving model (-0.92231120 ==> -0.92251778)\n",
      "Epoch 67 : Training loss 0.00005069 and valid loss : -0.92272520 :  \n",
      "Epoch 67 : valid accuracy :91.99762726 with total prob : 98.11871338 \n",
      "29.80563449859619\n",
      "validation loss decreased , saving model (-0.92251778 ==> -0.92272520)\n",
      "Epoch 68 : Training loss 0.00005059 and valid loss : -0.92293363 :  \n",
      "Epoch 68 : valid accuracy :92.01358032 with total prob : 98.11781311 \n",
      "29.36398959159851\n",
      "validation loss decreased , saving model (-0.92272520 ==> -0.92293363)\n",
      "Epoch 69 : Training loss 0.00005048 and valid loss : -0.92314325 :  \n",
      "Epoch 69 : valid accuracy :92.02656555 with total prob : 98.11631775 \n",
      "28.831732749938965\n",
      "validation loss decreased , saving model (-0.92293363 ==> -0.92314325)\n",
      "Epoch 70 : Training loss 0.00005038 and valid loss : -0.92335421 :  \n",
      "Epoch 70 : valid accuracy :92.04297638 with total prob : 98.11455536 \n",
      "28.004603624343872\n",
      "validation loss decreased , saving model (-0.92314325 ==> -0.92335421)\n",
      "Epoch 71 : Training loss 0.00005027 and valid loss : -0.92356666 :  \n",
      "Epoch 71 : valid accuracy :92.06348419 with total prob : 98.11261749 \n",
      "28.054550409317017\n",
      "validation loss decreased , saving model (-0.92335421 ==> -0.92356666)\n",
      "Epoch 72 : Training loss 0.00005017 and valid loss : -0.92378072 :  \n",
      "Epoch 72 : valid accuracy :92.08786774 with total prob : 98.11042786 \n",
      "28.148654222488403\n",
      "validation loss decreased , saving model (-0.92356666 ==> -0.92378072)\n",
      "Epoch 73 : Training loss 0.00005007 and valid loss : -0.92399654 :  \n",
      "Epoch 73 : valid accuracy :92.10131073 with total prob : 98.10794830 \n",
      "28.536054372787476\n",
      "validation loss decreased , saving model (-0.92378072 ==> -0.92399654)\n",
      "Epoch 74 : Training loss 0.00004997 and valid loss : -0.92421423 :  \n",
      "Epoch 74 : valid accuracy :92.12296295 with total prob : 98.10524750 \n",
      "28.675990104675293\n",
      "validation loss decreased , saving model (-0.92399654 ==> -0.92421423)\n",
      "Epoch 75 : Training loss 0.00004987 and valid loss : -0.92443390 :  \n",
      "Epoch 75 : valid accuracy :92.16033173 with total prob : 98.10257721 \n",
      "28.395132541656494\n",
      "validation loss decreased , saving model (-0.92421423 ==> -0.92443390)\n",
      "Epoch 76 : Training loss 0.00004976 and valid loss : -0.92465566 :  \n",
      "Epoch 76 : valid accuracy :92.17377472 with total prob : 98.10001373 \n",
      "35.11092686653137\n",
      "validation loss decreased , saving model (-0.92443390 ==> -0.92465566)\n",
      "Epoch 77 : Training loss 0.00004966 and valid loss : -0.92487958 :  \n",
      "Epoch 77 : valid accuracy :92.19268799 with total prob : 98.09731293 \n",
      "33.457911014556885\n",
      "validation loss decreased , saving model (-0.92465566 ==> -0.92487958)\n",
      "Epoch 78 : Training loss 0.00004956 and valid loss : -0.92510576 :  \n",
      "Epoch 78 : valid accuracy :92.21205902 with total prob : 98.09435272 \n",
      "29.229328155517578\n",
      "validation loss decreased , saving model (-0.92487958 ==> -0.92510576)\n",
      "Epoch 79 : Training loss 0.00004946 and valid loss : -0.92533426 :  \n",
      "Epoch 79 : valid accuracy :92.22891998 with total prob : 98.09103394 \n",
      "29.72584342956543\n",
      "validation loss decreased , saving model (-0.92510576 ==> -0.92533426)\n",
      "Epoch 80 : Training loss 0.00004936 and valid loss : -0.92556514 :  \n",
      "Epoch 80 : valid accuracy :92.24213409 with total prob : 98.08762360 \n",
      "29.64390468597412\n",
      "validation loss decreased , saving model (-0.92533426 ==> -0.92556514)\n",
      "Epoch 81 : Training loss 0.00004926 and valid loss : -0.92579845 :  \n",
      "Epoch 81 : valid accuracy :92.27221680 with total prob : 98.08445740 \n",
      "29.459823608398438\n",
      "validation loss decreased , saving model (-0.92556514 ==> -0.92579845)\n",
      "Epoch 82 : Training loss 0.00004915 and valid loss : -0.92603421 :  \n",
      "Epoch 82 : valid accuracy :92.29591370 with total prob : 98.08126068 \n",
      "29.66825795173645\n",
      "validation loss decreased , saving model (-0.92579845 ==> -0.92603421)\n",
      "Epoch 83 : Training loss 0.00004905 and valid loss : -0.92627245 :  \n",
      "Epoch 83 : valid accuracy :92.31414032 with total prob : 98.07792664 \n",
      "29.641642570495605\n",
      "validation loss decreased , saving model (-0.92603421 ==> -0.92627245)\n",
      "Epoch 84 : Training loss 0.00004895 and valid loss : -0.92651318 :  \n",
      "Epoch 84 : valid accuracy :92.32941437 with total prob : 98.07419586 \n",
      "29.51881217956543\n",
      "validation loss decreased , saving model (-0.92627245 ==> -0.92651318)\n",
      "Epoch 85 : Training loss 0.00004885 and valid loss : -0.92675637 :  \n",
      "Epoch 85 : valid accuracy :92.36267853 with total prob : 98.07038879 \n",
      "29.3137788772583\n",
      "validation loss decreased , saving model (-0.92651318 ==> -0.92675637)\n",
      "Epoch 86 : Training loss 0.00004875 and valid loss : -0.92700203 :  \n",
      "Epoch 86 : valid accuracy :92.40574646 with total prob : 98.06668854 \n",
      "29.706379890441895\n",
      "validation loss decreased , saving model (-0.92675637 ==> -0.92700203)\n",
      "Epoch 87 : Training loss 0.00004865 and valid loss : -0.92725009 :  \n",
      "Epoch 87 : valid accuracy :92.42694092 with total prob : 98.06328583 \n",
      "29.386337518692017\n",
      "validation loss decreased , saving model (-0.92700203 ==> -0.92725009)\n",
      "Epoch 88 : Training loss 0.00004855 and valid loss : -0.92750051 :  \n",
      "Epoch 88 : valid accuracy :92.46043396 with total prob : 98.06003571 \n",
      "28.942373991012573\n",
      "validation loss decreased , saving model (-0.92725009 ==> -0.92750051)\n",
      "Epoch 89 : Training loss 0.00004845 and valid loss : -0.92775323 :  \n",
      "Epoch 89 : valid accuracy :92.49666595 with total prob : 98.05711365 \n",
      "28.870968341827393\n",
      "validation loss decreased , saving model (-0.92750051 ==> -0.92775323)\n",
      "Epoch 90 : Training loss 0.00004835 and valid loss : -0.92800815 :  \n",
      "Epoch 90 : valid accuracy :92.52469635 with total prob : 98.05448914 \n",
      "29.743178844451904\n",
      "validation loss decreased , saving model (-0.92775323 ==> -0.92800815)\n",
      "Epoch 91 : Training loss 0.00004825 and valid loss : -0.92826517 :  \n",
      "Epoch 91 : valid accuracy :92.55522919 with total prob : 98.05213165 \n",
      "29.426109790802002\n",
      "validation loss decreased , saving model (-0.92800815 ==> -0.92826517)\n",
      "Epoch 92 : Training loss 0.00004815 and valid loss : -0.92852418 :  \n",
      "Epoch 92 : valid accuracy :92.57733154 with total prob : 98.04969788 \n",
      "29.565295457839966\n",
      "validation loss decreased , saving model (-0.92826517 ==> -0.92852418)\n",
      "Epoch 93 : Training loss 0.00004806 and valid loss : -0.92878505 :  \n",
      "Epoch 93 : valid accuracy :92.58759308 with total prob : 98.04710388 \n",
      "28.513592958450317\n",
      "validation loss decreased , saving model (-0.92852418 ==> -0.92878505)\n",
      "Epoch 94 : Training loss 0.00004796 and valid loss : -0.92904763 :  \n",
      "Epoch 94 : valid accuracy :92.59214783 with total prob : 98.04399872 \n",
      "28.210164546966553\n",
      "validation loss decreased , saving model (-0.92878505 ==> -0.92904763)\n",
      "Epoch 95 : Training loss 0.00004787 and valid loss : -0.92931177 :  \n",
      "Epoch 95 : valid accuracy :92.62154388 with total prob : 98.04086304 \n",
      "28.17420482635498\n",
      "validation loss decreased , saving model (-0.92904763 ==> -0.92931177)\n",
      "Epoch 96 : Training loss 0.00004777 and valid loss : -0.92957729 :  \n",
      "Epoch 96 : valid accuracy :92.64091492 with total prob : 98.03749084 \n",
      "28.2721529006958\n",
      "validation loss decreased , saving model (-0.92931177 ==> -0.92957729)\n",
      "Epoch 97 : Training loss 0.00004768 and valid loss : -0.92984402 :  \n",
      "Epoch 97 : valid accuracy :92.65914154 with total prob : 98.03415680 \n",
      "35.52181077003479\n",
      "validation loss decreased , saving model (-0.92957729 ==> -0.92984402)\n",
      "Epoch 98 : Training loss 0.00004759 and valid loss : -0.93011176 :  \n",
      "Epoch 98 : valid accuracy :92.68056488 with total prob : 98.03060913 \n",
      "29.202450275421143\n",
      "validation loss decreased , saving model (-0.92984402 ==> -0.93011176)\n",
      "Epoch 99 : Training loss 0.00004750 and valid loss : -0.93038032 :  \n",
      "Epoch 99 : valid accuracy :92.71907043 with total prob : 98.02748108 \n",
      "28.738077878952026\n",
      "validation loss decreased , saving model (-0.93011176 ==> -0.93038032)\n",
      "Epoch 100 : Training loss 0.00004741 and valid loss : -0.93064948 :  \n",
      "Epoch 100 : valid accuracy :92.74117279 with total prob : 98.02482605 \n",
      "27.977858066558838\n",
      "validation loss decreased , saving model (-0.93038032 ==> -0.93064948)\n",
      "Epoch 101 : Training loss 0.00004732 and valid loss : -0.93091905 :  \n",
      "Epoch 101 : valid accuracy :92.75757599 with total prob : 98.02268982 \n",
      "27.744615077972412\n",
      "validation loss decreased , saving model (-0.93064948 ==> -0.93091905)\n",
      "Epoch 102 : Training loss 0.00004724 and valid loss : -0.93118879 :  \n",
      "Epoch 102 : valid accuracy :92.79814148 with total prob : 98.02143860 \n",
      "28.224222660064697\n",
      "validation loss decreased , saving model (-0.93091905 ==> -0.93118879)\n",
      "Epoch 103 : Training loss 0.00004715 and valid loss : -0.93145850 :  \n",
      "Epoch 103 : valid accuracy :92.82707977 with total prob : 98.02084351 \n",
      "28.41299295425415\n",
      "validation loss decreased , saving model (-0.93118879 ==> -0.93145850)\n",
      "Epoch 104 : Training loss 0.00004707 and valid loss : -0.93172795 :  \n",
      "Epoch 104 : valid accuracy :92.86080933 with total prob : 98.02101135 \n",
      "28.494531393051147\n",
      "validation loss decreased , saving model (-0.93145850 ==> -0.93172795)\n",
      "Epoch 105 : Training loss 0.00004699 and valid loss : -0.93199692 :  \n",
      "Epoch 105 : valid accuracy :92.89635468 with total prob : 98.02159882 \n",
      "27.660247564315796\n",
      "validation loss decreased , saving model (-0.93172795 ==> -0.93199692)\n",
      "Epoch 106 : Training loss 0.00004691 and valid loss : -0.93226520 :  \n",
      "Epoch 106 : valid accuracy :92.93304443 with total prob : 98.02285004 \n",
      "27.739664554595947\n",
      "validation loss decreased , saving model (-0.93199692 ==> -0.93226520)\n",
      "Epoch 107 : Training loss 0.00004683 and valid loss : -0.93253256 :  \n",
      "Epoch 107 : valid accuracy :92.95127106 with total prob : 98.02458191 \n",
      "28.13343048095703\n",
      "validation loss decreased , saving model (-0.93226520 ==> -0.93253256)\n",
      "Epoch 108 : Training loss 0.00004676 and valid loss : -0.93279881 :  \n",
      "Epoch 108 : valid accuracy :92.97838593 with total prob : 98.02661133 \n",
      "28.911362171173096\n",
      "validation loss decreased , saving model (-0.93253256 ==> -0.93279881)\n",
      "Epoch 109 : Training loss 0.00004668 and valid loss : -0.93306372 :  \n",
      "Epoch 109 : valid accuracy :93.00505066 with total prob : 98.02899170 \n",
      "27.93925905227661\n",
      "validation loss decreased , saving model (-0.93279881 ==> -0.93306372)\n",
      "Epoch 110 : Training loss 0.00004661 and valid loss : -0.93332710 :  \n",
      "Epoch 110 : valid accuracy :93.03238678 with total prob : 98.03175354 \n",
      "27.719857931137085\n",
      "validation loss decreased , saving model (-0.93306372 ==> -0.93332710)\n",
      "Epoch 111 : Training loss 0.00004654 and valid loss : -0.93358875 :  \n",
      "Epoch 111 : valid accuracy :93.05699921 with total prob : 98.03485107 \n",
      "27.724180459976196\n",
      "validation loss decreased , saving model (-0.93332710 ==> -0.93358875)\n",
      "Epoch 112 : Training loss 0.00004647 and valid loss : -0.93384849 :  \n",
      "Epoch 112 : valid accuracy :93.07227325 with total prob : 98.03835297 \n",
      "27.357282638549805\n",
      "validation loss decreased , saving model (-0.93358875 ==> -0.93384849)\n",
      "Epoch 113 : Training loss 0.00004640 and valid loss : -0.93410614 :  \n",
      "Epoch 113 : valid accuracy :93.10029602 with total prob : 98.04200745 \n",
      "27.730896949768066\n",
      "validation loss decreased , saving model (-0.93384849 ==> -0.93410614)\n",
      "Epoch 114 : Training loss 0.00004634 and valid loss : -0.93436152 :  \n",
      "Epoch 114 : valid accuracy :93.12331390 with total prob : 98.04603577 \n",
      "27.772964000701904\n",
      "validation loss decreased , saving model (-0.93410614 ==> -0.93436152)\n",
      "Epoch 115 : Training loss 0.00004627 and valid loss : -0.93461448 :  \n",
      "Epoch 115 : valid accuracy :93.15635681 with total prob : 98.05055237 \n",
      "27.622512340545654\n",
      "validation loss decreased , saving model (-0.93436152 ==> -0.93461448)\n",
      "Epoch 116 : Training loss 0.00004621 and valid loss : -0.93486486 :  \n",
      "Epoch 116 : valid accuracy :93.18756866 with total prob : 98.05547333 \n",
      "27.947442770004272\n",
      "validation loss decreased , saving model (-0.93461448 ==> -0.93486486)\n",
      "Epoch 117 : Training loss 0.00004614 and valid loss : -0.93511252 :  \n",
      "Epoch 117 : valid accuracy :93.22563171 with total prob : 98.06086731 \n",
      "27.73518991470337\n",
      "validation loss decreased , saving model (-0.93486486 ==> -0.93511252)\n",
      "Epoch 118 : Training loss 0.00004608 and valid loss : -0.93535732 :  \n",
      "Epoch 118 : valid accuracy :93.24795532 with total prob : 98.06672668 \n",
      "27.90161442756653\n",
      "validation loss decreased , saving model (-0.93511252 ==> -0.93535732)\n",
      "Epoch 119 : Training loss 0.00004602 and valid loss : -0.93559916 :  \n",
      "Epoch 119 : valid accuracy :93.27871704 with total prob : 98.07303619 \n",
      "36.12712860107422\n",
      "validation loss decreased , saving model (-0.93535732 ==> -0.93559916)\n",
      "Epoch 120 : Training loss 0.00004596 and valid loss : -0.93583791 :  \n",
      "Epoch 120 : valid accuracy :93.30879974 with total prob : 98.07966614 \n",
      "27.968993186950684\n",
      "validation loss decreased , saving model (-0.93559916 ==> -0.93583791)\n",
      "Epoch 121 : Training loss 0.00004590 and valid loss : -0.93607348 :  \n",
      "Epoch 121 : valid accuracy :93.33090210 with total prob : 98.08684540 \n",
      "28.13853359222412\n",
      "validation loss decreased , saving model (-0.93583791 ==> -0.93607348)\n",
      "Epoch 122 : Training loss 0.00004585 and valid loss : -0.93630577 :  \n",
      "Epoch 122 : valid accuracy :93.34526062 with total prob : 98.09447479 \n",
      "27.896578550338745\n",
      "validation loss decreased , saving model (-0.93607348 ==> -0.93630577)\n",
      "Epoch 123 : Training loss 0.00004579 and valid loss : -0.93653471 :  \n",
      "Epoch 123 : valid accuracy :93.37100983 with total prob : 98.10233307 \n",
      "27.86651873588562\n",
      "validation loss decreased , saving model (-0.93630577 ==> -0.93653471)\n",
      "Epoch 124 : Training loss 0.00004573 and valid loss : -0.93676023 :  \n",
      "Epoch 124 : valid accuracy :93.40222168 with total prob : 98.11083984 \n",
      "28.074753761291504\n",
      "validation loss decreased , saving model (-0.93653471 ==> -0.93676023)\n",
      "Epoch 125 : Training loss 0.00004568 and valid loss : -0.93698226 :  \n",
      "Epoch 125 : valid accuracy :93.43777466 with total prob : 98.11980438 \n",
      "27.73504114151001\n",
      "validation loss decreased , saving model (-0.93676023 ==> -0.93698226)\n",
      "Epoch 126 : Training loss 0.00004562 and valid loss : -0.93720076 :  \n",
      "Epoch 126 : valid accuracy :93.45532227 with total prob : 98.12937927 \n",
      "27.748647212982178\n",
      "validation loss decreased , saving model (-0.93698226 ==> -0.93720076)\n",
      "Epoch 127 : Training loss 0.00004556 and valid loss : -0.93741568 :  \n",
      "Epoch 127 : valid accuracy :93.47035980 with total prob : 98.13936615 \n",
      "28.08173441886902\n",
      "validation loss decreased , saving model (-0.93720076 ==> -0.93741568)\n",
      "Epoch 128 : Training loss 0.00004551 and valid loss : -0.93762700 :  \n",
      "Epoch 128 : valid accuracy :93.49451447 with total prob : 98.14968872 \n",
      "28.148325204849243\n",
      "validation loss decreased , saving model (-0.93741568 ==> -0.93762700)\n",
      "Epoch 129 : Training loss 0.00004545 and valid loss : -0.93783469 :  \n",
      "Epoch 129 : valid accuracy :93.51935577 with total prob : 98.16017151 \n",
      "27.92173147201538\n",
      "validation loss decreased , saving model (-0.93762700 ==> -0.93783469)\n",
      "Epoch 130 : Training loss 0.00004539 and valid loss : -0.93803875 :  \n",
      "Epoch 130 : valid accuracy :93.54418945 with total prob : 98.17100525 \n",
      "27.450373649597168\n",
      "validation loss decreased , saving model (-0.93783469 ==> -0.93803875)\n",
      "Epoch 131 : Training loss 0.00004534 and valid loss : -0.93823916 :  \n",
      "Epoch 131 : valid accuracy :93.55809021 with total prob : 98.18204498 \n",
      "27.59137487411499\n",
      "validation loss decreased , saving model (-0.93803875 ==> -0.93823916)\n",
      "Epoch 132 : Training loss 0.00004528 and valid loss : -0.93843594 :  \n",
      "Epoch 132 : valid accuracy :93.57267761 with total prob : 98.19343567 \n",
      "27.85096836090088\n",
      "validation loss decreased , saving model (-0.93823916 ==> -0.93843594)\n",
      "Epoch 133 : Training loss 0.00004522 and valid loss : -0.93862909 :  \n",
      "Epoch 133 : valid accuracy :93.59660339 with total prob : 98.20497894 \n",
      "27.291914224624634\n",
      "validation loss decreased , saving model (-0.93843594 ==> -0.93862909)\n",
      "Epoch 134 : Training loss 0.00004516 and valid loss : -0.93881864 :  \n",
      "Epoch 134 : valid accuracy :93.61551666 with total prob : 98.21694183 \n",
      "27.40907597541809\n",
      "validation loss decreased , saving model (-0.93862909 ==> -0.93881864)\n",
      "Epoch 135 : Training loss 0.00004510 and valid loss : -0.93900461 :  \n",
      "Epoch 135 : valid accuracy :93.63852692 with total prob : 98.22944641 \n",
      "27.296724557876587\n",
      "validation loss decreased , saving model (-0.93881864 ==> -0.93900461)\n",
      "Epoch 136 : Training loss 0.00004504 and valid loss : -0.93918703 :  \n",
      "Epoch 136 : valid accuracy :93.65812683 with total prob : 98.24247742 \n",
      "27.842331886291504\n",
      "validation loss decreased , saving model (-0.93900461 ==> -0.93918703)\n",
      "Epoch 137 : Training loss 0.00004498 and valid loss : -0.93936596 :  \n",
      "Epoch 137 : valid accuracy :93.67179871 with total prob : 98.25601196 \n",
      "28.32912850379944\n",
      "validation loss decreased , saving model (-0.93918703 ==> -0.93936596)\n",
      "Epoch 138 : Training loss 0.00004491 and valid loss : -0.93954142 :  \n",
      "Epoch 138 : valid accuracy :93.70096588 with total prob : 98.27012634 \n",
      "27.858482837677002\n",
      "validation loss decreased , saving model (-0.93936596 ==> -0.93954142)\n",
      "Epoch 139 : Training loss 0.00004484 and valid loss : -0.93971348 :  \n",
      "Epoch 139 : valid accuracy :93.72830963 with total prob : 98.28475952 \n",
      "28.16428852081299\n",
      "validation loss decreased , saving model (-0.93954142 ==> -0.93971348)\n",
      "Epoch 140 : Training loss 0.00004478 and valid loss : -0.93988218 :  \n",
      "Epoch 140 : valid accuracy :93.75611115 with total prob : 98.29974365 \n",
      "28.311904430389404\n",
      "validation loss decreased , saving model (-0.93971348 ==> -0.93988218)\n",
      "Epoch 141 : Training loss 0.00004471 and valid loss : -0.94004758 :  \n",
      "Epoch 141 : valid accuracy :93.76567841 with total prob : 98.31505585 \n",
      "34.1762170791626\n",
      "validation loss decreased , saving model (-0.93988218 ==> -0.94004758)\n",
      "Epoch 142 : Training loss 0.00004464 and valid loss : -0.94020976 :  \n",
      "Epoch 142 : valid accuracy :93.78345490 with total prob : 98.33049774 \n",
      "27.993030786514282\n",
      "validation loss decreased , saving model (-0.94004758 ==> -0.94020976)\n",
      "Epoch 143 : Training loss 0.00004456 and valid loss : -0.94036876 :  \n",
      "Epoch 143 : valid accuracy :93.79644775 with total prob : 98.34628296 \n",
      "27.86356782913208\n",
      "validation loss decreased , saving model (-0.94020976 ==> -0.94036876)\n",
      "Epoch 144 : Training loss 0.00004449 and valid loss : -0.94052465 :  \n",
      "Epoch 144 : valid accuracy :93.80510712 with total prob : 98.36247253 \n",
      "27.82457208633423\n",
      "validation loss decreased , saving model (-0.94036876 ==> -0.94052465)\n",
      "Epoch 145 : Training loss 0.00004441 and valid loss : -0.94067752 :  \n",
      "Epoch 145 : valid accuracy :93.82402039 with total prob : 98.37875366 \n",
      "27.882089138031006\n",
      "validation loss decreased , saving model (-0.94052465 ==> -0.94067752)\n",
      "Epoch 146 : Training loss 0.00004433 and valid loss : -0.94082741 :  \n",
      "Epoch 146 : valid accuracy :93.83267212 with total prob : 98.39526367 \n",
      "27.687145948410034\n",
      "validation loss decreased , saving model (-0.94067752 ==> -0.94082741)\n",
      "Epoch 147 : Training loss 0.00004424 and valid loss : -0.94097440 :  \n",
      "Epoch 147 : valid accuracy :93.84497833 with total prob : 98.41181183 \n",
      "27.5899338722229\n",
      "validation loss decreased , saving model (-0.94082741 ==> -0.94097440)\n",
      "Epoch 148 : Training loss 0.00004415 and valid loss : -0.94111856 :  \n",
      "Epoch 148 : valid accuracy :93.85295868 with total prob : 98.42827606 \n",
      "27.475834608078003\n",
      "validation loss decreased , saving model (-0.94097440 ==> -0.94111856)\n",
      "Epoch 149 : Training loss 0.00004406 and valid loss : -0.94125996 :  \n",
      "Epoch 149 : valid accuracy :93.86730957 with total prob : 98.44476318 \n",
      "27.478418111801147\n",
      "validation loss decreased , saving model (-0.94111856 ==> -0.94125996)\n",
      "Epoch 150 : Training loss 0.00004397 and valid loss : -0.94139867 :  \n",
      "Epoch 150 : valid accuracy :93.87368774 with total prob : 98.46110535 \n",
      "28.927037954330444\n",
      "validation loss decreased , saving model (-0.94125996 ==> -0.94139867)\n",
      "Epoch 151 : Training loss 0.00004388 and valid loss : -0.94153474 :  \n",
      "Epoch 151 : valid accuracy :93.89123535 with total prob : 98.47730255 \n",
      "27.75599718093872\n",
      "validation loss decreased , saving model (-0.94139867 ==> -0.94153474)\n",
      "Epoch 152 : Training loss 0.00004378 and valid loss : -0.94166825 :  \n",
      "Epoch 152 : valid accuracy :93.93180084 with total prob : 98.49325562 \n",
      "27.638187646865845\n",
      "validation loss decreased , saving model (-0.94153474 ==> -0.94166825)\n",
      "Epoch 153 : Training loss 0.00004368 and valid loss : -0.94179925 :  \n",
      "Epoch 153 : valid accuracy :93.98580170 with total prob : 98.50908661 \n",
      "27.72672438621521\n",
      "validation loss decreased , saving model (-0.94166825 ==> -0.94179925)\n",
      "Epoch 154 : Training loss 0.00004357 and valid loss : -0.94192782 :  \n",
      "Epoch 154 : valid accuracy :94.02613831 with total prob : 98.52487946 \n",
      "27.4538893699646\n",
      "validation loss decreased , saving model (-0.94179925 ==> -0.94192782)\n",
      "Epoch 155 : Training loss 0.00004346 and valid loss : -0.94205400 :  \n",
      "Epoch 155 : valid accuracy :94.06145477 with total prob : 98.54037476 \n",
      "27.06334948539734\n",
      "validation loss decreased , saving model (-0.94192782 ==> -0.94205400)\n",
      "Epoch 156 : Training loss 0.00004335 and valid loss : -0.94217786 :  \n",
      "Epoch 156 : valid accuracy :94.08401489 with total prob : 98.55562592 \n",
      "28.186013221740723\n",
      "validation loss decreased , saving model (-0.94205400 ==> -0.94217786)\n",
      "Epoch 157 : Training loss 0.00004323 and valid loss : -0.94229945 :  \n",
      "Epoch 157 : valid accuracy :94.11546326 with total prob : 98.57061768 \n",
      "28.048007488250732\n",
      "validation loss decreased , saving model (-0.94217786 ==> -0.94229945)\n",
      "Epoch 158 : Training loss 0.00004311 and valid loss : -0.94241884 :  \n",
      "Epoch 158 : valid accuracy :94.14576721 with total prob : 98.58530426 \n",
      "27.85860538482666\n",
      "validation loss decreased , saving model (-0.94229945 ==> -0.94241884)\n",
      "Epoch 159 : Training loss 0.00004299 and valid loss : -0.94253607 :  \n",
      "Epoch 159 : valid accuracy :94.17174530 with total prob : 98.59954071 \n",
      "27.57788324356079\n",
      "validation loss decreased , saving model (-0.94241884 ==> -0.94253607)\n",
      "Epoch 160 : Training loss 0.00004286 and valid loss : -0.94265120 :  \n",
      "Epoch 160 : valid accuracy :94.22871399 with total prob : 98.61337280 \n",
      "27.366672039031982\n",
      "validation loss decreased , saving model (-0.94253607 ==> -0.94265120)\n",
      "Epoch 161 : Training loss 0.00004273 and valid loss : -0.94276430 :  \n",
      "Epoch 161 : valid accuracy :94.26448822 with total prob : 98.62691498 \n",
      "27.83686375617981\n",
      "validation loss decreased , saving model (-0.94265120 ==> -0.94276430)\n",
      "Epoch 162 : Training loss 0.00004260 and valid loss : -0.94287542 :  \n",
      "Epoch 162 : valid accuracy :94.28203583 with total prob : 98.64007568 \n",
      "35.23842406272888\n",
      "validation loss decreased , saving model (-0.94276430 ==> -0.94287542)\n",
      "Epoch 163 : Training loss 0.00004246 and valid loss : -0.94298462 :  \n",
      "Epoch 163 : valid accuracy :94.32191467 with total prob : 98.65287018 \n",
      "33.184983253479004\n",
      "validation loss decreased , saving model (-0.94287542 ==> -0.94298462)\n",
      "Epoch 164 : Training loss 0.00004232 and valid loss : -0.94309197 :  \n",
      "Epoch 164 : valid accuracy :94.34902954 with total prob : 98.66530609 \n",
      "27.89508295059204\n",
      "validation loss decreased , saving model (-0.94298462 ==> -0.94309197)\n",
      "Epoch 165 : Training loss 0.00004218 and valid loss : -0.94319755 :  \n",
      "Epoch 165 : valid accuracy :94.37454987 with total prob : 98.67736053 \n",
      "27.720158100128174\n",
      "validation loss decreased , saving model (-0.94309197 ==> -0.94319755)\n",
      "Epoch 166 : Training loss 0.00004203 and valid loss : -0.94330142 :  \n",
      "Epoch 166 : valid accuracy :94.39346313 with total prob : 98.68897247 \n",
      "27.499319314956665\n",
      "validation loss decreased , saving model (-0.94319755 ==> -0.94330142)\n",
      "Epoch 167 : Training loss 0.00004188 and valid loss : -0.94340369 :  \n",
      "Epoch 167 : valid accuracy :94.43312073 with total prob : 98.70020294 \n",
      "26.950612545013428\n",
      "validation loss decreased , saving model (-0.94330142 ==> -0.94340369)\n",
      "Epoch 168 : Training loss 0.00004173 and valid loss : -0.94350443 :  \n",
      "Epoch 168 : valid accuracy :94.47208405 with total prob : 98.71113586 \n",
      "27.663996696472168\n",
      "validation loss decreased , saving model (-0.94340369 ==> -0.94350443)\n",
      "Epoch 169 : Training loss 0.00004158 and valid loss : -0.94360376 :  \n",
      "Epoch 169 : valid accuracy :94.49714661 with total prob : 98.72168732 \n",
      "27.900468349456787\n",
      "validation loss decreased , saving model (-0.94350443 ==> -0.94360376)\n",
      "Epoch 170 : Training loss 0.00004142 and valid loss : -0.94370179 :  \n",
      "Epoch 170 : valid accuracy :94.54135132 with total prob : 98.73187256 \n",
      "27.73380422592163\n",
      "validation loss decreased , saving model (-0.94360376 ==> -0.94370179)\n",
      "Epoch 171 : Training loss 0.00004126 and valid loss : -0.94379866 :  \n",
      "Epoch 171 : valid accuracy :94.58852386 with total prob : 98.74173737 \n",
      "27.864299774169922\n",
      "validation loss decreased , saving model (-0.94370179 ==> -0.94379866)\n",
      "Epoch 172 : Training loss 0.00004110 and valid loss : -0.94389449 :  \n",
      "Epoch 172 : valid accuracy :94.63159180 with total prob : 98.75132751 \n",
      "27.45019841194153\n",
      "validation loss decreased , saving model (-0.94379866 ==> -0.94389449)\n",
      "Epoch 173 : Training loss 0.00004094 and valid loss : -0.94398946 :  \n",
      "Epoch 173 : valid accuracy :94.66326141 with total prob : 98.76055145 \n",
      "26.903618812561035\n",
      "validation loss decreased , saving model (-0.94389449 ==> -0.94398946)\n",
      "Epoch 174 : Training loss 0.00004078 and valid loss : -0.94408372 :  \n",
      "Epoch 174 : valid accuracy :94.72364807 with total prob : 98.76949310 \n",
      "27.12109112739563\n",
      "validation loss decreased , saving model (-0.94398946 ==> -0.94408372)\n",
      "Epoch 175 : Training loss 0.00004061 and valid loss : -0.94417747 :  \n",
      "Epoch 175 : valid accuracy :94.77560425 with total prob : 98.77833557 \n",
      "27.669894456863403\n",
      "validation loss decreased , saving model (-0.94408372 ==> -0.94417747)\n",
      "Epoch 176 : Training loss 0.00004045 and valid loss : -0.94427092 :  \n",
      "Epoch 176 : valid accuracy :94.80021667 with total prob : 98.78686523 \n",
      "29.42996096611023\n",
      "validation loss decreased , saving model (-0.94417747 ==> -0.94427092)\n",
      "Epoch 177 : Training loss 0.00004029 and valid loss : -0.94436428 :  \n",
      "Epoch 177 : valid accuracy :94.84327698 with total prob : 98.79508972 \n",
      "27.09030246734619\n",
      "validation loss decreased , saving model (-0.94427092 ==> -0.94436428)\n",
      "Epoch 178 : Training loss 0.00004013 and valid loss : -0.94445778 :  \n",
      "Epoch 178 : valid accuracy :94.88020325 with total prob : 98.80309296 \n",
      "27.393671989440918\n",
      "validation loss decreased , saving model (-0.94436428 ==> -0.94445778)\n",
      "Epoch 179 : Training loss 0.00003997 and valid loss : -0.94455168 :  \n",
      "Epoch 179 : valid accuracy :94.88885498 with total prob : 98.81076050 \n",
      "27.479036569595337\n",
      "validation loss decreased , saving model (-0.94445778 ==> -0.94455168)\n",
      "Epoch 180 : Training loss 0.00003981 and valid loss : -0.94464624 :  \n",
      "Epoch 180 : valid accuracy :94.89820099 with total prob : 98.81799316 \n",
      "27.58908200263977\n",
      "validation loss decreased , saving model (-0.94455168 ==> -0.94464624)\n",
      "Epoch 181 : Training loss 0.00003965 and valid loss : -0.94474173 :  \n",
      "Epoch 181 : valid accuracy :94.90708923 with total prob : 98.82482147 \n",
      "27.403684854507446\n",
      "validation loss decreased , saving model (-0.94464624 ==> -0.94474173)\n",
      "Epoch 182 : Training loss 0.00003949 and valid loss : -0.94483844 :  \n",
      "Epoch 182 : valid accuracy :94.91323853 with total prob : 98.83126831 \n",
      "27.924843311309814\n",
      "validation loss decreased , saving model (-0.94474173 ==> -0.94483844)\n",
      "Epoch 183 : Training loss 0.00003934 and valid loss : -0.94493665 :  \n",
      "Epoch 183 : valid accuracy :94.91733551 with total prob : 98.83726501 \n",
      "27.531874418258667\n",
      "validation loss decreased , saving model (-0.94483844 ==> -0.94493665)\n",
      "Epoch 184 : Training loss 0.00003919 and valid loss : -0.94503666 :  \n",
      "Epoch 184 : valid accuracy :94.92577362 with total prob : 98.84282684 \n",
      "41.870667457580566\n",
      "validation loss decreased , saving model (-0.94493665 ==> -0.94503666)\n",
      "Epoch 185 : Training loss 0.00003905 and valid loss : -0.94513875 :  \n",
      "Epoch 185 : valid accuracy :94.93101501 with total prob : 98.84803009 \n",
      "32.77998995780945\n",
      "validation loss decreased , saving model (-0.94503666 ==> -0.94513875)\n",
      "Epoch 186 : Training loss 0.00003891 and valid loss : -0.94524321 :  \n",
      "Epoch 186 : valid accuracy :94.94810486 with total prob : 98.85292053 \n",
      "28.270912170410156\n",
      "validation loss decreased , saving model (-0.94513875 ==> -0.94524321)\n",
      "Epoch 187 : Training loss 0.00003877 and valid loss : -0.94535031 :  \n",
      "Epoch 187 : valid accuracy :94.95448303 with total prob : 98.85750580 \n",
      "28.567963361740112\n",
      "validation loss decreased , saving model (-0.94524321 ==> -0.94535031)\n",
      "Epoch 188 : Training loss 0.00003864 and valid loss : -0.94546029 :  \n",
      "Epoch 188 : valid accuracy :94.96405029 with total prob : 98.86170959 \n",
      "28.28362727165222\n",
      "validation loss decreased , saving model (-0.94535031 ==> -0.94546029)\n",
      "Epoch 189 : Training loss 0.00003851 and valid loss : -0.94557338 :  \n",
      "Epoch 189 : valid accuracy :94.97613525 with total prob : 98.86566162 \n",
      "28.288306713104248\n",
      "validation loss decreased , saving model (-0.94546029 ==> -0.94557338)\n",
      "Epoch 190 : Training loss 0.00003839 and valid loss : -0.94568979 :  \n",
      "Epoch 190 : valid accuracy :94.98478699 with total prob : 98.86932373 \n",
      "28.437087535858154\n",
      "validation loss decreased , saving model (-0.94557338 ==> -0.94568979)\n",
      "Epoch 191 : Training loss 0.00003827 and valid loss : -0.94580967 :  \n",
      "Epoch 191 : valid accuracy :94.99914551 with total prob : 98.87274170 \n",
      "27.447011709213257\n",
      "validation loss decreased , saving model (-0.94568979 ==> -0.94580967)\n",
      "Epoch 192 : Training loss 0.00003816 and valid loss : -0.94593314 :  \n",
      "Epoch 192 : valid accuracy :95.00552368 with total prob : 98.87593079 \n",
      "27.894593000411987\n",
      "validation loss decreased , saving model (-0.94580967 ==> -0.94593314)\n",
      "Epoch 193 : Training loss 0.00003805 and valid loss : -0.94606026 :  \n",
      "Epoch 193 : valid accuracy :95.01623535 with total prob : 98.87882996 \n",
      "27.745678663253784\n",
      "validation loss decreased , saving model (-0.94593314 ==> -0.94606026)\n",
      "Epoch 194 : Training loss 0.00003795 and valid loss : -0.94619106 :  \n",
      "Epoch 194 : valid accuracy :95.02831268 with total prob : 98.88149261 \n",
      "27.82157850265503\n",
      "validation loss decreased , saving model (-0.94606026 ==> -0.94619106)\n",
      "Epoch 195 : Training loss 0.00003786 and valid loss : -0.94632548 :  \n",
      "Epoch 195 : valid accuracy :95.04654694 with total prob : 98.88393402 \n",
      "27.271721124649048\n",
      "validation loss decreased , saving model (-0.94619106 ==> -0.94632548)\n",
      "Epoch 196 : Training loss 0.00003776 and valid loss : -0.94646342 :  \n",
      "Epoch 196 : valid accuracy :95.06499481 with total prob : 98.88628387 \n",
      "27.85879898071289\n",
      "validation loss decreased , saving model (-0.94632548 ==> -0.94646342)\n",
      "Epoch 197 : Training loss 0.00003768 and valid loss : -0.94660470 :  \n",
      "Epoch 197 : valid accuracy :95.07958221 with total prob : 98.88857269 \n",
      "27.520692586898804\n",
      "validation loss decreased , saving model (-0.94646342 ==> -0.94660470)\n",
      "Epoch 198 : Training loss 0.00003760 and valid loss : -0.94674908 :  \n",
      "Epoch 198 : valid accuracy :95.08960724 with total prob : 98.89065552 \n",
      "27.37094736099243\n",
      "validation loss decreased , saving model (-0.94660470 ==> -0.94674908)\n",
      "Epoch 199 : Training loss 0.00003753 and valid loss : -0.94689625 :  \n",
      "Epoch 199 : valid accuracy :95.09918213 with total prob : 98.89238739 \n",
      "27.617467403411865\n",
      "validation loss decreased , saving model (-0.94674908 ==> -0.94689625)\n",
      "Epoch 200 : Training loss 0.00003746 and valid loss : -0.94704582 :  \n",
      "Epoch 200 : valid accuracy :95.11239624 with total prob : 98.89385223 \n",
      "27.64101243019104\n",
      "validation loss decreased , saving model (-0.94689625 ==> -0.94704582)\n",
      "Epoch 201 : Training loss 0.00003739 and valid loss : -0.94719736 :  \n",
      "Epoch 201 : valid accuracy :95.13017273 with total prob : 98.89508820 \n",
      "27.79626488685608\n",
      "validation loss decreased , saving model (-0.94704582 ==> -0.94719736)\n",
      "Epoch 202 : Training loss 0.00003734 and valid loss : -0.94735035 :  \n",
      "Epoch 202 : valid accuracy :95.15113831 with total prob : 98.89616394 \n",
      "27.956315755844116\n",
      "validation loss decreased , saving model (-0.94719736 ==> -0.94735035)\n",
      "Epoch 203 : Training loss 0.00003729 and valid loss : -0.94750425 :  \n",
      "Epoch 203 : valid accuracy :95.16709137 with total prob : 98.89735413 \n",
      "28.405097723007202\n",
      "validation loss decreased , saving model (-0.94735035 ==> -0.94750425)\n",
      "Epoch 204 : Training loss 0.00003724 and valid loss : -0.94765845 :  \n",
      "Epoch 204 : valid accuracy :95.19876099 with total prob : 98.89857483 \n",
      "29.09670901298523\n",
      "validation loss decreased , saving model (-0.94750425 ==> -0.94765845)\n",
      "Epoch 205 : Training loss 0.00003720 and valid loss : -0.94781232 :  \n",
      "Epoch 205 : valid accuracy :95.22747040 with total prob : 98.90015411 \n",
      "28.67967653274536\n",
      "validation loss decreased , saving model (-0.94765845 ==> -0.94781232)\n",
      "Epoch 206 : Training loss 0.00003717 and valid loss : -0.94796519 :  \n",
      "Epoch 206 : valid accuracy :95.25709534 with total prob : 98.90184784 \n",
      "36.18309020996094\n",
      "validation loss decreased , saving model (-0.94781232 ==> -0.94796519)\n",
      "Epoch 207 : Training loss 0.00003714 and valid loss : -0.94811637 :  \n",
      "Epoch 207 : valid accuracy :95.28512573 with total prob : 98.90348053 \n",
      "29.127591609954834\n",
      "validation loss decreased , saving model (-0.94796519 ==> -0.94811637)\n",
      "Epoch 208 : Training loss 0.00003712 and valid loss : -0.94826517 :  \n",
      "Epoch 208 : valid accuracy :95.30471802 with total prob : 98.90544128 \n",
      "29.15462613105774\n",
      "validation loss decreased , saving model (-0.94811637 ==> -0.94826517)\n",
      "Epoch 209 : Training loss 0.00003710 and valid loss : -0.94841087 :  \n",
      "Epoch 209 : valid accuracy :95.34960938 with total prob : 98.90776062 \n",
      "28.801634073257446\n",
      "validation loss decreased , saving model (-0.94826517 ==> -0.94841087)\n",
      "Epoch 210 : Training loss 0.00003709 and valid loss : -0.94855276 :  \n",
      "Epoch 210 : valid accuracy :95.37854767 with total prob : 98.91048431 \n",
      "28.4803466796875\n",
      "validation loss decreased , saving model (-0.94841087 ==> -0.94855276)\n",
      "Epoch 211 : Training loss 0.00003709 and valid loss : -0.94869011 :  \n",
      "Epoch 211 : valid accuracy :95.38515472 with total prob : 98.91297150 \n",
      "28.63459587097168\n",
      "validation loss decreased , saving model (-0.94855276 ==> -0.94869011)\n",
      "Epoch 212 : Training loss 0.00003709 and valid loss : -0.94882221 :  \n",
      "Epoch 212 : valid accuracy :95.38903046 with total prob : 98.91448975 \n",
      "28.27450203895569\n",
      "validation loss decreased , saving model (-0.94869011 ==> -0.94882221)\n",
      "Epoch 213 : Training loss 0.00003709 and valid loss : -0.94894833 :  \n",
      "Epoch 213 : valid accuracy :95.40293121 with total prob : 98.91505432 \n",
      "29.489673376083374\n",
      "validation loss decreased , saving model (-0.94882221 ==> -0.94894833)\n",
      "Epoch 214 : Training loss 0.00003710 and valid loss : -0.94906774 :  \n",
      "Epoch 214 : valid accuracy :95.40863037 with total prob : 98.91481781 \n",
      "29.137900829315186\n",
      "validation loss decreased , saving model (-0.94894833 ==> -0.94906774)\n",
      "Epoch 215 : Training loss 0.00003712 and valid loss : -0.94917974 :  \n",
      "Epoch 215 : valid accuracy :95.42024994 with total prob : 98.91362762 \n",
      "28.537559509277344\n",
      "validation loss decreased , saving model (-0.94906774 ==> -0.94917974)\n",
      "Epoch 216 : Training loss 0.00003713 and valid loss : -0.94928362 :  \n",
      "Epoch 216 : valid accuracy :95.43255615 with total prob : 98.91157532 \n",
      "27.687169790267944\n",
      "validation loss decreased , saving model (-0.94917974 ==> -0.94928362)\n",
      "Epoch 217 : Training loss 0.00003715 and valid loss : -0.94937873 :  \n",
      "Epoch 217 : valid accuracy :95.44371796 with total prob : 98.90852356 \n",
      "27.995238065719604\n",
      "validation loss decreased , saving model (-0.94928362 ==> -0.94937873)\n",
      "Epoch 218 : Training loss 0.00003718 and valid loss : -0.94946443 :  \n",
      "Epoch 218 : valid accuracy :95.45078278 with total prob : 98.90439606 \n",
      "27.222259521484375\n",
      "validation loss decreased , saving model (-0.94937873 ==> -0.94946443)\n",
      "Epoch 219 : Training loss 0.00003720 and valid loss : -0.94954015 :  \n",
      "Epoch 219 : valid accuracy :95.45465851 with total prob : 98.89911652 \n",
      "27.513432502746582\n",
      "validation loss decreased , saving model (-0.94946443 ==> -0.94954015)\n",
      "Epoch 220 : Training loss 0.00003723 and valid loss : -0.94960537 :  \n",
      "Epoch 220 : valid accuracy :95.45761871 with total prob : 98.89254761 \n",
      "27.779788732528687\n",
      "validation loss decreased , saving model (-0.94954015 ==> -0.94960537)\n",
      "Epoch 221 : Training loss 0.00003726 and valid loss : -0.94965964 :  \n",
      "Epoch 221 : valid accuracy :95.46537018 with total prob : 98.88459778 \n",
      "27.38598370552063\n",
      "validation loss decreased , saving model (-0.94960537 ==> -0.94965964)\n",
      "Epoch 222 : Training loss 0.00003729 and valid loss : -0.94970261 :  \n",
      "Epoch 222 : valid accuracy :95.48063660 with total prob : 98.87561035 \n",
      "27.4735906124115\n",
      "validation loss decreased , saving model (-0.94965964 ==> -0.94970261)\n",
      "Epoch 223 : Training loss 0.00003732 and valid loss : -0.94973398 :  \n",
      "Epoch 223 : valid accuracy :95.49157715 with total prob : 98.86537170 \n",
      "27.9864821434021\n",
      "validation loss decreased , saving model (-0.94970261 ==> -0.94973398)\n",
      "Epoch 224 : Training loss 0.00003735 and valid loss : -0.94975358 :  \n",
      "Epoch 224 : valid accuracy :95.49795532 with total prob : 98.85381317 \n",
      "27.1701819896698\n",
      "validation loss decreased , saving model (-0.94973398 ==> -0.94975358)\n",
      "Epoch 225 : Training loss 0.00003739 and valid loss : -0.94976129 :  \n",
      "Epoch 225 : valid accuracy :95.51436615 with total prob : 98.84115601 \n",
      "26.9077365398407\n",
      "validation loss decreased , saving model (-0.94975358 ==> -0.94976129)\n",
      "Epoch 226 : Training loss 0.00003742 and valid loss : -0.94975710 :  \n",
      "Epoch 226 : valid accuracy :95.51755524 with total prob : 98.82736206 \n",
      "26.82750153541565\n",
      "Epoch 227 : Training loss 0.00003746 and valid loss : -0.94974110 :  \n",
      "Epoch 227 : valid accuracy :95.52825928 with total prob : 98.81243134 \n",
      "28.412970304489136\n",
      "Epoch 228 : Training loss 0.00003750 and valid loss : -0.94971345 :  \n",
      "Epoch 228 : valid accuracy :95.54284668 with total prob : 98.79655457 \n",
      "33.489463090896606\n",
      "Epoch 229 : Training loss 0.00003754 and valid loss : -0.94967440 :  \n",
      "Epoch 229 : valid accuracy :95.56312561 with total prob : 98.77989197 \n",
      "27.3681480884552\n",
      "Epoch 230 : Training loss 0.00003758 and valid loss : -0.94962431 :  \n",
      "Epoch 230 : valid accuracy :95.58522797 with total prob : 98.76288605 \n",
      "27.48582673072815\n",
      "Epoch 231 : Training loss 0.00003762 and valid loss : -0.94956358 :  \n",
      "Epoch 231 : valid accuracy :95.59776306 with total prob : 98.74542999 \n",
      "26.92176127433777\n",
      "Epoch 232 : Training loss 0.00003766 and valid loss : -0.94949272 :  \n",
      "Epoch 232 : valid accuracy :95.61280060 with total prob : 98.72753906 \n",
      "26.605554342269897\n",
      "Epoch 233 : Training loss 0.00003770 and valid loss : -0.94941229 :  \n",
      "Epoch 233 : valid accuracy :95.63330841 with total prob : 98.70936584 \n",
      "27.202800035476685\n",
      "Epoch 234 : Training loss 0.00003775 and valid loss : -0.94932292 :  \n",
      "Epoch 234 : valid accuracy :95.64379120 with total prob : 98.69071198 \n",
      "27.3158061504364\n",
      "Epoch 235 : Training loss 0.00003779 and valid loss : -0.94922528 :  \n",
      "Epoch 235 : valid accuracy :95.66384888 with total prob : 98.67165375 \n",
      "26.983909845352173\n",
      "Epoch 236 : Training loss 0.00003784 and valid loss : -0.94912011 :  \n",
      "Epoch 236 : valid accuracy :95.68070984 with total prob : 98.65248871 \n",
      "26.913038730621338\n",
      "Epoch 237 : Training loss 0.00003789 and valid loss : -0.94900817 :  \n",
      "Epoch 237 : valid accuracy :95.71762085 with total prob : 98.63362885 \n",
      "27.149603366851807\n",
      "Epoch 238 : Training loss 0.00003793 and valid loss : -0.94889026 :  \n",
      "Epoch 238 : valid accuracy :95.77938080 with total prob : 98.61585999 \n",
      "26.61445188522339\n",
      "Epoch 239 : Training loss 0.00003798 and valid loss : -0.94876716 :  \n",
      "Epoch 239 : valid accuracy :95.85525513 with total prob : 98.59966278 \n",
      "26.74128818511963\n",
      "Epoch 240 : Training loss 0.00003803 and valid loss : -0.94863971 :  \n",
      "Epoch 240 : valid accuracy :95.88533783 with total prob : 98.58457947 \n",
      "26.898051023483276\n",
      "Epoch 241 : Training loss 0.00003808 and valid loss : -0.94850871 :  \n",
      "Epoch 241 : valid accuracy :95.25344849 with total prob : 98.58199310 \n",
      "26.595444202423096\n",
      "Epoch 242 : Training loss 0.00003813 and valid loss : -0.94837495 :  \n",
      "Epoch 242 : valid accuracy :94.56140137 with total prob : 98.60477448 \n",
      "27.01481342315674\n",
      "Epoch 243 : Training loss 0.00003819 and valid loss : -0.94823922 :  \n",
      "Epoch 243 : valid accuracy :94.45317078 with total prob : 98.64278412 \n",
      "26.953663110733032\n",
      "Epoch 244 : Training loss 0.00003824 and valid loss : -0.94810225 :  \n",
      "Epoch 244 : valid accuracy :94.45317078 with total prob : 98.68034363 \n",
      "26.748314142227173\n",
      "Epoch 245 : Training loss 0.00003829 and valid loss : -0.94796476 :  \n",
      "Epoch 245 : valid accuracy :94.45317078 with total prob : 98.71702576 \n",
      "27.26820659637451\n",
      "Epoch 246 : Training loss 0.00003834 and valid loss : -0.94782741 :  \n",
      "Epoch 246 : valid accuracy :94.45317078 with total prob : 98.75280762 \n",
      "26.692696809768677\n",
      "Epoch 247 : Training loss 0.00003840 and valid loss : -0.94769082 :  \n",
      "Epoch 247 : valid accuracy :94.45317078 with total prob : 98.78761292 \n",
      "26.56233811378479\n",
      "Epoch 248 : Training loss 0.00003845 and valid loss : -0.94755556 :  \n",
      "Epoch 248 : valid accuracy :94.45317078 with total prob : 98.82142639 \n",
      "27.37643599510193\n",
      "Epoch 249 : Training loss 0.00003851 and valid loss : -0.94742214 :  \n",
      "Epoch 249 : valid accuracy :94.45317078 with total prob : 98.85420990 \n",
      "27.305208921432495\n",
      "Epoch 250 : Training loss 0.00003856 and valid loss : -0.94729101 :  \n",
      "Epoch 250 : valid accuracy :94.45317078 with total prob : 98.88593292 \n",
      "34.880553007125854\n",
      "Epoch 251 : Training loss 0.00003862 and valid loss : -0.94716258 :  \n",
      "Epoch 251 : valid accuracy :94.45317078 with total prob : 98.91657257 \n",
      "26.944000482559204\n",
      "Epoch 252 : Training loss 0.00003867 and valid loss : -0.94703720 :  \n",
      "Epoch 252 : valid accuracy :94.45317078 with total prob : 98.94612122 \n",
      "26.710355758666992\n",
      "Epoch 253 : Training loss 0.00003873 and valid loss : -0.94691515 :  \n",
      "Epoch 253 : valid accuracy :94.45317078 with total prob : 98.97459412 \n",
      "29.059847354888916\n",
      "Epoch 254 : Training loss 0.00003878 and valid loss : -0.94679669 :  \n",
      "Epoch 254 : valid accuracy :94.45317078 with total prob : 99.00195312 \n",
      "27.079766988754272\n",
      "Epoch 255 : Training loss 0.00003884 and valid loss : -0.94668200 :  \n",
      "Epoch 255 : valid accuracy :94.45317078 with total prob : 99.02819824 \n",
      "26.70321273803711\n",
      "Epoch 256 : Training loss 0.00003890 and valid loss : -0.94657124 :  \n",
      "Epoch 256 : valid accuracy :94.45317078 with total prob : 99.05339050 \n",
      "27.117753505706787\n",
      "Epoch 257 : Training loss 0.00003895 and valid loss : -0.94646450 :  \n",
      "Epoch 257 : valid accuracy :94.45317078 with total prob : 99.07749176 \n",
      "27.054026126861572\n",
      "Epoch 258 : Training loss 0.00003901 and valid loss : -0.94636187 :  \n",
      "Epoch 258 : valid accuracy :94.45317078 with total prob : 99.10053253 \n",
      "27.060012340545654\n",
      "Epoch 259 : Training loss 0.00003907 and valid loss : -0.94626337 :  \n",
      "Epoch 259 : valid accuracy :94.45317078 with total prob : 99.12255096 \n",
      "26.769124746322632\n",
      "Epoch 260 : Training loss 0.00003912 and valid loss : -0.94616902 :  \n",
      "Epoch 260 : valid accuracy :94.45317078 with total prob : 99.14355469 \n",
      "26.952162265777588\n",
      "Epoch 261 : Training loss 0.00003918 and valid loss : -0.94607878 :  \n",
      "Epoch 261 : valid accuracy :94.45317078 with total prob : 99.16357422 \n",
      "26.76055121421814\n",
      "Epoch 262 : Training loss 0.00003924 and valid loss : -0.94599261 :  \n",
      "Epoch 262 : valid accuracy :94.45317078 with total prob : 99.18261719 \n",
      "26.59826636314392\n",
      "Epoch 263 : Training loss 0.00003929 and valid loss : -0.94591044 :  \n",
      "Epoch 263 : valid accuracy :94.45317078 with total prob : 99.20074463 \n",
      "27.067898511886597\n",
      "Epoch 264 : Training loss 0.00003935 and valid loss : -0.94583220 :  \n",
      "Epoch 264 : valid accuracy :94.44952393 with total prob : 99.21797180 \n",
      "26.29892659187317\n",
      "Epoch 265 : Training loss 0.00003940 and valid loss : -0.94575778 :  \n",
      "Epoch 265 : valid accuracy :94.44769287 with total prob : 99.23448944 \n",
      "27.53416109085083\n",
      "Epoch 266 : Training loss 0.00003946 and valid loss : -0.94568708 :  \n",
      "Epoch 266 : valid accuracy :94.46068573 with total prob : 99.25099182 \n",
      "27.441670656204224\n",
      "Epoch 267 : Training loss 0.00003952 and valid loss : -0.94561997 :  \n",
      "Epoch 267 : valid accuracy :94.46364594 with total prob : 99.26746368 \n",
      "26.859989404678345\n",
      "Epoch 268 : Training loss 0.00003957 and valid loss : -0.94555635 :  \n",
      "Epoch 268 : valid accuracy :94.45726776 with total prob : 99.28384399 \n",
      "26.804280519485474\n",
      "Epoch 269 : Training loss 0.00003963 and valid loss : -0.94549607 :  \n",
      "Epoch 269 : valid accuracy :94.46388245 with total prob : 99.30023193 \n",
      "27.44088912010193\n",
      "Epoch 270 : Training loss 0.00003968 and valid loss : -0.94543900 :  \n",
      "Epoch 270 : valid accuracy :94.47161865 with total prob : 99.31640625 \n",
      "26.835001707077026\n",
      "Epoch 271 : Training loss 0.00003974 and valid loss : -0.94538502 :  \n",
      "Epoch 271 : valid accuracy :94.48461914 with total prob : 99.33222198 \n",
      "26.81870126724243\n",
      "Epoch 272 : Training loss 0.00003979 and valid loss : -0.94533399 :  \n",
      "Epoch 272 : valid accuracy :94.48461914 with total prob : 99.34739685 \n",
      "34.00005578994751\n",
      "Epoch 273 : Training loss 0.00003984 and valid loss : -0.94528577 :  \n",
      "Epoch 273 : valid accuracy :94.48461914 with total prob : 99.36189270 \n",
      "32.05172896385193\n",
      "Epoch 274 : Training loss 0.00003990 and valid loss : -0.94524024 :  \n",
      "Epoch 274 : valid accuracy :94.48461914 with total prob : 99.37573242 \n",
      "26.966087341308594\n",
      "Epoch 275 : Training loss 0.00003995 and valid loss : -0.94519726 :  \n",
      "Epoch 275 : valid accuracy :94.48461914 with total prob : 99.38895416 \n",
      "26.85687756538391\n",
      "Epoch 276 : Training loss 0.00004000 and valid loss : -0.94515671 :  \n",
      "Epoch 276 : valid accuracy :94.48461914 with total prob : 99.40158844 \n",
      "27.315886735916138\n",
      "Epoch 277 : Training loss 0.00004006 and valid loss : -0.94511846 :  \n",
      "Epoch 277 : valid accuracy :94.48461914 with total prob : 99.41364288 \n",
      "26.90839123725891\n",
      "Epoch 278 : Training loss 0.00004011 and valid loss : -0.94508240 :  \n",
      "Epoch 278 : valid accuracy :94.48461914 with total prob : 99.42516327 \n",
      "27.617143869400024\n",
      "Epoch 279 : Training loss 0.00004016 and valid loss : -0.94504842 :  \n",
      "Epoch 279 : valid accuracy :94.48461914 with total prob : 99.43616486 \n",
      "27.282269954681396\n",
      "Epoch 280 : Training loss 0.00004021 and valid loss : -0.94501639 :  \n",
      "Epoch 280 : valid accuracy :94.48461914 with total prob : 99.44667053 \n",
      "26.98900318145752\n",
      "Epoch 281 : Training loss 0.00004026 and valid loss : -0.94498622 :  \n",
      "Epoch 281 : valid accuracy :94.48461914 with total prob : 99.45670319 \n",
      "27.314697265625\n",
      "Epoch 282 : Training loss 0.00004031 and valid loss : -0.94495781 :  \n",
      "Epoch 282 : valid accuracy :94.48461914 with total prob : 99.46628571 \n",
      "27.16029644012451\n",
      "Epoch 283 : Training loss 0.00004035 and valid loss : -0.94493105 :  \n",
      "Epoch 283 : valid accuracy :94.48461914 with total prob : 99.47544098 \n",
      "28.04384684562683\n",
      "Epoch 284 : Training loss 0.00004040 and valid loss : -0.94490586 :  \n",
      "Epoch 284 : valid accuracy :94.48461914 with total prob : 99.48416901 \n",
      "28.483730792999268\n",
      "Epoch 285 : Training loss 0.00004045 and valid loss : -0.94488215 :  \n",
      "Epoch 285 : valid accuracy :94.48461914 with total prob : 99.49252319 \n",
      "28.063104391098022\n",
      "Epoch 286 : Training loss 0.00004049 and valid loss : -0.94485983 :  \n",
      "Epoch 286 : valid accuracy :94.48461914 with total prob : 99.50049591 \n",
      "28.24785566329956\n",
      "Epoch 287 : Training loss 0.00004054 and valid loss : -0.94483883 :  \n",
      "Epoch 287 : valid accuracy :94.48461914 with total prob : 99.50810242 \n",
      "28.16342520713806\n",
      "Epoch 288 : Training loss 0.00004058 and valid loss : -0.94481907 :  \n",
      "Epoch 288 : valid accuracy :94.48461914 with total prob : 99.51538849 \n",
      "28.02361273765564\n",
      "Epoch 289 : Training loss 0.00004063 and valid loss : -0.94480049 :  \n",
      "Epoch 289 : valid accuracy :94.48461914 with total prob : 99.52233124 \n",
      "28.06391954421997\n",
      "Epoch 290 : Training loss 0.00004067 and valid loss : -0.94478301 :  \n",
      "Epoch 290 : valid accuracy :94.48461914 with total prob : 99.52895355 \n",
      "27.61141586303711\n",
      "Epoch 291 : Training loss 0.00004071 and valid loss : -0.94476658 :  \n",
      "Epoch 291 : valid accuracy :94.48461914 with total prob : 99.53528595 \n",
      "28.041183948516846\n",
      "Epoch 292 : Training loss 0.00004075 and valid loss : -0.94475113 :  \n",
      "Epoch 292 : valid accuracy :94.48461914 with total prob : 99.54135132 \n",
      "27.545021772384644\n",
      "Epoch 293 : Training loss 0.00004079 and valid loss : -0.94473662 :  \n",
      "Epoch 293 : valid accuracy :94.48461914 with total prob : 99.54711914 \n",
      "28.2472083568573\n",
      "Epoch 294 : Training loss 0.00004083 and valid loss : -0.94472298 :  \n",
      "Epoch 294 : valid accuracy :94.48461914 with total prob : 99.55265045 \n",
      "37.310160636901855\n",
      "Epoch 295 : Training loss 0.00004087 and valid loss : -0.94471018 :  \n",
      "Epoch 295 : valid accuracy :94.48461914 with total prob : 99.55791473 \n",
      "33.88415861129761\n",
      "Epoch 296 : Training loss 0.00004091 and valid loss : -0.94469817 :  \n",
      "Epoch 296 : valid accuracy :94.48461914 with total prob : 99.56294250 \n",
      "27.524815320968628\n",
      "Epoch 297 : Training loss 0.00004095 and valid loss : -0.94468691 :  \n",
      "Epoch 297 : valid accuracy :94.48461914 with total prob : 99.56775665 \n",
      "27.669504404067993\n",
      "Epoch 298 : Training loss 0.00004098 and valid loss : -0.94467635 :  \n",
      "Epoch 298 : valid accuracy :94.48461914 with total prob : 99.57234192 \n",
      "28.795006275177002\n",
      "Epoch 299 : Training loss 0.00004102 and valid loss : -0.94466646 :  \n",
      "Epoch 299 : valid accuracy :94.48461914 with total prob : 99.57672882 \n",
      "29.362902641296387\n",
      "Epoch 300 : Training loss 0.00004105 and valid loss : -0.94465720 :  \n",
      "Epoch 300 : valid accuracy :94.48461914 with total prob : 99.58090210 \n",
      "31.21557068824768\n",
      "Epoch 301 : Training loss 0.00004108 and valid loss : -0.94464856 :  \n",
      "Epoch 301 : valid accuracy :94.48461914 with total prob : 99.58490753 \n",
      "31.815876722335815\n",
      "Epoch 302 : Training loss 0.00004112 and valid loss : -0.94464049 :  \n",
      "Epoch 302 : valid accuracy :94.48461914 with total prob : 99.58872223 \n",
      "31.396173000335693\n",
      "Epoch 303 : Training loss 0.00004115 and valid loss : -0.94463296 :  \n",
      "Epoch 303 : valid accuracy :94.48461914 with total prob : 99.59234619 \n",
      "30.901169776916504\n",
      "Epoch 304 : Training loss 0.00004118 and valid loss : -0.94462596 :  \n",
      "Epoch 304 : valid accuracy :94.48461914 with total prob : 99.59579468 \n",
      "32.43171977996826\n",
      "Epoch 305 : Training loss 0.00004121 and valid loss : -0.94461946 :  \n",
      "Epoch 305 : valid accuracy :94.48461914 with total prob : 99.59911346 \n",
      "31.094300031661987\n",
      "Epoch 306 : Training loss 0.00004124 and valid loss : -0.94461344 :  \n",
      "Epoch 306 : valid accuracy :94.48461914 with total prob : 99.60224915 \n",
      "31.010518789291382\n",
      "Epoch 307 : Training loss 0.00004126 and valid loss : -0.94460787 :  \n",
      "Epoch 307 : valid accuracy :94.48461914 with total prob : 99.60525513 \n",
      "31.310463905334473\n",
      "Epoch 308 : Training loss 0.00004129 and valid loss : -0.94460275 :  \n",
      "Epoch 308 : valid accuracy :94.48461914 with total prob : 99.60810852 \n",
      "31.160365104675293\n",
      "Epoch 309 : Training loss 0.00004132 and valid loss : -0.94459804 :  \n",
      "Epoch 309 : valid accuracy :94.48461914 with total prob : 99.61082458 \n",
      "30.936188220977783\n",
      "Epoch 310 : Training loss 0.00004134 and valid loss : -0.94459375 :  \n",
      "Epoch 310 : valid accuracy :94.48461914 with total prob : 99.61340332 \n",
      "30.9962260723114\n",
      "Epoch 311 : Training loss 0.00004137 and valid loss : -0.94458984 :  \n",
      "Epoch 311 : valid accuracy :94.48461914 with total prob : 99.61585236 \n",
      "31.22289752960205\n",
      "Epoch 312 : Training loss 0.00004139 and valid loss : -0.94458631 :  \n",
      "Epoch 312 : valid accuracy :94.48461914 with total prob : 99.61817169 \n",
      "31.06923007965088\n",
      "Epoch 313 : Training loss 0.00004141 and valid loss : -0.94458315 :  \n",
      "Epoch 313 : valid accuracy :94.48461914 with total prob : 99.62036896 \n",
      "29.75054121017456\n",
      "Epoch 314 : Training loss 0.00004143 and valid loss : -0.94458035 :  \n",
      "Epoch 314 : valid accuracy :94.48461914 with total prob : 99.62245941 \n",
      "43.13528275489807\n",
      "Epoch 315 : Training loss 0.00004145 and valid loss : -0.94457788 :  \n",
      "Epoch 315 : valid accuracy :94.48461914 with total prob : 99.62442780 \n",
      "33.79103112220764\n",
      "Epoch 316 : Training loss 0.00004147 and valid loss : -0.94457576 :  \n",
      "Epoch 316 : valid accuracy :94.48461914 with total prob : 99.62628937 \n",
      "28.807804107666016\n",
      "Epoch 317 : Training loss 0.00004149 and valid loss : -0.94457395 :  \n",
      "Epoch 317 : valid accuracy :94.48461914 with total prob : 99.62804413 \n",
      "28.589218616485596\n",
      "Epoch 318 : Training loss 0.00004151 and valid loss : -0.94457247 :  \n",
      "Epoch 318 : valid accuracy :94.48461914 with total prob : 99.62968445 \n",
      "28.693063020706177\n",
      "Epoch 319 : Training loss 0.00004153 and valid loss : -0.94457130 :  \n",
      "Epoch 319 : valid accuracy :94.48461914 with total prob : 99.63123322 \n",
      "28.65574026107788\n",
      "Epoch 320 : Training loss 0.00004154 and valid loss : -0.94457043 :  \n",
      "Epoch 320 : valid accuracy :94.48461914 with total prob : 99.63267517 \n",
      "29.39793562889099\n",
      "Epoch 321 : Training loss 0.00004156 and valid loss : -0.94456986 :  \n",
      "Epoch 321 : valid accuracy :94.48461914 with total prob : 99.63402557 \n",
      "29.542040824890137\n",
      "Epoch 322 : Training loss 0.00004158 and valid loss : -0.94456958 :  \n",
      "Epoch 322 : valid accuracy :94.48461914 with total prob : 99.63526154 \n",
      "29.684988737106323\n",
      "Epoch 323 : Training loss 0.00004159 and valid loss : -0.94456959 :  \n",
      "Epoch 323 : valid accuracy :94.48461914 with total prob : 99.63642120 \n",
      "31.463262796401978\n",
      "Epoch 324 : Training loss 0.00004160 and valid loss : -0.94456988 :  \n",
      "Epoch 324 : valid accuracy :94.48461914 with total prob : 99.63748169 \n",
      "31.70674705505371\n",
      "Epoch 325 : Training loss 0.00004162 and valid loss : -0.94457045 :  \n",
      "Epoch 325 : valid accuracy :94.48461914 with total prob : 99.63845825 \n",
      "30.531450748443604\n",
      "Epoch 326 : Training loss 0.00004163 and valid loss : -0.94457130 :  \n",
      "Epoch 326 : valid accuracy :94.48461914 with total prob : 99.63933563 \n",
      "28.846681594848633\n",
      "Epoch 327 : Training loss 0.00004164 and valid loss : -0.94457242 :  \n",
      "Epoch 327 : valid accuracy :94.48461914 with total prob : 99.64012146 \n",
      "27.669798374176025\n",
      "Epoch 328 : Training loss 0.00004165 and valid loss : -0.94457381 :  \n",
      "Epoch 328 : valid accuracy :94.48461914 with total prob : 99.64083099 \n",
      "27.972105503082275\n",
      "Epoch 329 : Training loss 0.00004166 and valid loss : -0.94457546 :  \n",
      "Epoch 329 : valid accuracy :94.48461914 with total prob : 99.64144135 \n",
      "27.542635917663574\n",
      "Epoch 330 : Training loss 0.00004167 and valid loss : -0.94457738 :  \n",
      "Epoch 330 : valid accuracy :94.48461914 with total prob : 99.64196777 \n",
      "27.99668288230896\n",
      "Epoch 331 : Training loss 0.00004168 and valid loss : -0.94457956 :  \n",
      "Epoch 331 : valid accuracy :94.48461914 with total prob : 99.64241028 \n",
      "28.19023609161377\n",
      "Epoch 332 : Training loss 0.00004169 and valid loss : -0.94458200 :  \n",
      "Epoch 332 : valid accuracy :94.48461914 with total prob : 99.64276123 \n",
      "28.115344762802124\n",
      "Epoch 333 : Training loss 0.00004169 and valid loss : -0.94458470 :  \n",
      "Epoch 333 : valid accuracy :94.48461914 with total prob : 99.64303589 \n",
      "27.968904972076416\n",
      "Epoch 334 : Training loss 0.00004170 and valid loss : -0.94458766 :  \n",
      "Epoch 334 : valid accuracy :94.48461914 with total prob : 99.64321899 \n",
      "28.057230472564697\n",
      "Epoch 335 : Training loss 0.00004171 and valid loss : -0.94459087 :  \n",
      "Epoch 335 : valid accuracy :94.48461914 with total prob : 99.64331055 \n",
      "41.3880295753479\n",
      "Epoch 336 : Training loss 0.00004171 and valid loss : -0.94459434 :  \n",
      "Epoch 336 : valid accuracy :94.48461914 with total prob : 99.64332581 \n",
      "29.805047750473022\n",
      "Epoch 337 : Training loss 0.00004172 and valid loss : -0.94459807 :  \n",
      "Epoch 337 : valid accuracy :94.48461914 with total prob : 99.64325714 \n",
      "27.809852123260498\n",
      "Epoch 338 : Training loss 0.00004172 and valid loss : -0.94460205 :  \n",
      "Epoch 338 : valid accuracy :94.48461914 with total prob : 99.64308929 \n",
      "27.801246881484985\n",
      "Epoch 339 : Training loss 0.00004172 and valid loss : -0.94460629 :  \n",
      "Epoch 339 : valid accuracy :94.48461914 with total prob : 99.64284515 \n",
      "27.754448652267456\n",
      "Epoch 340 : Training loss 0.00004173 and valid loss : -0.94461078 :  \n",
      "Epoch 340 : valid accuracy :94.48461914 with total prob : 99.64249420 \n",
      "27.77018904685974\n",
      "Epoch 341 : Training loss 0.00004173 and valid loss : -0.94461553 :  \n",
      "Epoch 341 : valid accuracy :94.48461914 with total prob : 99.64207458 \n",
      "27.296833038330078\n",
      "Epoch 342 : Training loss 0.00004173 and valid loss : -0.94462053 :  \n",
      "Epoch 342 : valid accuracy :94.48461914 with total prob : 99.64156342 \n",
      "27.76676321029663\n",
      "Epoch 343 : Training loss 0.00004173 and valid loss : -0.94462579 :  \n",
      "Epoch 343 : valid accuracy :94.48461914 with total prob : 99.64096069 \n",
      "27.87802219390869\n",
      "Epoch 344 : Training loss 0.00004174 and valid loss : -0.94463131 :  \n",
      "Epoch 344 : valid accuracy :94.48461914 with total prob : 99.64025879 \n",
      "29.60333776473999\n",
      "Epoch 345 : Training loss 0.00004174 and valid loss : -0.94463708 :  \n",
      "Epoch 345 : valid accuracy :94.48461914 with total prob : 99.63946533 \n",
      "27.579196453094482\n",
      "Epoch 346 : Training loss 0.00004174 and valid loss : -0.94464311 :  \n",
      "Epoch 346 : valid accuracy :94.48461914 with total prob : 99.63858032 \n",
      "27.458658456802368\n",
      "Epoch 347 : Training loss 0.00004174 and valid loss : -0.94464940 :  \n",
      "Epoch 347 : valid accuracy :94.48461914 with total prob : 99.63759613 \n",
      "27.635765314102173\n",
      "Epoch 348 : Training loss 0.00004174 and valid loss : -0.94465595 :  \n",
      "Epoch 348 : valid accuracy :94.48461914 with total prob : 99.63652802 \n",
      "27.05003786087036\n",
      "Epoch 349 : Training loss 0.00004173 and valid loss : -0.94466275 :  \n",
      "Epoch 349 : valid accuracy :94.48461914 with total prob : 99.63535309 \n",
      "27.158275365829468\n",
      "Epoch 350 : Training loss 0.00004173 and valid loss : -0.94466982 :  \n",
      "Epoch 350 : valid accuracy :94.48461914 with total prob : 99.63407898 \n",
      "27.39499807357788\n",
      "Epoch 351 : Training loss 0.00004173 and valid loss : -0.94467716 :  \n",
      "Epoch 351 : valid accuracy :94.48461914 with total prob : 99.63269806 \n",
      "27.64469575881958\n",
      "Epoch 352 : Training loss 0.00004173 and valid loss : -0.94468475 :  \n",
      "Epoch 352 : valid accuracy :94.48461914 with total prob : 99.63121796 \n",
      "27.88808846473694\n",
      "Epoch 353 : Training loss 0.00004173 and valid loss : -0.94469262 :  \n",
      "Epoch 353 : valid accuracy :94.48461914 with total prob : 99.62963867 \n",
      "27.23305082321167\n",
      "Epoch 354 : Training loss 0.00004172 and valid loss : -0.94470074 :  \n",
      "Epoch 354 : valid accuracy :94.48461914 with total prob : 99.62794495 \n",
      "27.233364820480347\n",
      "Epoch 355 : Training loss 0.00004172 and valid loss : -0.94470914 :  \n",
      "Epoch 355 : valid accuracy :94.48461914 with total prob : 99.62614441 \n",
      "27.642381191253662\n",
      "Epoch 356 : Training loss 0.00004172 and valid loss : -0.94471781 :  \n",
      "Epoch 356 : valid accuracy :94.48461914 with total prob : 99.62423706 \n",
      "27.805362462997437\n",
      "Epoch 357 : Training loss 0.00004171 and valid loss : -0.94472674 :  \n",
      "Epoch 357 : valid accuracy :94.48461914 with total prob : 99.62220001 \n",
      "40.06386685371399\n",
      "Epoch 358 : Training loss 0.00004171 and valid loss : -0.94473595 :  \n",
      "Epoch 358 : valid accuracy :94.48461914 with total prob : 99.62007141 \n",
      "29.2680184841156\n",
      "Epoch 359 : Training loss 0.00004170 and valid loss : -0.94474543 :  \n",
      "Epoch 359 : valid accuracy :94.48461914 with total prob : 99.61780548 \n",
      "28.418142080307007\n",
      "Epoch 360 : Training loss 0.00004170 and valid loss : -0.94475518 :  \n",
      "Epoch 360 : valid accuracy :94.48461914 with total prob : 99.61542511 \n",
      "28.144206047058105\n",
      "Epoch 361 : Training loss 0.00004169 and valid loss : -0.94476521 :  \n",
      "Epoch 361 : valid accuracy :94.48461914 with total prob : 99.61292267 \n",
      "28.06258749961853\n",
      "Epoch 362 : Training loss 0.00004169 and valid loss : -0.94477551 :  \n",
      "Epoch 362 : valid accuracy :94.48461914 with total prob : 99.61028290 \n",
      "28.012047290802002\n",
      "Epoch 363 : Training loss 0.00004168 and valid loss : -0.94478608 :  \n",
      "Epoch 363 : valid accuracy :94.48461914 with total prob : 99.60751343 \n",
      "27.873692512512207\n",
      "Epoch 364 : Training loss 0.00004167 and valid loss : -0.94479693 :  \n",
      "Epoch 364 : valid accuracy :94.48461914 with total prob : 99.60461426 \n",
      "27.734745502471924\n",
      "Epoch 365 : Training loss 0.00004167 and valid loss : -0.94480806 :  \n",
      "Epoch 365 : valid accuracy :94.48461914 with total prob : 99.60159302 \n",
      "27.78678035736084\n",
      "Epoch 366 : Training loss 0.00004166 and valid loss : -0.94481946 :  \n",
      "Epoch 366 : valid accuracy :94.48461914 with total prob : 99.59841919 \n",
      "27.25258207321167\n",
      "Epoch 367 : Training loss 0.00004165 and valid loss : -0.94483114 :  \n",
      "Epoch 367 : valid accuracy :94.48461914 with total prob : 99.59511566 \n",
      "27.116662740707397\n",
      "Epoch 368 : Training loss 0.00004164 and valid loss : -0.94484309 :  \n",
      "Epoch 368 : valid accuracy :94.48461914 with total prob : 99.59165192 \n",
      "27.48251175880432\n",
      "Epoch 369 : Training loss 0.00004164 and valid loss : -0.94485532 :  \n",
      "Epoch 369 : valid accuracy :94.48461914 with total prob : 99.58805847 \n",
      "27.31441307067871\n",
      "Epoch 370 : Training loss 0.00004163 and valid loss : -0.94486781 :  \n",
      "Epoch 370 : valid accuracy :94.48461914 with total prob : 99.58429718 \n",
      "30.402594804763794\n",
      "Epoch 371 : Training loss 0.00004162 and valid loss : -0.94488058 :  \n",
      "Epoch 371 : valid accuracy :94.48461914 with total prob : 99.58039093 \n",
      "27.08324432373047\n",
      "Epoch 372 : Training loss 0.00004161 and valid loss : -0.94489361 :  \n",
      "Epoch 372 : valid accuracy :94.48461914 with total prob : 99.57631683 \n",
      "28.211486101150513\n",
      "Epoch 373 : Training loss 0.00004160 and valid loss : -0.94490691 :  \n",
      "Epoch 373 : valid accuracy :94.48461914 with total prob : 99.57208252 \n",
      "27.952680826187134\n",
      "Epoch 374 : Training loss 0.00004159 and valid loss : -0.94492047 :  \n",
      "Epoch 374 : valid accuracy :94.48461914 with total prob : 99.56768799 \n",
      "27.572924375534058\n",
      "Epoch 375 : Training loss 0.00004159 and valid loss : -0.94493429 :  \n",
      "Epoch 375 : valid accuracy :94.48461914 with total prob : 99.56312561 \n",
      "27.548636436462402\n",
      "Epoch 376 : Training loss 0.00004158 and valid loss : -0.94494836 :  \n",
      "Epoch 376 : valid accuracy :94.48461914 with total prob : 99.55837250 \n",
      "27.820192575454712\n",
      "Epoch 377 : Training loss 0.00004157 and valid loss : -0.94496267 :  \n",
      "Epoch 377 : valid accuracy :94.48461914 with total prob : 99.55346680 \n",
      "27.859471797943115\n",
      "Epoch 378 : Training loss 0.00004156 and valid loss : -0.94497723 :  \n",
      "Epoch 378 : valid accuracy :94.48461914 with total prob : 99.54835510 \n",
      "27.758633375167847\n",
      "Epoch 379 : Training loss 0.00004155 and valid loss : -0.94499203 :  \n",
      "Epoch 379 : valid accuracy :94.48461914 with total prob : 99.54307556 \n",
      "38.35720419883728\n",
      "Epoch 380 : Training loss 0.00004154 and valid loss : -0.94500704 :  \n",
      "Epoch 380 : valid accuracy :94.48461914 with total prob : 99.53759766 \n",
      "27.552287101745605\n",
      "Epoch 381 : Training loss 0.00004153 and valid loss : -0.94502228 :  \n",
      "Epoch 381 : valid accuracy :94.48461914 with total prob : 99.53193665 \n",
      "27.57062005996704\n",
      "Epoch 382 : Training loss 0.00004152 and valid loss : -0.94503773 :  \n",
      "Epoch 382 : valid accuracy :94.48461914 with total prob : 99.52606964 \n",
      "27.05336308479309\n",
      "Epoch 383 : Training loss 0.00004151 and valid loss : -0.94505338 :  \n",
      "Epoch 383 : valid accuracy :94.48461914 with total prob : 99.52000427 \n",
      "27.869364976882935\n",
      "Epoch 384 : Training loss 0.00004150 and valid loss : -0.94506921 :  \n",
      "Epoch 384 : valid accuracy :94.48461914 with total prob : 99.51371765 \n",
      "27.739054203033447\n",
      "Epoch 385 : Training loss 0.00004149 and valid loss : -0.94508522 :  \n",
      "Epoch 385 : valid accuracy :94.48461914 with total prob : 99.50724030 \n",
      "27.506804943084717\n",
      "Epoch 386 : Training loss 0.00004147 and valid loss : -0.94510139 :  \n",
      "Epoch 386 : valid accuracy :94.48461914 with total prob : 99.50054932 \n",
      "27.218414068222046\n",
      "Epoch 387 : Training loss 0.00004146 and valid loss : -0.94511771 :  \n",
      "Epoch 387 : valid accuracy :94.48461914 with total prob : 99.49363708 \n",
      "26.90583062171936\n",
      "Epoch 388 : Training loss 0.00004145 and valid loss : -0.94513416 :  \n",
      "Epoch 388 : valid accuracy :94.48461914 with total prob : 99.48650360 \n",
      "27.41051483154297\n",
      "Epoch 389 : Training loss 0.00004144 and valid loss : -0.94515072 :  \n",
      "Epoch 389 : valid accuracy :94.48461914 with total prob : 99.47914124 \n",
      "27.721015214920044\n",
      "Epoch 390 : Training loss 0.00004143 and valid loss : -0.94516738 :  \n",
      "Epoch 390 : valid accuracy :94.48461914 with total prob : 99.47154999 \n",
      "27.867249011993408\n",
      "Epoch 391 : Training loss 0.00004142 and valid loss : -0.94518412 :  \n",
      "Epoch 391 : valid accuracy :94.48461914 with total prob : 99.46372223 \n",
      "27.704894304275513\n",
      "Epoch 392 : Training loss 0.00004141 and valid loss : -0.94520091 :  \n",
      "Epoch 392 : valid accuracy :94.48461914 with total prob : 99.45565796 \n",
      "27.676924228668213\n",
      "Epoch 393 : Training loss 0.00004139 and valid loss : -0.94521774 :  \n",
      "Epoch 393 : valid accuracy :94.48461914 with total prob : 99.44734955 \n",
      "27.510477781295776\n",
      "Epoch 394 : Training loss 0.00004138 and valid loss : -0.94523458 :  \n",
      "Epoch 394 : valid accuracy :94.48461914 with total prob : 99.43879700 \n",
      "27.500550270080566\n",
      "Epoch 395 : Training loss 0.00004137 and valid loss : -0.94525140 :  \n",
      "Epoch 395 : valid accuracy :94.48461914 with total prob : 99.42999268 \n",
      "27.295066118240356\n",
      "Epoch 396 : Training loss 0.00004136 and valid loss : -0.94526818 :  \n",
      "Epoch 396 : valid accuracy :94.48461914 with total prob : 99.42093658 \n",
      "27.718523740768433\n",
      "Epoch 397 : Training loss 0.00004135 and valid loss : -0.94528489 :  \n",
      "Epoch 397 : valid accuracy :94.48461914 with total prob : 99.41160583 \n",
      "27.063511610031128\n",
      "Epoch 398 : Training loss 0.00004133 and valid loss : -0.94530151 :  \n",
      "Epoch 398 : valid accuracy :94.48461914 with total prob : 99.40203857 \n",
      "27.310593366622925\n",
      "Epoch 399 : Training loss 0.00004132 and valid loss : -0.94531800 :  \n",
      "Epoch 399 : valid accuracy :94.48461914 with total prob : 99.39220428 \n",
      "27.19136381149292\n",
      "Epoch 400 : Training loss 0.00004131 and valid loss : -0.94533432 :  \n",
      "Epoch 400 : valid accuracy :94.48461914 with total prob : 99.38210297 \n",
      "27.528502225875854\n",
      "Epoch 401 : Training loss 0.00004130 and valid loss : -0.94535045 :  \n",
      "Epoch 401 : valid accuracy :94.48461914 with total prob : 99.37171936 \n",
      "27.02002453804016\n",
      "Epoch 402 : Training loss 0.00004129 and valid loss : -0.94536635 :  \n",
      "Epoch 402 : valid accuracy :94.48461914 with total prob : 99.36107635 \n",
      "27.697389364242554\n",
      "Epoch 403 : Training loss 0.00004127 and valid loss : -0.94538199 :  \n",
      "Epoch 403 : valid accuracy :94.48461914 with total prob : 99.35014343 \n",
      "27.12485647201538\n",
      "Epoch 404 : Training loss 0.00004126 and valid loss : -0.94539732 :  \n",
      "Epoch 404 : valid accuracy :94.48461914 with total prob : 99.33892822 \n",
      "28.12067675590515\n",
      "Epoch 405 : Training loss 0.00004125 and valid loss : -0.94541231 :  \n",
      "Epoch 405 : valid accuracy :94.48461914 with total prob : 99.32746124 \n",
      "27.787041664123535\n",
      "Epoch 406 : Training loss 0.00004124 and valid loss : -0.94542692 :  \n",
      "Epoch 406 : valid accuracy :94.48461914 with total prob : 99.31569672 \n",
      "27.951444149017334\n",
      "Epoch 407 : Training loss 0.00004122 and valid loss : -0.94544111 :  \n",
      "Epoch 407 : valid accuracy :94.48461914 with total prob : 99.30363464 \n",
      "27.576775550842285\n",
      "Epoch 408 : Training loss 0.00004121 and valid loss : -0.94545483 :  \n",
      "Epoch 408 : valid accuracy :94.48461914 with total prob : 99.29129791 \n",
      "27.944228172302246\n",
      "Epoch 409 : Training loss 0.00004120 and valid loss : -0.94546805 :  \n",
      "Epoch 409 : valid accuracy :94.48461914 with total prob : 99.27865601 \n",
      "27.81866955757141\n",
      "Epoch 410 : Training loss 0.00004119 and valid loss : -0.94548071 :  \n",
      "Epoch 410 : valid accuracy :94.48461914 with total prob : 99.26574707 \n",
      "27.41702389717102\n",
      "Epoch 411 : Training loss 0.00004117 and valid loss : -0.94549278 :  \n",
      "Epoch 411 : valid accuracy :94.48461914 with total prob : 99.25254059 \n",
      "40.821521043777466\n",
      "Epoch 412 : Training loss 0.00004116 and valid loss : -0.94550420 :  \n",
      "Epoch 412 : valid accuracy :94.48461914 with total prob : 99.23903656 \n",
      "31.76790761947632\n",
      "Epoch 413 : Training loss 0.00004115 and valid loss : -0.94551494 :  \n",
      "Epoch 413 : valid accuracy :94.48461914 with total prob : 99.22525024 \n",
      "27.41260528564453\n",
      "Epoch 414 : Training loss 0.00004113 and valid loss : -0.94552494 :  \n",
      "Epoch 414 : valid accuracy :94.48461914 with total prob : 99.21116638 \n",
      "27.52647876739502\n",
      "Epoch 415 : Training loss 0.00004112 and valid loss : -0.94553416 :  \n",
      "Epoch 415 : valid accuracy :94.48461914 with total prob : 99.19680023 \n",
      "27.701170206069946\n",
      "Epoch 416 : Training loss 0.00004111 and valid loss : -0.94554255 :  \n",
      "Epoch 416 : valid accuracy :94.48461914 with total prob : 99.18212891 \n",
      "27.736586809158325\n",
      "Epoch 417 : Training loss 0.00004110 and valid loss : -0.94555007 :  \n",
      "Epoch 417 : valid accuracy :94.48461914 with total prob : 99.16717529 \n",
      "27.348604917526245\n",
      "Epoch 418 : Training loss 0.00004108 and valid loss : -0.94555667 :  \n",
      "Epoch 418 : valid accuracy :94.48461914 with total prob : 99.15192413 \n",
      "26.986480951309204\n",
      "Epoch 419 : Training loss 0.00004107 and valid loss : -0.94556230 :  \n",
      "Epoch 419 : valid accuracy :94.48461914 with total prob : 99.13640594 \n",
      "28.03618359565735\n",
      "Epoch 420 : Training loss 0.00004106 and valid loss : -0.94556692 :  \n",
      "Epoch 420 : valid accuracy :94.48461914 with total prob : 99.12059784 \n",
      "27.634625673294067\n",
      "Epoch 421 : Training loss 0.00004105 and valid loss : -0.94557049 :  \n",
      "Epoch 421 : valid accuracy :94.48461914 with total prob : 99.10449219 \n",
      "27.46352458000183\n",
      "Epoch 422 : Training loss 0.00004104 and valid loss : -0.94557296 :  \n",
      "Epoch 422 : valid accuracy :94.48461914 with total prob : 99.08811951 \n",
      "27.891167163848877\n",
      "Epoch 423 : Training loss 0.00004102 and valid loss : -0.94557428 :  \n",
      "Epoch 423 : valid accuracy :94.48461914 with total prob : 99.07146454 \n",
      "27.620230197906494\n",
      "Epoch 424 : Training loss 0.00004101 and valid loss : -0.94557443 :  \n",
      "Epoch 424 : valid accuracy :94.48461914 with total prob : 99.05454254 \n",
      "27.737027645111084\n",
      "Epoch 425 : Training loss 0.00004100 and valid loss : -0.94557335 :  \n",
      "Epoch 425 : valid accuracy :94.48461914 with total prob : 99.03733826 \n",
      "27.654362440109253\n",
      "Epoch 426 : Training loss 0.00004099 and valid loss : -0.94557102 :  \n",
      "Epoch 426 : valid accuracy :94.51127625 with total prob : 99.02007294 \n",
      "27.150268077850342\n",
      "Epoch 427 : Training loss 0.00004097 and valid loss : -0.94556739 :  \n",
      "Epoch 427 : valid accuracy :94.54363251 with total prob : 99.00309753 \n",
      "27.691431045532227\n",
      "Epoch 428 : Training loss 0.00004096 and valid loss : -0.94556243 :  \n",
      "Epoch 428 : valid accuracy :94.59148407 with total prob : 98.98658752 \n",
      "27.55895757675171\n",
      "Epoch 429 : Training loss 0.00004095 and valid loss : -0.94555611 :  \n",
      "Epoch 429 : valid accuracy :94.63318634 with total prob : 98.97064972 \n",
      "27.30826711654663\n",
      "Epoch 430 : Training loss 0.00004094 and valid loss : -0.94554841 :  \n",
      "Epoch 430 : valid accuracy :94.66508484 with total prob : 98.95505524 \n",
      "28.098469734191895\n",
      "Epoch 431 : Training loss 0.00004093 and valid loss : -0.94553929 :  \n",
      "Epoch 431 : valid accuracy :94.69676208 with total prob : 98.93974304 \n",
      "28.013462781906128\n",
      "Epoch 432 : Training loss 0.00004091 and valid loss : -0.94552873 :  \n",
      "Epoch 432 : valid accuracy :94.73618317 with total prob : 98.92471313 \n",
      "27.35114550590515\n",
      "Epoch 433 : Training loss 0.00004090 and valid loss : -0.94551672 :  \n",
      "Epoch 433 : valid accuracy :94.76853943 with total prob : 98.91003418 \n",
      "42.310200691223145\n",
      "Epoch 434 : Training loss 0.00004089 and valid loss : -0.94550324 :  \n",
      "Epoch 434 : valid accuracy :94.78631592 with total prob : 98.89553833 \n",
      "28.895963191986084\n",
      "Epoch 435 : Training loss 0.00004088 and valid loss : -0.94548827 :  \n",
      "Epoch 435 : valid accuracy :94.81661987 with total prob : 98.88113403 \n",
      "27.434317588806152\n",
      "Epoch 436 : Training loss 0.00004087 and valid loss : -0.94547180 :  \n",
      "Epoch 436 : valid accuracy :94.82710266 with total prob : 98.86686707 \n",
      "27.59020185470581\n",
      "Epoch 437 : Training loss 0.00004086 and valid loss : -0.94545384 :  \n",
      "Epoch 437 : valid accuracy :94.84875488 with total prob : 98.85258484 \n",
      "27.757378816604614\n",
      "Epoch 438 : Training loss 0.00004085 and valid loss : -0.94543436 :  \n",
      "Epoch 438 : valid accuracy :94.85741425 with total prob : 98.83834076 \n",
      "28.43564796447754\n",
      "Epoch 439 : Training loss 0.00004084 and valid loss : -0.94541338 :  \n",
      "Epoch 439 : valid accuracy :94.87495422 with total prob : 98.82405853 \n",
      "29.213265419006348\n",
      "Epoch 440 : Training loss 0.00004082 and valid loss : -0.94539090 :  \n",
      "Epoch 440 : valid accuracy :94.89181519 with total prob : 98.80983734 \n",
      "28.98287057876587\n",
      "Epoch 441 : Training loss 0.00004081 and valid loss : -0.94536692 :  \n",
      "Epoch 441 : valid accuracy :94.92417908 with total prob : 98.79566193 \n",
      "28.383912801742554\n",
      "Epoch 442 : Training loss 0.00004080 and valid loss : -0.94534147 :  \n",
      "Epoch 442 : valid accuracy :94.94149780 with total prob : 98.78171539 \n",
      "28.33261203765869\n",
      "Epoch 443 : Training loss 0.00004079 and valid loss : -0.94531455 :  \n",
      "Epoch 443 : valid accuracy :94.96109009 with total prob : 98.76777649 \n",
      "28.314152240753174\n",
      "Epoch 444 : Training loss 0.00004078 and valid loss : -0.94528618 :  \n",
      "Epoch 444 : valid accuracy :94.97817993 with total prob : 98.75393677 \n",
      "27.60589098930359\n",
      "Epoch 445 : Training loss 0.00004077 and valid loss : -0.94525639 :  \n",
      "Epoch 445 : valid accuracy :94.99481201 with total prob : 98.74011993 \n",
      "28.27348518371582\n",
      "Epoch 446 : Training loss 0.00004076 and valid loss : -0.94522521 :  \n",
      "Epoch 446 : valid accuracy :95.01988220 with total prob : 98.72640228 \n",
      "31.264735460281372\n",
      "Epoch 447 : Training loss 0.00004075 and valid loss : -0.94519266 :  \n",
      "Epoch 447 : valid accuracy :95.06978607 with total prob : 98.71296692 \n",
      "27.709169387817383\n",
      "Epoch 448 : Training loss 0.00004074 and valid loss : -0.94515879 :  \n",
      "Epoch 448 : valid accuracy :95.11923218 with total prob : 98.70025635 \n",
      "28.2897207736969\n",
      "Epoch 449 : Training loss 0.00004073 and valid loss : -0.94512361 :  \n",
      "Epoch 449 : valid accuracy :95.16754150 with total prob : 98.68819427 \n",
      "27.94192147254944\n",
      "Epoch 450 : Training loss 0.00004072 and valid loss : -0.94508719 :  \n",
      "Epoch 450 : valid accuracy :95.20491028 with total prob : 98.67663574 \n",
      "27.576014280319214\n",
      "Epoch 451 : Training loss 0.00004071 and valid loss : -0.94504956 :  \n",
      "Epoch 451 : valid accuracy :95.24684143 with total prob : 98.66541290 \n",
      "28.291531562805176\n",
      "Epoch 452 : Training loss 0.00004070 and valid loss : -0.94501076 :  \n",
      "Epoch 452 : valid accuracy :95.28831482 with total prob : 98.65474701 \n",
      "27.614497661590576\n",
      "Epoch 453 : Training loss 0.00004069 and valid loss : -0.94497085 :  \n",
      "Epoch 453 : valid accuracy :95.32750702 with total prob : 98.64451599 \n",
      "27.469660997390747\n",
      "Epoch 454 : Training loss 0.00004068 and valid loss : -0.94492988 :  \n",
      "Epoch 454 : valid accuracy :95.35029602 with total prob : 98.63456726 \n",
      "28.015515089035034\n",
      "Epoch 455 : Training loss 0.00004067 and valid loss : -0.94488790 :  \n",
      "Epoch 455 : valid accuracy :95.37467957 with total prob : 98.62492371 \n",
      "42.10678720474243\n",
      "Epoch 456 : Training loss 0.00004066 and valid loss : -0.94484497 :  \n",
      "Epoch 456 : valid accuracy :95.41068268 with total prob : 98.61566162 \n",
      "27.606194972991943\n",
      "Epoch 457 : Training loss 0.00004065 and valid loss : -0.94480114 :  \n",
      "Epoch 457 : valid accuracy :95.45876312 with total prob : 98.60688782 \n",
      "28.091607809066772\n",
      "Epoch 458 : Training loss 0.00004064 and valid loss : -0.94475649 :  \n",
      "Epoch 458 : valid accuracy :95.47539520 with total prob : 98.59835815 \n",
      "28.450812578201294\n",
      "Epoch 459 : Training loss 0.00004063 and valid loss : -0.94471106 :  \n",
      "Epoch 459 : valid accuracy :95.48542023 with total prob : 98.58992004 \n",
      "28.239036798477173\n",
      "Epoch 460 : Training loss 0.00004062 and valid loss : -0.94466492 :  \n",
      "Epoch 460 : valid accuracy :95.51185608 with total prob : 98.58171844 \n",
      "28.589812755584717\n",
      "Epoch 461 : Training loss 0.00004061 and valid loss : -0.94461813 :  \n",
      "Epoch 461 : valid accuracy :95.52621460 with total prob : 98.57369995 \n",
      "27.86052370071411\n",
      "Epoch 462 : Training loss 0.00004060 and valid loss : -0.94457076 :  \n",
      "Epoch 462 : valid accuracy :95.54421234 with total prob : 98.56588745 \n",
      "27.75190782546997\n",
      "Epoch 463 : Training loss 0.00004059 and valid loss : -0.94452288 :  \n",
      "Epoch 463 : valid accuracy :94.13460541 with total prob : 98.56805420 \n",
      "27.880706787109375\n",
      "Epoch 464 : Training loss 0.00004059 and valid loss : -0.94447454 :  \n",
      "Epoch 464 : valid accuracy :94.08470154 with total prob : 98.58583069 \n",
      "27.23832106590271\n",
      "Epoch 465 : Training loss 0.00004058 and valid loss : -0.94442581 :  \n",
      "Epoch 465 : valid accuracy :94.09563446 with total prob : 98.60418701 \n",
      "27.798940658569336\n",
      "Epoch 466 : Training loss 0.00004057 and valid loss : -0.94437676 :  \n",
      "Epoch 466 : valid accuracy :94.11796570 with total prob : 98.62274170 \n",
      "27.625258684158325\n",
      "Epoch 467 : Training loss 0.00004056 and valid loss : -0.94432744 :  \n",
      "Epoch 467 : valid accuracy :94.13916016 with total prob : 98.64143372 \n",
      "27.459272623062134\n",
      "Epoch 468 : Training loss 0.00004055 and valid loss : -0.94427794 :  \n",
      "Epoch 468 : valid accuracy :94.15898132 with total prob : 98.66023254 \n",
      "27.505717754364014\n",
      "Epoch 469 : Training loss 0.00004054 and valid loss : -0.94422829 :  \n",
      "Epoch 469 : valid accuracy :94.17106628 with total prob : 98.67907715 \n",
      "27.578799962997437\n",
      "Epoch 470 : Training loss 0.00004053 and valid loss : -0.94417858 :  \n",
      "Epoch 470 : valid accuracy :94.18132019 with total prob : 98.69788361 \n",
      "28.199586153030396\n",
      "Epoch 471 : Training loss 0.00004053 and valid loss : -0.94412885 :  \n",
      "Epoch 471 : valid accuracy :94.19134521 with total prob : 98.71661377 \n",
      "28.23060154914856\n",
      "Epoch 472 : Training loss 0.00004052 and valid loss : -0.94407916 :  \n",
      "Epoch 472 : valid accuracy :94.20592499 with total prob : 98.73529816 \n",
      "28.184361696243286\n",
      "Epoch 473 : Training loss 0.00004051 and valid loss : -0.94402958 :  \n",
      "Epoch 473 : valid accuracy :94.21435547 with total prob : 98.75392914 \n",
      "27.490286588668823\n",
      "Epoch 474 : Training loss 0.00004050 and valid loss : -0.94398015 :  \n",
      "Epoch 474 : valid accuracy :94.22598267 with total prob : 98.77249146 \n",
      "28.180668354034424\n",
      "Epoch 475 : Training loss 0.00004049 and valid loss : -0.94393094 :  \n",
      "Epoch 475 : valid accuracy :94.23783112 with total prob : 98.79094696 \n",
      "27.25822949409485\n",
      "Epoch 476 : Training loss 0.00004049 and valid loss : -0.94388199 :  \n",
      "Epoch 476 : valid accuracy :94.24306488 with total prob : 98.80928802 \n",
      "27.410266160964966\n",
      "Epoch 477 : Training loss 0.00004048 and valid loss : -0.94383335 :  \n",
      "Epoch 477 : valid accuracy :94.25081635 with total prob : 98.82750702 \n",
      "26.96728205680847\n",
      "Epoch 478 : Training loss 0.00004047 and valid loss : -0.94378507 :  \n",
      "Epoch 478 : valid accuracy :94.25355530 with total prob : 98.84553528 \n",
      "28.451246738433838\n",
      "Epoch 479 : Training loss 0.00004046 and valid loss : -0.94373720 :  \n",
      "Epoch 479 : valid accuracy :94.26129913 with total prob : 98.86336517 \n",
      "27.108250379562378\n",
      "Epoch 480 : Training loss 0.00004045 and valid loss : -0.94368977 :  \n",
      "Epoch 480 : valid accuracy :94.26744843 with total prob : 98.88105011 \n",
      "27.53545641899109\n",
      "Epoch 481 : Training loss 0.00004045 and valid loss : -0.94364283 :  \n",
      "Epoch 481 : valid accuracy :94.27519989 with total prob : 98.89855957 \n",
      "27.613801956176758\n",
      "Epoch 482 : Training loss 0.00004044 and valid loss : -0.94359641 :  \n",
      "Epoch 482 : valid accuracy :94.28249359 with total prob : 98.91587830 \n",
      "27.5723979473114\n",
      "Epoch 483 : Training loss 0.00004043 and valid loss : -0.94355055 :  \n",
      "Epoch 483 : valid accuracy :94.28681946 with total prob : 98.93299103 \n",
      "27.400264739990234\n",
      "Epoch 484 : Training loss 0.00004042 and valid loss : -0.94350529 :  \n",
      "Epoch 484 : valid accuracy :94.28955078 with total prob : 98.94989014 \n",
      "27.17516779899597\n",
      "Epoch 485 : Training loss 0.00004042 and valid loss : -0.94346065 :  \n",
      "Epoch 485 : valid accuracy :94.29366302 with total prob : 98.96656799 \n",
      "28.094696044921875\n",
      "Epoch 486 : Training loss 0.00004041 and valid loss : -0.94341667 :  \n",
      "Epoch 486 : valid accuracy :94.30231476 with total prob : 98.98305511 \n",
      "27.668659210205078\n",
      "Epoch 487 : Training loss 0.00004040 and valid loss : -0.94337336 :  \n",
      "Epoch 487 : valid accuracy :94.30573273 with total prob : 98.99932098 \n",
      "27.912900924682617\n",
      "Epoch 488 : Training loss 0.00004039 and valid loss : -0.94333075 :  \n",
      "Epoch 488 : valid accuracy :94.31211090 with total prob : 99.01538849 \n",
      "28.670181035995483\n",
      "Epoch 489 : Training loss 0.00004039 and valid loss : -0.94328887 :  \n",
      "Epoch 489 : valid accuracy :94.31758881 with total prob : 99.03121948 \n",
      "28.111077070236206\n",
      "Epoch 490 : Training loss 0.00004038 and valid loss : -0.94324772 :  \n",
      "Epoch 490 : valid accuracy :94.32305145 with total prob : 99.04685974 \n",
      "28.782407522201538\n",
      "Epoch 491 : Training loss 0.00004037 and valid loss : -0.94320734 :  \n",
      "Epoch 491 : valid accuracy :94.32487488 with total prob : 99.06224060 \n",
      "27.983471155166626\n",
      "Epoch 492 : Training loss 0.00004037 and valid loss : -0.94316772 :  \n",
      "Epoch 492 : valid accuracy :94.32487488 with total prob : 99.07737732 \n",
      "27.734656810760498\n",
      "Epoch 493 : Training loss 0.00004036 and valid loss : -0.94312890 :  \n",
      "Epoch 493 : valid accuracy :94.32487488 with total prob : 99.09223175 \n",
      "27.57001757621765\n",
      "Epoch 494 : Training loss 0.00004035 and valid loss : -0.94309086 :  \n",
      "Epoch 494 : valid accuracy :94.32487488 with total prob : 99.10681915 \n",
      "28.59538221359253\n",
      "Epoch 495 : Training loss 0.00004034 and valid loss : -0.94305363 :  \n",
      "Epoch 495 : valid accuracy :94.32487488 with total prob : 99.12113190 \n",
      "27.86494541168213\n",
      "Epoch 496 : Training loss 0.00004034 and valid loss : -0.94301722 :  \n",
      "Epoch 496 : valid accuracy :94.32487488 with total prob : 99.13518524 \n",
      "28.0614595413208\n",
      "Epoch 497 : Training loss 0.00004033 and valid loss : -0.94298161 :  \n",
      "Epoch 497 : valid accuracy :94.32487488 with total prob : 99.14897156 \n",
      "27.99743676185608\n",
      "Epoch 498 : Training loss 0.00004032 and valid loss : -0.94294682 :  \n",
      "Epoch 498 : valid accuracy :94.32487488 with total prob : 99.16249084 \n",
      "27.59790849685669\n",
      "Epoch 499 : Training loss 0.00004032 and valid loss : -0.94291286 :  \n",
      "Epoch 499 : valid accuracy :94.32487488 with total prob : 99.17573547 \n",
      "27.979199171066284\n",
      "Epoch 500 : Training loss 0.00004031 and valid loss : -0.94287971 :  \n",
      "Epoch 500 : valid accuracy :94.32487488 with total prob : 99.18873596 \n",
      "27.990253925323486\n",
      "Epoch 501 : Training loss 0.00004030 and valid loss : -0.94284738 :  \n",
      "Epoch 501 : valid accuracy :94.32487488 with total prob : 99.20145416 \n",
      "27.742616415023804\n",
      "Epoch 502 : Training loss 0.00004030 and valid loss : -0.94281586 :  \n",
      "Epoch 502 : valid accuracy :94.32487488 with total prob : 99.21392822 \n",
      "28.04528045654297\n",
      "Epoch 503 : Training loss 0.00004029 and valid loss : -0.94278515 :  \n",
      "Epoch 503 : valid accuracy :94.32487488 with total prob : 99.22615051 \n",
      "27.25148582458496\n",
      "Epoch 504 : Training loss 0.00004028 and valid loss : -0.94275525 :  \n",
      "Epoch 504 : valid accuracy :94.32487488 with total prob : 99.23811340 \n",
      "27.967488288879395\n",
      "Epoch 505 : Training loss 0.00004028 and valid loss : -0.94272615 :  \n",
      "Epoch 505 : valid accuracy :94.32487488 with total prob : 99.24982452 \n",
      "27.568907022476196\n",
      "Epoch 506 : Training loss 0.00004027 and valid loss : -0.94269783 :  \n",
      "Epoch 506 : valid accuracy :94.32487488 with total prob : 99.26128387 \n",
      "30.803643226623535\n",
      "Epoch 507 : Training loss 0.00004026 and valid loss : -0.94267030 :  \n",
      "Epoch 507 : valid accuracy :94.32487488 with total prob : 99.27251434 \n",
      "28.174835205078125\n",
      "Epoch 508 : Training loss 0.00004026 and valid loss : -0.94264354 :  \n",
      "Epoch 508 : valid accuracy :94.32487488 with total prob : 99.28350067 \n",
      "27.68365502357483\n",
      "Epoch 509 : Training loss 0.00004025 and valid loss : -0.94261754 :  \n",
      "Epoch 509 : valid accuracy :94.32487488 with total prob : 99.29424286 \n",
      "27.72115468978882\n",
      "Epoch 510 : Training loss 0.00004024 and valid loss : -0.94259229 :  \n",
      "Epoch 510 : valid accuracy :94.32487488 with total prob : 99.30475616 \n",
      "27.707866430282593\n",
      "Epoch 511 : Training loss 0.00004024 and valid loss : -0.94256779 :  \n",
      "Epoch 511 : valid accuracy :94.32487488 with total prob : 99.31503296 \n",
      "27.790476083755493\n",
      "Epoch 512 : Training loss 0.00004023 and valid loss : -0.94254401 :  \n",
      "Epoch 512 : valid accuracy :94.32487488 with total prob : 99.32507324 \n",
      "27.098655939102173\n",
      "Epoch 513 : Training loss 0.00004022 and valid loss : -0.94252094 :  \n",
      "Epoch 513 : valid accuracy :94.32487488 with total prob : 99.33489990 \n",
      "28.051483631134033\n",
      "Epoch 514 : Training loss 0.00004022 and valid loss : -0.94249857 :  \n",
      "Epoch 514 : valid accuracy :94.32487488 with total prob : 99.34451294 \n",
      "27.68693256378174\n",
      "Epoch 515 : Training loss 0.00004021 and valid loss : -0.94247689 :  \n",
      "Epoch 515 : valid accuracy :94.32487488 with total prob : 99.35388947 \n",
      "27.42821216583252\n",
      "Epoch 516 : Training loss 0.00004021 and valid loss : -0.94245589 :  \n",
      "Epoch 516 : valid accuracy :94.32487488 with total prob : 99.36306763 \n",
      "26.52035403251648\n",
      "Epoch 517 : Training loss 0.00004020 and valid loss : -0.94243554 :  \n",
      "Epoch 517 : valid accuracy :94.32487488 with total prob : 99.37203217 \n",
      "26.52055597305298\n",
      "Epoch 518 : Training loss 0.00004019 and valid loss : -0.94241584 :  \n",
      "Epoch 518 : valid accuracy :94.32487488 with total prob : 99.38079071 \n",
      "26.606653213500977\n",
      "Epoch 519 : Training loss 0.00004019 and valid loss : -0.94239677 :  \n",
      "Epoch 519 : valid accuracy :94.32487488 with total prob : 99.38934326 \n",
      "26.798428773880005\n",
      "Epoch 520 : Training loss 0.00004018 and valid loss : -0.94237831 :  \n",
      "Epoch 520 : valid accuracy :94.32487488 with total prob : 99.39769745 \n",
      "27.194013357162476\n",
      "Epoch 521 : Training loss 0.00004017 and valid loss : -0.94236045 :  \n",
      "Epoch 521 : valid accuracy :94.32487488 with total prob : 99.40586853 \n",
      "27.659924030303955\n",
      "Epoch 522 : Training loss 0.00004017 and valid loss : -0.94234318 :  \n",
      "Epoch 522 : valid accuracy :94.32487488 with total prob : 99.41383362 \n",
      "27.250638961791992\n",
      "Epoch 523 : Training loss 0.00004016 and valid loss : -0.94232647 :  \n",
      "Epoch 523 : valid accuracy :94.32487488 with total prob : 99.42162323 \n",
      "27.00261664390564\n",
      "Epoch 524 : Training loss 0.00004015 and valid loss : -0.94231032 :  \n",
      "Epoch 524 : valid accuracy :94.32487488 with total prob : 99.42922211 \n",
      "27.200575351715088\n",
      "Epoch 525 : Training loss 0.00004015 and valid loss : -0.94229471 :  \n",
      "Epoch 525 : valid accuracy :94.32487488 with total prob : 99.43663788 \n",
      "26.84092426300049\n",
      "Epoch 526 : Training loss 0.00004014 and valid loss : -0.94227963 :  \n",
      "Epoch 526 : valid accuracy :94.32487488 with total prob : 99.44388580 \n",
      "26.782005786895752\n",
      "Epoch 527 : Training loss 0.00004014 and valid loss : -0.94226505 :  \n",
      "Epoch 527 : valid accuracy :94.32487488 with total prob : 99.45094299 \n",
      "26.740967750549316\n",
      "Epoch 528 : Training loss 0.00004013 and valid loss : -0.94225097 :  \n",
      "Epoch 528 : valid accuracy :94.32487488 with total prob : 99.45784760 \n",
      "26.171141624450684\n",
      "Epoch 529 : Training loss 0.00004012 and valid loss : -0.94223737 :  \n",
      "Epoch 529 : valid accuracy :94.32487488 with total prob : 99.46459198 \n",
      "26.73131537437439\n",
      "Epoch 530 : Training loss 0.00004012 and valid loss : -0.94222423 :  \n",
      "Epoch 530 : valid accuracy :94.32487488 with total prob : 99.47115326 \n",
      "26.6177761554718\n",
      "Epoch 531 : Training loss 0.00004011 and valid loss : -0.94221154 :  \n",
      "Epoch 531 : valid accuracy :94.32487488 with total prob : 99.47756195 \n",
      "26.602872848510742\n",
      "Epoch 532 : Training loss 0.00004010 and valid loss : -0.94219929 :  \n",
      "Epoch 532 : valid accuracy :94.32487488 with total prob : 99.48383331 \n",
      "26.558473587036133\n",
      "Epoch 533 : Training loss 0.00004010 and valid loss : -0.94218747 :  \n",
      "Epoch 533 : valid accuracy :94.32487488 with total prob : 99.48993683 \n",
      "26.08247184753418\n",
      "Epoch 534 : Training loss 0.00004009 and valid loss : -0.94217605 :  \n",
      "Epoch 534 : valid accuracy :94.32487488 with total prob : 99.49588776 \n",
      "27.405887842178345\n",
      "Epoch 535 : Training loss 0.00004009 and valid loss : -0.94216503 :  \n",
      "Epoch 535 : valid accuracy :94.32487488 with total prob : 99.50170898 \n",
      "26.68739151954651\n",
      "Epoch 536 : Training loss 0.00004008 and valid loss : -0.94215439 :  \n",
      "Epoch 536 : valid accuracy :94.32487488 with total prob : 99.50737000 \n",
      "26.146801471710205\n",
      "Epoch 537 : Training loss 0.00004007 and valid loss : -0.94214412 :  \n",
      "Epoch 537 : valid accuracy :94.32487488 with total prob : 99.51290131 \n",
      "26.578200340270996\n",
      "Epoch 538 : Training loss 0.00004007 and valid loss : -0.94213421 :  \n",
      "Epoch 538 : valid accuracy :94.32487488 with total prob : 99.51829529 \n",
      "25.789733409881592\n",
      "Epoch 539 : Training loss 0.00004006 and valid loss : -0.94212464 :  \n",
      "Epoch 539 : valid accuracy :94.32487488 with total prob : 99.52355194 \n",
      "26.33044457435608\n",
      "Epoch 540 : Training loss 0.00004005 and valid loss : -0.94211540 :  \n",
      "Epoch 540 : valid accuracy :94.32487488 with total prob : 99.52869415 \n",
      "26.313623428344727\n",
      "Epoch 541 : Training loss 0.00004005 and valid loss : -0.94210648 :  \n",
      "Epoch 541 : valid accuracy :94.32487488 with total prob : 99.53369141 \n",
      "26.254116535186768\n",
      "Epoch 542 : Training loss 0.00004004 and valid loss : -0.94209788 :  \n",
      "Epoch 542 : valid accuracy :94.32487488 with total prob : 99.53857422 \n",
      "28.58467125892639\n",
      "Epoch 543 : Training loss 0.00004004 and valid loss : -0.94208957 :  \n",
      "Epoch 543 : valid accuracy :94.32487488 with total prob : 99.54333496 \n",
      "25.944907188415527\n",
      "Epoch 544 : Training loss 0.00004003 and valid loss : -0.94208154 :  \n",
      "Epoch 544 : valid accuracy :94.32487488 with total prob : 99.54797363 \n",
      "26.721892595291138\n",
      "Epoch 545 : Training loss 0.00004002 and valid loss : -0.94207379 :  \n",
      "Epoch 545 : valid accuracy :94.32487488 with total prob : 99.55250549 \n",
      "26.447364807128906\n",
      "Epoch 546 : Training loss 0.00004002 and valid loss : -0.94206631 :  \n",
      "Epoch 546 : valid accuracy :94.32487488 with total prob : 99.55690765 \n",
      "25.68148922920227\n",
      "Epoch 547 : Training loss 0.00004001 and valid loss : -0.94205908 :  \n",
      "Epoch 547 : valid accuracy :94.32487488 with total prob : 99.56121826 \n",
      "26.17247462272644\n",
      "Epoch 548 : Training loss 0.00004000 and valid loss : -0.94205209 :  \n",
      "Epoch 548 : valid accuracy :94.32487488 with total prob : 99.56540680 \n",
      "26.24626064300537\n",
      "Epoch 549 : Training loss 0.00004000 and valid loss : -0.94204534 :  \n",
      "Epoch 549 : valid accuracy :94.32487488 with total prob : 99.56951141 \n",
      "26.452368021011353\n",
      "Epoch 550 : Training loss 0.00003999 and valid loss : -0.94203881 :  \n",
      "Epoch 550 : valid accuracy :94.32487488 with total prob : 99.57350159 \n",
      "26.597496032714844\n",
      "Epoch 551 : Training loss 0.00003999 and valid loss : -0.94203251 :  \n",
      "Epoch 551 : valid accuracy :94.32487488 with total prob : 99.57738495 \n",
      "26.157538652420044\n",
      "Epoch 552 : Training loss 0.00003998 and valid loss : -0.94202641 :  \n",
      "Epoch 552 : valid accuracy :94.32487488 with total prob : 99.58117676 \n",
      "26.00887393951416\n",
      "Epoch 553 : Training loss 0.00003997 and valid loss : -0.94202050 :  \n",
      "Epoch 553 : valid accuracy :94.32487488 with total prob : 99.58486176 \n",
      "26.525800466537476\n",
      "Epoch 554 : Training loss 0.00003997 and valid loss : -0.94201479 :  \n",
      "Epoch 554 : valid accuracy :94.32487488 with total prob : 99.58847809 \n",
      "26.567203044891357\n",
      "Epoch 555 : Training loss 0.00003996 and valid loss : -0.94200926 :  \n",
      "Epoch 555 : valid accuracy :94.32487488 with total prob : 99.59197998 \n",
      "26.271127939224243\n",
      "Epoch 556 : Training loss 0.00003995 and valid loss : -0.94200391 :  \n",
      "Epoch 556 : valid accuracy :94.32487488 with total prob : 99.59541321 \n",
      "26.17426109313965\n",
      "Epoch 557 : Training loss 0.00003995 and valid loss : -0.94199873 :  \n",
      "Epoch 557 : valid accuracy :94.32487488 with total prob : 99.59874725 \n",
      "25.95364284515381\n",
      "Epoch 558 : Training loss 0.00003994 and valid loss : -0.94199370 :  \n",
      "Epoch 558 : valid accuracy :94.32487488 with total prob : 99.60199738 \n",
      "26.333410263061523\n",
      "Epoch 559 : Training loss 0.00003994 and valid loss : -0.94198883 :  \n",
      "Epoch 559 : valid accuracy :94.32487488 with total prob : 99.60517120 \n",
      "26.199158191680908\n",
      "Epoch 560 : Training loss 0.00003993 and valid loss : -0.94198411 :  \n",
      "Epoch 560 : valid accuracy :94.32487488 with total prob : 99.60826111 \n",
      "26.105252981185913\n",
      "Epoch 561 : Training loss 0.00003992 and valid loss : -0.94197952 :  \n",
      "Epoch 561 : valid accuracy :94.32487488 with total prob : 99.61127472 \n",
      "26.388729095458984\n",
      "Epoch 562 : Training loss 0.00003992 and valid loss : -0.94197507 :  \n",
      "Epoch 562 : valid accuracy :94.32487488 with total prob : 99.61421204 \n",
      "25.791184425354004\n",
      "Epoch 563 : Training loss 0.00003991 and valid loss : -0.94197075 :  \n",
      "Epoch 563 : valid accuracy :94.32487488 with total prob : 99.61706543 \n",
      "26.4767644405365\n",
      "Epoch 564 : Training loss 0.00003990 and valid loss : -0.94196654 :  \n",
      "Epoch 564 : valid accuracy :94.32487488 with total prob : 99.61985016 \n",
      "26.135866165161133\n",
      "Epoch 565 : Training loss 0.00003990 and valid loss : -0.94196246 :  \n",
      "Epoch 565 : valid accuracy :94.32487488 with total prob : 99.62257385 \n",
      "26.46639585494995\n",
      "Epoch 566 : Training loss 0.00003989 and valid loss : -0.94195848 :  \n",
      "Epoch 566 : valid accuracy :94.32487488 with total prob : 99.62522125 \n",
      "25.88117289543152\n",
      "Epoch 567 : Training loss 0.00003988 and valid loss : -0.94195462 :  \n",
      "Epoch 567 : valid accuracy :94.32487488 with total prob : 99.62780762 \n",
      "26.40719199180603\n",
      "Epoch 568 : Training loss 0.00003988 and valid loss : -0.94195085 :  \n",
      "Epoch 568 : valid accuracy :94.32487488 with total prob : 99.63031769 \n",
      "25.98423957824707\n",
      "Epoch 569 : Training loss 0.00003987 and valid loss : -0.94194718 :  \n",
      "Epoch 569 : valid accuracy :94.32487488 with total prob : 99.63276672 \n",
      "26.40014410018921\n",
      "Epoch 570 : Training loss 0.00003987 and valid loss : -0.94194359 :  \n",
      "Epoch 570 : valid accuracy :94.32487488 with total prob : 99.63514709 \n",
      "26.093428373336792\n",
      "Epoch 571 : Training loss 0.00003986 and valid loss : -0.94194010 :  \n",
      "Epoch 571 : valid accuracy :94.32487488 with total prob : 99.63747406 \n",
      "25.568652153015137\n",
      "Epoch 572 : Training loss 0.00003985 and valid loss : -0.94193669 :  \n",
      "Epoch 572 : valid accuracy :94.32487488 with total prob : 99.63974762 \n",
      "26.160033702850342\n",
      "Epoch 573 : Training loss 0.00003985 and valid loss : -0.94193335 :  \n",
      "Epoch 573 : valid accuracy :94.32487488 with total prob : 99.64195251 \n",
      "26.62057662010193\n",
      "Epoch 574 : Training loss 0.00003984 and valid loss : -0.94193009 :  \n",
      "Epoch 574 : valid accuracy :94.32487488 with total prob : 99.64409637 \n",
      "26.318323373794556\n",
      "Epoch 575 : Training loss 0.00003983 and valid loss : -0.94192690 :  \n",
      "Epoch 575 : valid accuracy :94.32487488 with total prob : 99.64620209 \n",
      "26.459977626800537\n",
      "Epoch 576 : Training loss 0.00003983 and valid loss : -0.94192378 :  \n",
      "Epoch 576 : valid accuracy :94.32487488 with total prob : 99.64823914 \n",
      "26.052494287490845\n",
      "Epoch 577 : Training loss 0.00003982 and valid loss : -0.94192072 :  \n",
      "Epoch 577 : valid accuracy :94.32487488 with total prob : 99.65023041 \n",
      "25.756844758987427\n",
      "Epoch 578 : Training loss 0.00003981 and valid loss : -0.94191772 :  \n",
      "Epoch 578 : valid accuracy :94.32487488 with total prob : 99.65215302 \n",
      "26.796584367752075\n",
      "Epoch 579 : Training loss 0.00003981 and valid loss : -0.94191478 :  \n",
      "Epoch 579 : valid accuracy :94.32487488 with total prob : 99.65404510 \n",
      "26.994431734085083\n",
      "Epoch 580 : Training loss 0.00003980 and valid loss : -0.94191190 :  \n",
      "Epoch 580 : valid accuracy :94.32487488 with total prob : 99.65587616 \n",
      "26.705844163894653\n",
      "Epoch 581 : Training loss 0.00003979 and valid loss : -0.94190906 :  \n",
      "Epoch 581 : valid accuracy :94.32487488 with total prob : 99.65766907 \n",
      "26.36322259902954\n",
      "Epoch 582 : Training loss 0.00003979 and valid loss : -0.94190627 :  \n",
      "Epoch 582 : valid accuracy :94.32487488 with total prob : 99.65941620 \n",
      "26.61429738998413\n",
      "Epoch 583 : Training loss 0.00003978 and valid loss : -0.94190353 :  \n",
      "Epoch 583 : valid accuracy :94.32487488 with total prob : 99.66110229 \n",
      "27.21623945236206\n",
      "Epoch 584 : Training loss 0.00003977 and valid loss : -0.94190083 :  \n",
      "Epoch 584 : valid accuracy :94.32487488 with total prob : 99.66275787 \n",
      "26.859534740447998\n",
      "Epoch 585 : Training loss 0.00003977 and valid loss : -0.94189817 :  \n",
      "Epoch 585 : valid accuracy :94.32487488 with total prob : 99.66437531 \n",
      "27.39125370979309\n",
      "Epoch 586 : Training loss 0.00003976 and valid loss : -0.94189555 :  \n",
      "Epoch 586 : valid accuracy :94.32487488 with total prob : 99.66593933 \n",
      "27.511924743652344\n",
      "Epoch 587 : Training loss 0.00003975 and valid loss : -0.94189297 :  \n",
      "Epoch 587 : valid accuracy :94.32487488 with total prob : 99.66744995 \n",
      "26.903016567230225\n",
      "Epoch 588 : Training loss 0.00003975 and valid loss : -0.94189042 :  \n",
      "Epoch 588 : valid accuracy :94.32487488 with total prob : 99.66893005 \n",
      "27.170169591903687\n",
      "Epoch 589 : Training loss 0.00003974 and valid loss : -0.94188790 :  \n",
      "Epoch 589 : valid accuracy :94.32487488 with total prob : 99.67038727 \n",
      "27.531174182891846\n",
      "Epoch 590 : Training loss 0.00003973 and valid loss : -0.94188541 :  \n",
      "Epoch 590 : valid accuracy :94.32487488 with total prob : 99.67178345 \n",
      "26.89623236656189\n",
      "Epoch 591 : Training loss 0.00003973 and valid loss : -0.94188296 :  \n",
      "Epoch 591 : valid accuracy :94.32487488 with total prob : 99.67314911 \n",
      "27.150869607925415\n",
      "Epoch 592 : Training loss 0.00003972 and valid loss : -0.94188052 :  \n",
      "Epoch 592 : valid accuracy :94.32487488 with total prob : 99.67448425 \n",
      "26.921857595443726\n",
      "Epoch 593 : Training loss 0.00003971 and valid loss : -0.94187812 :  \n",
      "Epoch 593 : valid accuracy :94.32487488 with total prob : 99.67577362 \n",
      "26.531869173049927\n",
      "Epoch 594 : Training loss 0.00003971 and valid loss : -0.94187574 :  \n",
      "Epoch 594 : valid accuracy :94.32487488 with total prob : 99.67704010 \n",
      "26.9039204120636\n",
      "Epoch 595 : Training loss 0.00003970 and valid loss : -0.94187338 :  \n",
      "Epoch 595 : valid accuracy :94.32487488 with total prob : 99.67826080 \n",
      "27.07293939590454\n",
      "Epoch 596 : Training loss 0.00003969 and valid loss : -0.94187104 :  \n",
      "Epoch 596 : valid accuracy :94.32487488 with total prob : 99.67945862 \n",
      "26.84621787071228\n",
      "Epoch 597 : Training loss 0.00003969 and valid loss : -0.94186872 :  \n",
      "Epoch 597 : valid accuracy :94.32487488 with total prob : 99.68061066 \n",
      "27.230361938476562\n",
      "Epoch 598 : Training loss 0.00003968 and valid loss : -0.94186642 :  \n",
      "Epoch 598 : valid accuracy :94.32487488 with total prob : 99.68173218 \n",
      "26.575054168701172\n",
      "Epoch 599 : Training loss 0.00003967 and valid loss : -0.94186413 :  \n",
      "Epoch 599 : valid accuracy :94.32487488 with total prob : 99.68283081 \n",
      "26.541494607925415\n",
      "Epoch 600 : Training loss 0.00003967 and valid loss : -0.94186187 :  \n",
      "Epoch 600 : valid accuracy :94.32487488 with total prob : 99.68389893 \n",
      "27.042277336120605\n",
      "Epoch 601 : Training loss 0.00003966 and valid loss : -0.94185961 :  \n",
      "Epoch 601 : valid accuracy :94.32487488 with total prob : 99.68494415 \n",
      "26.921477556228638\n",
      "Epoch 602 : Training loss 0.00003965 and valid loss : -0.94185738 :  \n",
      "Epoch 602 : valid accuracy :94.32487488 with total prob : 99.68595123 \n",
      "26.497734546661377\n",
      "Epoch 603 : Training loss 0.00003965 and valid loss : -0.94185515 :  \n",
      "Epoch 603 : valid accuracy :94.32487488 with total prob : 99.68693542 \n",
      "26.360366106033325\n",
      "Epoch 604 : Training loss 0.00003964 and valid loss : -0.94185294 :  \n",
      "Epoch 604 : valid accuracy :94.32487488 with total prob : 99.68787384 \n",
      "26.15348219871521\n",
      "Epoch 605 : Training loss 0.00003963 and valid loss : -0.94185074 :  \n",
      "Epoch 605 : valid accuracy :94.32487488 with total prob : 99.68881226 \n",
      "26.495193481445312\n",
      "Epoch 606 : Training loss 0.00003963 and valid loss : -0.94184855 :  \n",
      "Epoch 606 : valid accuracy :94.32487488 with total prob : 99.68970490 \n",
      "26.301223516464233\n",
      "Epoch 607 : Training loss 0.00003962 and valid loss : -0.94184637 :  \n",
      "Epoch 607 : valid accuracy :94.32487488 with total prob : 99.69057465 \n",
      "26.817681550979614\n",
      "Epoch 608 : Training loss 0.00003961 and valid loss : -0.94184420 :  \n",
      "Epoch 608 : valid accuracy :94.32487488 with total prob : 99.69142914 \n",
      "26.467117309570312\n",
      "Epoch 609 : Training loss 0.00003961 and valid loss : -0.94184204 :  \n",
      "Epoch 609 : valid accuracy :94.32487488 with total prob : 99.69224548 \n",
      "25.88855767250061\n",
      "Epoch 610 : Training loss 0.00003960 and valid loss : -0.94183988 :  \n",
      "Epoch 610 : valid accuracy :94.32487488 with total prob : 99.69306183 \n",
      "26.19561791419983\n",
      "Epoch 611 : Training loss 0.00003959 and valid loss : -0.94183774 :  \n",
      "Epoch 611 : valid accuracy :94.32487488 with total prob : 99.69383240 \n",
      "26.12001132965088\n",
      "Epoch 612 : Training loss 0.00003959 and valid loss : -0.94183560 :  \n",
      "Epoch 612 : valid accuracy :94.32487488 with total prob : 99.69457245 \n",
      "26.36820125579834\n",
      "Epoch 613 : Training loss 0.00003958 and valid loss : -0.94183347 :  \n",
      "Epoch 613 : valid accuracy :94.32487488 with total prob : 99.69530487 \n",
      "26.289581775665283\n",
      "Epoch 614 : Training loss 0.00003957 and valid loss : -0.94183135 :  \n",
      "Epoch 614 : valid accuracy :94.32487488 with total prob : 99.69600677 \n",
      "27.23609471321106\n",
      "Epoch 615 : Training loss 0.00003957 and valid loss : -0.94182923 :  \n",
      "Epoch 615 : valid accuracy :94.32487488 with total prob : 99.69670105 \n",
      "26.397664070129395\n",
      "Epoch 616 : Training loss 0.00003956 and valid loss : -0.94182711 :  \n",
      "Epoch 616 : valid accuracy :94.32487488 with total prob : 99.69737244 \n",
      "26.947547674179077\n",
      "Epoch 617 : Training loss 0.00003955 and valid loss : -0.94182500 :  \n",
      "Epoch 617 : valid accuracy :94.32487488 with total prob : 99.69802856 \n",
      "26.463379859924316\n",
      "Epoch 618 : Training loss 0.00003955 and valid loss : -0.94182290 :  \n",
      "Epoch 618 : valid accuracy :94.32487488 with total prob : 99.69865417 \n",
      "26.435481786727905\n",
      "Epoch 619 : Training loss 0.00003954 and valid loss : -0.94182080 :  \n",
      "Epoch 619 : valid accuracy :94.32487488 with total prob : 99.69924927 \n",
      "27.078513860702515\n",
      "Epoch 620 : Training loss 0.00003953 and valid loss : -0.94181871 :  \n",
      "Epoch 620 : valid accuracy :94.32487488 with total prob : 99.69985962 \n",
      "26.354740619659424\n",
      "Epoch 621 : Training loss 0.00003952 and valid loss : -0.94181662 :  \n",
      "Epoch 621 : valid accuracy :94.32487488 with total prob : 99.70041656 \n",
      "26.754226446151733\n",
      "Epoch 622 : Training loss 0.00003952 and valid loss : -0.94181453 :  \n",
      "Epoch 622 : valid accuracy :94.32487488 with total prob : 99.70097351 \n",
      "26.247971057891846\n",
      "Epoch 623 : Training loss 0.00003951 and valid loss : -0.94181245 :  \n",
      "Epoch 623 : valid accuracy :94.32487488 with total prob : 99.70150757 \n",
      "27.62450861930847\n",
      "Epoch 624 : Training loss 0.00003950 and valid loss : -0.94181037 :  \n",
      "Epoch 624 : valid accuracy :94.32487488 with total prob : 99.70202637 \n",
      "25.99961757659912\n",
      "Epoch 625 : Training loss 0.00003950 and valid loss : -0.94180829 :  \n",
      "Epoch 625 : valid accuracy :94.32487488 with total prob : 99.70252991 \n",
      "26.038578033447266\n",
      "Epoch 626 : Training loss 0.00003949 and valid loss : -0.94180622 :  \n",
      "Epoch 626 : valid accuracy :94.32487488 with total prob : 99.70301056 \n",
      "26.141873121261597\n",
      "Epoch 627 : Training loss 0.00003948 and valid loss : -0.94180415 :  \n",
      "Epoch 627 : valid accuracy :94.32487488 with total prob : 99.70347595 \n",
      "26.030989408493042\n",
      "Epoch 628 : Training loss 0.00003948 and valid loss : -0.94180208 :  \n",
      "Epoch 628 : valid accuracy :94.32487488 with total prob : 99.70394135 \n",
      "26.40678858757019\n",
      "Epoch 629 : Training loss 0.00003947 and valid loss : -0.94180001 :  \n",
      "Epoch 629 : valid accuracy :94.32487488 with total prob : 99.70437622 \n",
      "26.104074716567993\n",
      "Epoch 630 : Training loss 0.00003946 and valid loss : -0.94179795 :  \n",
      "Epoch 630 : valid accuracy :94.32487488 with total prob : 99.70479584 \n",
      "26.24211859703064\n",
      "Epoch 631 : Training loss 0.00003946 and valid loss : -0.94179589 :  \n",
      "Epoch 631 : valid accuracy :94.32487488 with total prob : 99.70520782 \n",
      "27.234156847000122\n",
      "Epoch 632 : Training loss 0.00003945 and valid loss : -0.94179383 :  \n",
      "Epoch 632 : valid accuracy :94.32487488 with total prob : 99.70558929 \n",
      "26.741155862808228\n",
      "Epoch 633 : Training loss 0.00003944 and valid loss : -0.94179177 :  \n",
      "Epoch 633 : valid accuracy :94.32487488 with total prob : 99.70597839 \n",
      "27.421791553497314\n",
      "Epoch 634 : Training loss 0.00003944 and valid loss : -0.94178972 :  \n",
      "Epoch 634 : valid accuracy :94.32487488 with total prob : 99.70634460 \n",
      "27.827587842941284\n",
      "Epoch 635 : Training loss 0.00003943 and valid loss : -0.94178767 :  \n",
      "Epoch 635 : valid accuracy :94.32487488 with total prob : 99.70668793 \n",
      "28.053250551223755\n",
      "Epoch 636 : Training loss 0.00003942 and valid loss : -0.94178562 :  \n",
      "Epoch 636 : valid accuracy :94.32487488 with total prob : 99.70703125 \n",
      "26.916853666305542\n",
      "Epoch 637 : Training loss 0.00003942 and valid loss : -0.94178357 :  \n",
      "Epoch 637 : valid accuracy :94.32487488 with total prob : 99.70736694 \n",
      "28.098283529281616\n",
      "Epoch 638 : Training loss 0.00003941 and valid loss : -0.94178152 :  \n",
      "Epoch 638 : valid accuracy :94.32487488 with total prob : 99.70767212 \n",
      "27.3743793964386\n",
      "Epoch 639 : Training loss 0.00003941 and valid loss : -0.94177948 :  \n",
      "Epoch 639 : valid accuracy :94.32487488 with total prob : 99.70796967 \n",
      "27.594337463378906\n",
      "Epoch 640 : Training loss 0.00003940 and valid loss : -0.94177743 :  \n",
      "Epoch 640 : valid accuracy :94.32487488 with total prob : 99.70825195 \n",
      "26.878079414367676\n",
      "Epoch 641 : Training loss 0.00003939 and valid loss : -0.94177539 :  \n",
      "Epoch 641 : valid accuracy :94.32487488 with total prob : 99.70854187 \n",
      "27.084476232528687\n",
      "Epoch 642 : Training loss 0.00003939 and valid loss : -0.94177335 :  \n",
      "Epoch 642 : valid accuracy :94.32487488 with total prob : 99.70880127 \n",
      "27.22864866256714\n",
      "Epoch 643 : Training loss 0.00003938 and valid loss : -0.94177132 :  \n",
      "Epoch 643 : valid accuracy :94.32487488 with total prob : 99.70905304 \n",
      "27.382111310958862\n",
      "Epoch 644 : Training loss 0.00003937 and valid loss : -0.94176928 :  \n",
      "Epoch 644 : valid accuracy :94.32487488 with total prob : 99.70930481 \n",
      "27.090036630630493\n",
      "Epoch 645 : Training loss 0.00003937 and valid loss : -0.94176725 :  \n",
      "Epoch 645 : valid accuracy :94.32487488 with total prob : 99.70953369 \n",
      "26.781781673431396\n",
      "Epoch 646 : Training loss 0.00003936 and valid loss : -0.94176522 :  \n",
      "Epoch 646 : valid accuracy :94.32487488 with total prob : 99.70974731 \n",
      "26.887043714523315\n",
      "Epoch 647 : Training loss 0.00003936 and valid loss : -0.94176319 :  \n",
      "Epoch 647 : valid accuracy :94.32487488 with total prob : 99.70996094 \n",
      "27.266841888427734\n",
      "Epoch 648 : Training loss 0.00003935 and valid loss : -0.94176117 :  \n",
      "Epoch 648 : valid accuracy :94.32487488 with total prob : 99.71015930 \n",
      "27.985279321670532\n",
      "Epoch 649 : Training loss 0.00003934 and valid loss : -0.94175914 :  \n",
      "Epoch 649 : valid accuracy :94.32487488 with total prob : 99.71036530 \n",
      "28.44006848335266\n",
      "Epoch 650 : Training loss 0.00003934 and valid loss : -0.94175712 :  \n",
      "Epoch 650 : valid accuracy :94.32487488 with total prob : 99.71054840 \n",
      "28.522863388061523\n",
      "Epoch 651 : Training loss 0.00003933 and valid loss : -0.94175510 :  \n",
      "Epoch 651 : valid accuracy :94.32487488 with total prob : 99.71070862 \n",
      "28.863356113433838\n",
      "Epoch 652 : Training loss 0.00003933 and valid loss : -0.94175309 :  \n",
      "Epoch 652 : valid accuracy :94.32487488 with total prob : 99.71087646 \n",
      "28.08239245414734\n",
      "Epoch 653 : Training loss 0.00003932 and valid loss : -0.94175108 :  \n",
      "Epoch 653 : valid accuracy :94.32487488 with total prob : 99.71102142 \n",
      "28.509719371795654\n",
      "Epoch 654 : Training loss 0.00003931 and valid loss : -0.94174907 :  \n",
      "Epoch 654 : valid accuracy :94.32487488 with total prob : 99.71116638 \n",
      "28.49183964729309\n",
      "Epoch 655 : Training loss 0.00003931 and valid loss : -0.94174706 :  \n",
      "Epoch 655 : valid accuracy :94.32487488 with total prob : 99.71131134 \n",
      "27.485613584518433\n",
      "Epoch 656 : Training loss 0.00003930 and valid loss : -0.94174506 :  \n",
      "Epoch 656 : valid accuracy :94.32487488 with total prob : 99.71143341 \n",
      "27.880388975143433\n",
      "Epoch 657 : Training loss 0.00003930 and valid loss : -0.94174306 :  \n",
      "Epoch 657 : valid accuracy :94.32487488 with total prob : 99.71155548 \n",
      "27.374762535095215\n",
      "Epoch 658 : Training loss 0.00003929 and valid loss : -0.94174107 :  \n",
      "Epoch 658 : valid accuracy :94.32487488 with total prob : 99.71167755 \n",
      "27.032474279403687\n",
      "Epoch 659 : Training loss 0.00003929 and valid loss : -0.94173908 :  \n",
      "Epoch 659 : valid accuracy :94.32487488 with total prob : 99.71176910 \n",
      "27.954455375671387\n",
      "Epoch 660 : Training loss 0.00003928 and valid loss : -0.94173710 :  \n",
      "Epoch 660 : valid accuracy :94.32487488 with total prob : 99.71186829 \n",
      "27.22431755065918\n",
      "Epoch 661 : Training loss 0.00003927 and valid loss : -0.94173512 :  \n",
      "Epoch 661 : valid accuracy :94.32487488 with total prob : 99.71195221 \n",
      "27.148536443710327\n",
      "Epoch 662 : Training loss 0.00003927 and valid loss : -0.94173315 :  \n",
      "Epoch 662 : valid accuracy :94.32487488 with total prob : 99.71204376 \n",
      "26.8112895488739\n",
      "Epoch 663 : Training loss 0.00003926 and valid loss : -0.94173118 :  \n",
      "Epoch 663 : valid accuracy :94.32487488 with total prob : 99.71211243 \n",
      "26.69891595840454\n",
      "Epoch 664 : Training loss 0.00003926 and valid loss : -0.94172922 :  \n",
      "Epoch 664 : valid accuracy :94.32487488 with total prob : 99.71218872 \n",
      "26.74475860595703\n",
      "Epoch 665 : Training loss 0.00003925 and valid loss : -0.94172726 :  \n",
      "Epoch 665 : valid accuracy :94.32487488 with total prob : 99.71225739 \n",
      "27.838947772979736\n",
      "Epoch 666 : Training loss 0.00003925 and valid loss : -0.94172532 :  \n",
      "Epoch 666 : valid accuracy :94.32487488 with total prob : 99.71230316 \n",
      "27.57019352912903\n",
      "Epoch 667 : Training loss 0.00003924 and valid loss : -0.94172337 :  \n",
      "Epoch 667 : valid accuracy :94.32487488 with total prob : 99.71234894 \n",
      "27.25594472885132\n",
      "Epoch 668 : Training loss 0.00003924 and valid loss : -0.94172144 :  \n",
      "Epoch 668 : valid accuracy :94.32487488 with total prob : 99.71238708 \n",
      "27.14261245727539\n",
      "Epoch 669 : Training loss 0.00003923 and valid loss : -0.94171951 :  \n",
      "Epoch 669 : valid accuracy :94.32487488 with total prob : 99.71244049 \n",
      "26.53468918800354\n",
      "Epoch 670 : Training loss 0.00003923 and valid loss : -0.94171760 :  \n",
      "Epoch 670 : valid accuracy :94.32487488 with total prob : 99.71246338 \n",
      "27.18445324897766\n",
      "Epoch 671 : Training loss 0.00003922 and valid loss : -0.94171569 :  \n",
      "Epoch 671 : valid accuracy :94.32487488 with total prob : 99.71249390 \n",
      "27.329102516174316\n",
      "Epoch 672 : Training loss 0.00003922 and valid loss : -0.94171378 :  \n",
      "Epoch 672 : valid accuracy :94.32487488 with total prob : 99.71252441 \n",
      "27.088522911071777\n",
      "Epoch 673 : Training loss 0.00003921 and valid loss : -0.94171189 :  \n",
      "Epoch 673 : valid accuracy :94.32487488 with total prob : 99.71253204 \n",
      "27.269197940826416\n",
      "Epoch 674 : Training loss 0.00003921 and valid loss : -0.94171001 :  \n",
      "Epoch 674 : valid accuracy :94.32487488 with total prob : 99.71254730 \n",
      "26.9080810546875\n",
      "Epoch 675 : Training loss 0.00003920 and valid loss : -0.94170813 :  \n",
      "Epoch 675 : valid accuracy :94.32487488 with total prob : 99.71255493 \n",
      "26.413137197494507\n",
      "Epoch 676 : Training loss 0.00003919 and valid loss : -0.94170627 :  \n",
      "Epoch 676 : valid accuracy :94.32487488 with total prob : 99.71255493 \n",
      "26.73700714111328\n",
      "Epoch 677 : Training loss 0.00003919 and valid loss : -0.94170441 :  \n",
      "Epoch 677 : valid accuracy :94.32487488 with total prob : 99.71255493 \n",
      "27.117437601089478\n",
      "Epoch 678 : Training loss 0.00003918 and valid loss : -0.94170257 :  \n",
      "Epoch 678 : valid accuracy :94.32487488 with total prob : 99.71255493 \n",
      "27.0771267414093\n",
      "Epoch 679 : Training loss 0.00003918 and valid loss : -0.94170073 :  \n",
      "Epoch 679 : valid accuracy :94.32487488 with total prob : 99.71254730 \n",
      "27.18581509590149\n",
      "Epoch 680 : Training loss 0.00003917 and valid loss : -0.94169891 :  \n",
      "Epoch 680 : valid accuracy :94.32487488 with total prob : 99.71252441 \n",
      "26.68737244606018\n",
      "Epoch 681 : Training loss 0.00003917 and valid loss : -0.94169710 :  \n",
      "Epoch 681 : valid accuracy :94.32487488 with total prob : 99.71251678 \n",
      "26.486021757125854\n",
      "Epoch 682 : Training loss 0.00003916 and valid loss : -0.94169529 :  \n",
      "Epoch 682 : valid accuracy :94.32487488 with total prob : 99.71249390 \n",
      "26.709367513656616\n",
      "Epoch 683 : Training loss 0.00003916 and valid loss : -0.94169350 :  \n",
      "Epoch 683 : valid accuracy :94.32487488 with total prob : 99.71246338 \n",
      "27.26193070411682\n",
      "Epoch 684 : Training loss 0.00003915 and valid loss : -0.94169172 :  \n",
      "Epoch 684 : valid accuracy :94.32487488 with total prob : 99.71244049 \n",
      "27.193897008895874\n",
      "Epoch 685 : Training loss 0.00003915 and valid loss : -0.94168995 :  \n",
      "Epoch 685 : valid accuracy :94.32487488 with total prob : 99.71240997 \n",
      "26.476820945739746\n",
      "Epoch 686 : Training loss 0.00003914 and valid loss : -0.94168820 :  \n",
      "Epoch 686 : valid accuracy :94.32487488 with total prob : 99.71238708 \n",
      "27.697263479232788\n",
      "Epoch 687 : Training loss 0.00003914 and valid loss : -0.94168645 :  \n",
      "Epoch 687 : valid accuracy :94.32487488 with total prob : 99.71235657 \n",
      "28.526060581207275\n",
      "Epoch 688 : Training loss 0.00003913 and valid loss : -0.94168472 :  \n",
      "Epoch 688 : valid accuracy :94.32487488 with total prob : 99.71231079 \n",
      "28.818927526474\n",
      "Epoch 689 : Training loss 0.00003912 and valid loss : -0.94168300 :  \n",
      "Epoch 689 : valid accuracy :94.32487488 with total prob : 99.71227264 \n",
      "28.929562091827393\n",
      "Epoch 690 : Training loss 0.00003912 and valid loss : -0.94168128 :  \n",
      "Epoch 690 : valid accuracy :94.32487488 with total prob : 99.71222687 \n",
      "27.86926817893982\n",
      "Epoch 691 : Training loss 0.00003911 and valid loss : -0.94167959 :  \n",
      "Epoch 691 : valid accuracy :94.32487488 with total prob : 99.71217346 \n",
      "27.88408398628235\n",
      "Epoch 692 : Training loss 0.00003911 and valid loss : -0.94167790 :  \n",
      "Epoch 692 : valid accuracy :94.32487488 with total prob : 99.71212769 \n",
      "28.083940505981445\n",
      "Epoch 693 : Training loss 0.00003910 and valid loss : -0.94167623 :  \n",
      "Epoch 693 : valid accuracy :94.32487488 with total prob : 99.71207428 \n",
      "27.39263892173767\n",
      "Epoch 694 : Training loss 0.00003910 and valid loss : -0.94167456 :  \n",
      "Epoch 694 : valid accuracy :94.32487488 with total prob : 99.71202850 \n",
      "26.71595811843872\n",
      "Epoch 695 : Training loss 0.00003909 and valid loss : -0.94167291 :  \n",
      "Epoch 695 : valid accuracy :94.32487488 with total prob : 99.71196747 \n",
      "27.063485145568848\n",
      "Epoch 696 : Training loss 0.00003909 and valid loss : -0.94167128 :  \n",
      "Epoch 696 : valid accuracy :94.32487488 with total prob : 99.71190643 \n",
      "28.038671016693115\n",
      "Epoch 697 : Training loss 0.00003908 and valid loss : -0.94166965 :  \n",
      "Epoch 697 : valid accuracy :94.32487488 with total prob : 99.71186066 \n",
      "27.281505346298218\n",
      "Epoch 698 : Training loss 0.00003907 and valid loss : -0.94166803 :  \n",
      "Epoch 698 : valid accuracy :94.32487488 with total prob : 99.71179199 \n",
      "27.251749515533447\n",
      "Epoch 699 : Training loss 0.00003907 and valid loss : -0.94166643 :  \n",
      "Epoch 699 : valid accuracy :94.32487488 with total prob : 99.71173096 \n",
      "27.49161195755005\n",
      "Epoch 700 : Training loss 0.00003906 and valid loss : -0.94166484 :  \n",
      "Epoch 700 : valid accuracy :94.32487488 with total prob : 99.71165466 \n",
      "27.879384994506836\n",
      "Epoch 701 : Training loss 0.00003906 and valid loss : -0.94166326 :  \n",
      "Epoch 701 : valid accuracy :94.32487488 with total prob : 99.71159363 \n",
      "27.811725854873657\n",
      "Epoch 702 : Training loss 0.00003905 and valid loss : -0.94166169 :  \n",
      "Epoch 702 : valid accuracy :94.32487488 with total prob : 99.71152496 \n",
      "27.189767837524414\n",
      "Epoch 703 : Training loss 0.00003905 and valid loss : -0.94166014 :  \n",
      "Epoch 703 : valid accuracy :94.32487488 with total prob : 99.71145630 \n",
      "27.286062955856323\n",
      "Epoch 704 : Training loss 0.00003904 and valid loss : -0.94165860 :  \n",
      "Epoch 704 : valid accuracy :94.32487488 with total prob : 99.71137238 \n",
      "26.972108602523804\n",
      "Epoch 705 : Training loss 0.00003903 and valid loss : -0.94165706 :  \n",
      "Epoch 705 : valid accuracy :94.32487488 with total prob : 99.71129608 \n",
      "26.98645782470703\n",
      "Epoch 706 : Training loss 0.00003903 and valid loss : -0.94165554 :  \n",
      "Epoch 706 : valid accuracy :94.32487488 with total prob : 99.71121979 \n",
      "26.909057140350342\n",
      "Epoch 707 : Training loss 0.00003902 and valid loss : -0.94165403 :  \n",
      "Epoch 707 : valid accuracy :94.32487488 with total prob : 99.71115112 \n",
      "27.050910234451294\n",
      "Epoch 708 : Training loss 0.00003901 and valid loss : -0.94165253 :  \n",
      "Epoch 708 : valid accuracy :94.32487488 with total prob : 99.71107483 \n",
      "26.376001596450806\n",
      "Epoch 709 : Training loss 0.00003901 and valid loss : -0.94165105 :  \n",
      "Epoch 709 : valid accuracy :94.32487488 with total prob : 99.71099854 \n",
      "27.3778338432312\n",
      "Epoch 710 : Training loss 0.00003900 and valid loss : -0.94164957 :  \n",
      "Epoch 710 : valid accuracy :94.32487488 with total prob : 99.71089172 \n",
      "27.724467992782593\n",
      "Epoch 711 : Training loss 0.00003900 and valid loss : -0.94164810 :  \n",
      "Epoch 711 : valid accuracy :94.32487488 with total prob : 99.71081543 \n",
      "27.94745373725891\n",
      "Epoch 712 : Training loss 0.00003899 and valid loss : -0.94164665 :  \n",
      "Epoch 712 : valid accuracy :94.32487488 with total prob : 99.71073151 \n",
      "27.395828008651733\n",
      "Epoch 713 : Training loss 0.00003898 and valid loss : -0.94164520 :  \n",
      "Epoch 713 : valid accuracy :94.32487488 with total prob : 99.71063995 \n",
      "28.159412384033203\n",
      "Epoch 714 : Training loss 0.00003898 and valid loss : -0.94164377 :  \n",
      "Epoch 714 : valid accuracy :94.32487488 with total prob : 99.71055603 \n",
      "27.218767166137695\n",
      "Epoch 715 : Training loss 0.00003897 and valid loss : -0.94164235 :  \n",
      "Epoch 715 : valid accuracy :94.32487488 with total prob : 99.71046448 \n",
      "26.85812020301819\n",
      "Epoch 716 : Training loss 0.00003897 and valid loss : -0.94164093 :  \n",
      "Epoch 716 : valid accuracy :94.32487488 with total prob : 99.71037292 \n",
      "26.793923139572144\n",
      "Epoch 717 : Training loss 0.00003896 and valid loss : -0.94163953 :  \n",
      "Epoch 717 : valid accuracy :94.32487488 with total prob : 99.71027374 \n",
      "26.948035955429077\n",
      "Epoch 718 : Training loss 0.00003895 and valid loss : -0.94163814 :  \n",
      "Epoch 718 : valid accuracy :94.32487488 with total prob : 99.71017456 \n",
      "27.499746561050415\n",
      "Epoch 719 : Training loss 0.00003895 and valid loss : -0.94163676 :  \n",
      "Epoch 719 : valid accuracy :94.32487488 with total prob : 99.71009064 \n",
      "26.9435076713562\n",
      "Epoch 720 : Training loss 0.00003894 and valid loss : -0.94163538 :  \n",
      "Epoch 720 : valid accuracy :94.32487488 with total prob : 99.70999146 \n",
      "27.158097505569458\n",
      "Epoch 721 : Training loss 0.00003893 and valid loss : -0.94163402 :  \n",
      "Epoch 721 : valid accuracy :94.32487488 with total prob : 99.70989990 \n",
      "26.272406339645386\n",
      "Epoch 722 : Training loss 0.00003893 and valid loss : -0.94163267 :  \n",
      "Epoch 722 : valid accuracy :94.32487488 with total prob : 99.70979309 \n",
      "26.586671829223633\n",
      "Epoch 723 : Training loss 0.00003892 and valid loss : -0.94163132 :  \n",
      "Epoch 723 : valid accuracy :94.32487488 with total prob : 99.70968628 \n",
      "27.08125591278076\n",
      "Epoch 724 : Training loss 0.00003891 and valid loss : -0.94162999 :  \n",
      "Epoch 724 : valid accuracy :94.32487488 with total prob : 99.70959473 \n",
      "26.81030249595642\n",
      "Epoch 725 : Training loss 0.00003891 and valid loss : -0.94162866 :  \n",
      "Epoch 725 : valid accuracy :94.32487488 with total prob : 99.70948792 \n",
      "26.54260540008545\n",
      "Epoch 726 : Training loss 0.00003890 and valid loss : -0.94162735 :  \n",
      "Epoch 726 : valid accuracy :94.32487488 with total prob : 99.70938110 \n",
      "26.198067903518677\n",
      "Epoch 727 : Training loss 0.00003889 and valid loss : -0.94162604 :  \n",
      "Epoch 727 : valid accuracy :94.32487488 with total prob : 99.70926666 \n",
      "26.586841344833374\n",
      "Epoch 728 : Training loss 0.00003889 and valid loss : -0.94162474 :  \n",
      "Epoch 728 : valid accuracy :94.32487488 with total prob : 99.70915222 \n",
      "26.97855019569397\n",
      "Epoch 729 : Training loss 0.00003888 and valid loss : -0.94162346 :  \n",
      "Epoch 729 : valid accuracy :94.32487488 with total prob : 99.70905304 \n",
      "27.023032426834106\n",
      "Epoch 730 : Training loss 0.00003887 and valid loss : -0.94162218 :  \n",
      "Epoch 730 : valid accuracy :94.32487488 with total prob : 99.70893860 \n",
      "26.697744607925415\n",
      "Epoch 731 : Training loss 0.00003887 and valid loss : -0.94162091 :  \n",
      "Epoch 731 : valid accuracy :94.32487488 with total prob : 99.70882416 \n",
      "26.77811360359192\n",
      "Epoch 732 : Training loss 0.00003886 and valid loss : -0.94161964 :  \n",
      "Epoch 732 : valid accuracy :94.32487488 with total prob : 99.70871735 \n",
      "26.550586938858032\n",
      "Epoch 733 : Training loss 0.00003885 and valid loss : -0.94161839 :  \n",
      "Epoch 733 : valid accuracy :94.32487488 with total prob : 99.70859528 \n",
      "26.679140090942383\n",
      "Epoch 734 : Training loss 0.00003885 and valid loss : -0.94161715 :  \n",
      "Epoch 734 : valid accuracy :94.32487488 with total prob : 99.70846558 \n",
      "26.599761724472046\n",
      "Epoch 735 : Training loss 0.00003884 and valid loss : -0.94161591 :  \n",
      "Epoch 735 : valid accuracy :94.32487488 with total prob : 99.70835114 \n",
      "26.586048126220703\n",
      "Epoch 736 : Training loss 0.00003883 and valid loss : -0.94161468 :  \n",
      "Epoch 736 : valid accuracy :94.32487488 with total prob : 99.70824432 \n",
      "26.541555881500244\n",
      "Epoch 737 : Training loss 0.00003883 and valid loss : -0.94161346 :  \n",
      "Epoch 737 : valid accuracy :94.32487488 with total prob : 99.70811462 \n",
      "26.53551483154297\n",
      "Epoch 738 : Training loss 0.00003882 and valid loss : -0.94161225 :  \n",
      "Epoch 738 : valid accuracy :94.32487488 with total prob : 99.70800018 \n",
      "27.546684980392456\n",
      "Epoch 739 : Training loss 0.00003881 and valid loss : -0.94161105 :  \n",
      "Epoch 739 : valid accuracy :94.32487488 with total prob : 99.70787811 \n",
      "27.005825519561768\n",
      "Epoch 740 : Training loss 0.00003881 and valid loss : -0.94160985 :  \n",
      "Epoch 740 : valid accuracy :94.32487488 with total prob : 99.70775604 \n",
      "26.850654363632202\n",
      "Epoch 741 : Training loss 0.00003880 and valid loss : -0.94160867 :  \n",
      "Epoch 741 : valid accuracy :94.32487488 with total prob : 99.70762634 \n",
      "26.50334405899048\n",
      "Epoch 742 : Training loss 0.00003879 and valid loss : -0.94160749 :  \n",
      "Epoch 742 : valid accuracy :94.32487488 with total prob : 99.70750427 \n",
      "25.801889419555664\n",
      "Epoch 743 : Training loss 0.00003878 and valid loss : -0.94160632 :  \n",
      "Epoch 743 : valid accuracy :94.32487488 with total prob : 99.70737457 \n",
      "26.904415130615234\n",
      "Epoch 744 : Training loss 0.00003878 and valid loss : -0.94160515 :  \n",
      "Epoch 744 : valid accuracy :94.32487488 with total prob : 99.70724487 \n",
      "26.79401397705078\n",
      "Epoch 745 : Training loss 0.00003877 and valid loss : -0.94160400 :  \n",
      "Epoch 745 : valid accuracy :94.32487488 with total prob : 99.70711517 \n",
      "27.744776010513306\n",
      "Epoch 746 : Training loss 0.00003876 and valid loss : -0.94160285 :  \n",
      "Epoch 746 : valid accuracy :94.32487488 with total prob : 99.70697784 \n",
      "27.688990592956543\n",
      "Epoch 747 : Training loss 0.00003876 and valid loss : -0.94160171 :  \n",
      "Epoch 747 : valid accuracy :94.32487488 with total prob : 99.70685577 \n",
      "29.300443410873413\n",
      "Epoch 748 : Training loss 0.00003875 and valid loss : -0.94160058 :  \n",
      "Epoch 748 : valid accuracy :94.32487488 with total prob : 99.70671844 \n",
      "27.71018147468567\n",
      "Epoch 749 : Training loss 0.00003874 and valid loss : -0.94159945 :  \n",
      "Epoch 749 : valid accuracy :94.32487488 with total prob : 99.70657349 \n",
      "27.807074308395386\n",
      "Epoch 750 : Training loss 0.00003873 and valid loss : -0.94159833 :  \n",
      "Epoch 750 : valid accuracy :94.32487488 with total prob : 99.70644379 \n",
      "27.369080543518066\n",
      "Epoch 751 : Training loss 0.00003873 and valid loss : -0.94159722 :  \n",
      "Epoch 751 : valid accuracy :94.32487488 with total prob : 99.70630646 \n",
      "26.828677654266357\n",
      "Epoch 752 : Training loss 0.00003872 and valid loss : -0.94159612 :  \n",
      "Epoch 752 : valid accuracy :94.32487488 with total prob : 99.70617676 \n",
      "27.242404460906982\n",
      "Epoch 753 : Training loss 0.00003871 and valid loss : -0.94159502 :  \n",
      "Epoch 753 : valid accuracy :94.32487488 with total prob : 99.70603180 \n",
      "27.18594741821289\n",
      "Epoch 754 : Training loss 0.00003871 and valid loss : -0.94159394 :  \n",
      "Epoch 754 : valid accuracy :94.32487488 with total prob : 99.70589447 \n",
      "27.101473569869995\n",
      "Epoch 755 : Training loss 0.00003870 and valid loss : -0.94159285 :  \n",
      "Epoch 755 : valid accuracy :94.32487488 with total prob : 99.70576477 \n",
      "26.77675485610962\n",
      "Epoch 756 : Training loss 0.00003869 and valid loss : -0.94159178 :  \n",
      "Epoch 756 : valid accuracy :94.32487488 with total prob : 99.70560455 \n",
      "26.856282711029053\n",
      "Epoch 757 : Training loss 0.00003868 and valid loss : -0.94159071 :  \n",
      "Epoch 757 : valid accuracy :94.32487488 with total prob : 99.70547485 \n",
      "26.50935125350952\n",
      "Epoch 758 : Training loss 0.00003868 and valid loss : -0.94158965 :  \n",
      "Epoch 758 : valid accuracy :94.32487488 with total prob : 99.70532990 \n",
      "26.452190160751343\n",
      "Epoch 759 : Training loss 0.00003867 and valid loss : -0.94158860 :  \n",
      "Epoch 759 : valid accuracy :94.32487488 with total prob : 99.70517731 \n",
      "26.59530210494995\n",
      "Epoch 760 : Training loss 0.00003866 and valid loss : -0.94158755 :  \n",
      "Epoch 760 : valid accuracy :94.32487488 with total prob : 99.70503235 \n",
      "26.675797700881958\n",
      "Epoch 761 : Training loss 0.00003865 and valid loss : -0.94158651 :  \n",
      "Epoch 761 : valid accuracy :94.32487488 with total prob : 99.70487976 \n",
      "26.82572078704834\n",
      "Epoch 762 : Training loss 0.00003865 and valid loss : -0.94158547 :  \n",
      "Epoch 762 : valid accuracy :94.32487488 with total prob : 99.70474243 \n",
      "27.7712140083313\n",
      "Epoch 763 : Training loss 0.00003864 and valid loss : -0.94158445 :  \n",
      "Epoch 763 : valid accuracy :94.32487488 with total prob : 99.70458984 \n",
      "28.307613611221313\n",
      "Epoch 764 : Training loss 0.00003863 and valid loss : -0.94158342 :  \n",
      "Epoch 764 : valid accuracy :94.32487488 with total prob : 99.70444489 \n",
      "28.535088062286377\n",
      "Epoch 765 : Training loss 0.00003862 and valid loss : -0.94158241 :  \n",
      "Epoch 765 : valid accuracy :94.32487488 with total prob : 99.70429230 \n",
      "27.916372776031494\n",
      "Epoch 766 : Training loss 0.00003862 and valid loss : -0.94158140 :  \n",
      "Epoch 766 : valid accuracy :94.32487488 with total prob : 99.70413971 \n",
      "27.508028745651245\n",
      "Epoch 767 : Training loss 0.00003861 and valid loss : -0.94158040 :  \n",
      "Epoch 767 : valid accuracy :94.32487488 with total prob : 99.70397949 \n",
      "27.435653686523438\n",
      "Epoch 768 : Training loss 0.00003860 and valid loss : -0.94157940 :  \n",
      "Epoch 768 : valid accuracy :94.32487488 with total prob : 99.70382690 \n",
      "26.926830053329468\n",
      "Epoch 769 : Training loss 0.00003859 and valid loss : -0.94157841 :  \n",
      "Epoch 769 : valid accuracy :94.32487488 with total prob : 99.70367432 \n",
      "26.509662628173828\n",
      "Epoch 770 : Training loss 0.00003859 and valid loss : -0.94157742 :  \n",
      "Epoch 770 : valid accuracy :94.32487488 with total prob : 99.70352173 \n",
      "27.207863330841064\n",
      "Epoch 771 : Training loss 0.00003858 and valid loss : -0.94157645 :  \n",
      "Epoch 771 : valid accuracy :94.32487488 with total prob : 99.70336914 \n",
      "26.865142822265625\n",
      "Epoch 772 : Training loss 0.00003857 and valid loss : -0.94157547 :  \n",
      "Epoch 772 : valid accuracy :94.32487488 with total prob : 99.70320129 \n",
      "26.52060866355896\n",
      "Epoch 773 : Training loss 0.00003856 and valid loss : -0.94157450 :  \n",
      "Epoch 773 : valid accuracy :94.32487488 with total prob : 99.70305634 \n",
      "27.152623414993286\n",
      "Epoch 774 : Training loss 0.00003856 and valid loss : -0.94157354 :  \n",
      "Epoch 774 : valid accuracy :94.32487488 with total prob : 99.70290375 \n",
      "26.957298040390015\n",
      "Epoch 775 : Training loss 0.00003855 and valid loss : -0.94157258 :  \n",
      "Epoch 775 : valid accuracy :94.32487488 with total prob : 99.70272827 \n",
      "26.765684843063354\n",
      "Epoch 776 : Training loss 0.00003854 and valid loss : -0.94157163 :  \n",
      "Epoch 776 : valid accuracy :94.32487488 with total prob : 99.70257568 \n",
      "26.957918167114258\n",
      "Epoch 777 : Training loss 0.00003853 and valid loss : -0.94157069 :  \n",
      "Epoch 777 : valid accuracy :94.32487488 with total prob : 99.70240784 \n",
      "27.150575637817383\n",
      "Epoch 778 : Training loss 0.00003853 and valid loss : -0.94156974 :  \n",
      "Epoch 778 : valid accuracy :94.32487488 with total prob : 99.70224762 \n",
      "27.23663568496704\n",
      "Epoch 779 : Training loss 0.00003852 and valid loss : -0.94156881 :  \n",
      "Epoch 779 : valid accuracy :94.32487488 with total prob : 99.70207977 \n",
      "26.938838481903076\n",
      "Epoch 780 : Training loss 0.00003851 and valid loss : -0.94156788 :  \n",
      "Epoch 780 : valid accuracy :94.32487488 with total prob : 99.70191956 \n",
      "26.741378784179688\n",
      "Epoch 781 : Training loss 0.00003850 and valid loss : -0.94156695 :  \n",
      "Epoch 781 : valid accuracy :94.32487488 with total prob : 99.70174408 \n",
      "26.60550045967102\n",
      "Epoch 782 : Training loss 0.00003849 and valid loss : -0.94156603 :  \n",
      "Epoch 782 : valid accuracy :94.32487488 with total prob : 99.70159149 \n",
      "26.256150722503662\n",
      "Epoch 783 : Training loss 0.00003849 and valid loss : -0.94156511 :  \n",
      "Epoch 783 : valid accuracy :94.32487488 with total prob : 99.70140076 \n",
      "27.185922622680664\n",
      "Epoch 784 : Training loss 0.00003848 and valid loss : -0.94156420 :  \n",
      "Epoch 784 : valid accuracy :94.32487488 with total prob : 99.70124817 \n",
      "27.757814168930054\n",
      "Epoch 785 : Training loss 0.00003847 and valid loss : -0.94156329 :  \n",
      "Epoch 785 : valid accuracy :94.32487488 with total prob : 99.70108032 \n",
      "28.024020195007324\n",
      "Epoch 786 : Training loss 0.00003846 and valid loss : -0.94156238 :  \n",
      "Epoch 786 : valid accuracy :94.32487488 with total prob : 99.70090485 \n",
      "27.211013078689575\n",
      "Epoch 787 : Training loss 0.00003845 and valid loss : -0.94156148 :  \n",
      "Epoch 787 : valid accuracy :94.32487488 with total prob : 99.70073700 \n",
      "27.29515790939331\n",
      "Epoch 788 : Training loss 0.00003845 and valid loss : -0.94156059 :  \n",
      "Epoch 788 : valid accuracy :94.32487488 with total prob : 99.70054626 \n",
      "26.955212354660034\n",
      "Epoch 789 : Training loss 0.00003844 and valid loss : -0.94155969 :  \n",
      "Epoch 789 : valid accuracy :94.32487488 with total prob : 99.70037842 \n",
      "27.789387702941895\n",
      "Epoch 790 : Training loss 0.00003843 and valid loss : -0.94155880 :  \n",
      "Epoch 790 : valid accuracy :94.32487488 with total prob : 99.70020294 \n",
      "27.156692504882812\n",
      "Epoch 791 : Training loss 0.00003842 and valid loss : -0.94155792 :  \n",
      "Epoch 791 : valid accuracy :94.32487488 with total prob : 99.70001984 \n",
      "27.228405475616455\n",
      "Epoch 792 : Training loss 0.00003841 and valid loss : -0.94155704 :  \n",
      "Epoch 792 : valid accuracy :94.32487488 with total prob : 99.69985199 \n",
      "26.769999980926514\n",
      "Epoch 793 : Training loss 0.00003841 and valid loss : -0.94155616 :  \n",
      "Epoch 793 : valid accuracy :94.32487488 with total prob : 99.69966125 \n",
      "26.716264247894287\n",
      "Epoch 794 : Training loss 0.00003840 and valid loss : -0.94155528 :  \n",
      "Epoch 794 : valid accuracy :94.32487488 with total prob : 99.69948578 \n",
      "26.85889458656311\n",
      "Epoch 795 : Training loss 0.00003839 and valid loss : -0.94155441 :  \n",
      "Epoch 795 : valid accuracy :94.32487488 with total prob : 99.69931030 \n",
      "27.02621555328369\n",
      "Epoch 796 : Training loss 0.00003838 and valid loss : -0.94155354 :  \n",
      "Epoch 796 : valid accuracy :94.32487488 with total prob : 99.69912720 \n",
      "27.297977209091187\n",
      "Epoch 797 : Training loss 0.00003837 and valid loss : -0.94155268 :  \n",
      "Epoch 797 : valid accuracy :94.32487488 with total prob : 99.69893646 \n",
      "27.110036373138428\n",
      "Epoch 798 : Training loss 0.00003837 and valid loss : -0.94155181 :  \n",
      "Epoch 798 : valid accuracy :94.32487488 with total prob : 99.69875336 \n",
      "34.97199559211731\n",
      "Epoch 799 : Training loss 0.00003836 and valid loss : -0.94155095 :  \n",
      "Epoch 799 : valid accuracy :94.32487488 with total prob : 99.69857025 \n",
      "28.02001190185547\n",
      "22377.719012260437\n"
     ]
    }
   ],
   "source": [
    "#labels1=labels[loc]\n",
    "a=time.time()\n",
    "\n",
    "epochs = 800\n",
    "valid_loss=0\n",
    "accuracy=0\n",
    "valid_loss_min=np.Inf\n",
    "\n",
    "\n",
    "b=time.time()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = torch.exp(model(vinputs))\n",
    "    valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "del(output)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==vlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "#print ('valid accuracy :{0:.8f} with total prob : {3:.8f} and  valid loss : {2:.8f} ,  time {1:.6f} '.format(accuracy*100 , time.time()-b ,test_loss,propabilities))\n",
    "print ('Epoch  : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities))\n",
    "\n",
    "####\n",
    "#print(inputs.shape[0])\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "#batch_size=50\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    c=time.time()\n",
    "    running_loss = 0\n",
    "    #for i, x in enumerate(inputs):\n",
    "    for i in range(0,inputs.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #indices = [i:i+batch_size]\n",
    "        #print(i+batch_size)\n",
    "        batch_x, batch_y = inputs[i:i+batch_size], labels1[i:i+batch_size]\n",
    "        \n",
    "        #x2=x[None,:]\n",
    "        output = model.forward(batch_x)\n",
    "        \n",
    "        #output = model.forward(x2)\n",
    "        #l2=labels1[i][None]\n",
    "        #print(l2)\n",
    "        #loss = Fonction_de_perte(output, l2)\n",
    "        loss = Fonction_de_perte(output, batch_y)\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        accuracy=0\n",
    "        #print(l2)\n",
    "####\n",
    "\n",
    "####\n",
    "        b=time.time()\n",
    "        with torch.no_grad():\n",
    "            ##\n",
    "            #with torch.no_grad():\n",
    "            #for i, x in enumerate(vinputs):\n",
    "             #   x2=x[None,:]\n",
    "              #  output = torch.exp(model(x2))\n",
    "               # l2=vlabels1[i][None]\n",
    "                #valid_loss1+=Fonction_de_perte(output, l2)\n",
    "            #test_loss=test_loss/len(vinputs)\n",
    "            ##\n",
    "                \n",
    "            model.eval()\n",
    "            output = torch.exp(model(vinputs))\n",
    "            valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "        top_p , top_c = output.topk(1, dim=1)\n",
    "        del(output)\n",
    "        propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "        equals = top_c==vlabels1.view(*top_c.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        print('Epoch {2} : Training loss {0:.8f} and valid loss : {1:.8f} :  '.format(running_loss/len(inputs),valid_loss, e))\n",
    "   \n",
    "        print ('Epoch {2} : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities, e))\n",
    "        print(time.time()-c)\n",
    "        del(top_p);del(top_c)\n",
    "        del(propabilities)\n",
    "        del(equals)\n",
    "        del(accuracy)\n",
    "        model.train()\n",
    "    #print('validation loss with iterations {0}'.format(valid_loss1/len(vinputs) ) )   \n",
    "        train_losses.append(running_loss/len(inputs))\n",
    "        valid_losses.append(valid_loss)\n",
    "        if (valid_loss<valid_loss_min):\n",
    "            print('validation loss decreased , saving model ({:.8f} ==> {:.8f})'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(),'dataset2_600_800_RNN_Bin.pth')\n",
    "            no_learning=0\n",
    "            valid_loss_min=valid_loss\n",
    "        else:\n",
    "            no_learning+=1\n",
    "        if(no_learning==10):\n",
    "            no_learning=0\n",
    "            #model.load_state_dict(torch.load('2mod_temp_25_RNN_B.pth'))\n",
    "print(time.time()-a)\n",
    "#torch.save(model.state_dict(),'dataset2_600_800_RNN_Bin#2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T21:02:23.626282Z",
     "iopub.status.busy": "2021-08-29T21:02:23.625645Z",
     "iopub.status.idle": "2021-08-29T21:02:23.878624Z",
     "shell.execute_reply": "2021-08-29T21:02:23.879067Z"
    },
    "papermill": {
     "duration": 0.509107,
     "end_time": "2021-08-29T21:02:23.879237",
     "exception": false,
     "start_time": "2021-08-29T21:02:23.370130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6fb1d05710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "\n",
    "\n",
    "\n",
    "Tr=np.array(train_losses)\n",
    "Te=np.array(valid_losses)\n",
    "\n",
    "Tr=np.reshape(Tr, (len(Tr),1))\n",
    "Te=np.reshape(Te, (len(Te),1))\n",
    "\n",
    "# fit on training data column\n",
    "scale = StandardScaler().fit(Tr)\n",
    "tain_losses = scale.transform(Tr)\n",
    "scale = StandardScaler().fit(Te)\n",
    "test_losses = scale.transform(Te)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "plt.plot(tain_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='valid loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T21:02:24.595256Z",
     "iopub.status.busy": "2021-08-29T21:02:24.594584Z",
     "iopub.status.idle": "2021-08-29T21:09:16.018839Z",
     "shell.execute_reply": "2021-08-29T21:09:16.019268Z"
    },
    "papermill": {
     "duration": 411.889333,
     "end_time": "2021-08-29T21:09:16.019466",
     "exception": false,
     "start_time": "2021-08-29T21:02:24.130133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "test accuracy :94.35510254 with total prob : 99.70970154 and  test loss : -0.94197810 ,  time 6.42537355 \n",
      "la prcision de detection globale: 94.1978104956058 \n",
      "detection des communication normal: 91.31065544 with accuracy 91.38126071 ( 348169/381007 )\n",
      "details normal classed udp :8.61874, pluies 0.00000 , jam 0.00000 (ou 100.00000,0.00000,0.00000) \n",
      "detection du deni de service par udp flood 99.67815787 with accuracy 100.00000000 ( 200722/200722 )\n",
      "detection udp flood 100\n",
      "=====================\n",
      "<================================>\n",
      "Total_time\n",
      "411.4201691150665\n"
     ]
    }
   ],
   "source": [
    "a=time.time()\n",
    "summm=[]\n",
    "sum1=[]\n",
    "sum2=[]\n",
    "sum3=[]\n",
    "sum4=[]\n",
    "\n",
    "\n",
    "#tinputs =torch_tensor[:,:] \n",
    "#tlabels1=labels[:]\n",
    "model.eval()\n",
    "print('=====================')\n",
    "b=time.time()\n",
    "output = torch.exp(model(tinputs))\n",
    "test_loss=Fonction_de_perte(output, tlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "del(output)\n",
    "\n",
    "#####\n",
    "######\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==tlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "#model.train()\n",
    "\n",
    "####\n",
    "###\n",
    "print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.8f} '.format(accuracy*100 , time.time()-b ,test_loss ,propabilities))\n",
    "class_correct = list(0. for i in range (4))\n",
    "class_total = list(0. for i in range (4))\n",
    "\n",
    "C_n_udp=0\n",
    "C_n_pluies=0\n",
    "C_n_jam=0\n",
    "C_n_total=0\n",
    "\n",
    "\n",
    "C_u_normal=0\n",
    "C_u_jam=0\n",
    "C_u_pluies=0\n",
    "C_u_total=0\n",
    "\n",
    "C_p_normal=0\n",
    "C_p_udp=0\n",
    "C_p_jam=0\n",
    "C_p_total=0\n",
    "\n",
    "C_j_normal=0\n",
    "C_j_udp=0\n",
    "C_j_pluies=0\n",
    "C_j_total=0\n",
    "\n",
    "for i, x in enumerate(tinputs):\n",
    "    optimizer.zero_grad()\n",
    "    x2=x[None,:]\n",
    "    with torch.no_grad():\n",
    "        output = torch.exp(model(x2))\n",
    "    out=output.detach().numpy()*100\n",
    " \n",
    "    l3=tlabels1[i].item()\n",
    "  \n",
    "    if(l3==0):\n",
    "        summm.append(out[0][0])\n",
    "        sum1.append(out[0][0])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_n_udp+=1\n",
    "            #if(top_c[i][0]==2):\n",
    "            #    C_n_pluies+=1\n",
    "            #if(top_c[i][0]==3):\n",
    "            #    C_n_jam +=1\n",
    "            \n",
    "            C_n_total +=1\n",
    "            \n",
    "    if(l3==1):\n",
    "        summm.append(out[0][1])\n",
    "        sum2.append(out[0][1])\n",
    "        if(top_c[i][0]!=l3):\n",
    "           # if(top_c[i][0]==3):\n",
    "            #    C_u_jam+=1\n",
    "           # if(top_c[i][0]==2):\n",
    "           #     C_u_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_u_normal +=1\n",
    "            \n",
    "            C_u_total +=1\n",
    "\n",
    "    if(l3==2):\n",
    "        summm.append(out[0][2])\n",
    "        sum3.append(out[0][2])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_p_udp+=1\n",
    "            if(top_c[i][0]==3):\n",
    "                C_p_jam+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_p_normal +=1\n",
    "            \n",
    "            C_p_total +=1\n",
    "\n",
    "    if(l3==3):\n",
    "        summm.append(out[0][3])\n",
    "        sum4.append(out[0][3])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_j_udp+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_j_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_j_normal +=1\n",
    "            \n",
    "            C_j_total +=1\n",
    "\n",
    "    class_total[l3]+=1\n",
    "    class_correct[l3]+=equals[i][0]\n",
    "    #print(output)\n",
    "print('la prcision de detection globale: {0} '.format(mean(summm)))\n",
    "print('detection des communication normal: {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum1), class_correct[0]*100/class_total[0] ,class_correct[0] ,class_total[0]))\n",
    "if(C_n_total!=0):\n",
    "    print('details normal classed udp :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_n_udp*100/class_total[0],C_n_pluies*100/class_total[0],C_n_jam*100/class_total[0],C_n_udp*100/C_n_total,C_n_pluies*100/C_n_total,C_n_jam*100/C_n_total))\n",
    "else:\n",
    "    print('detection normal 100')\n",
    "\n",
    "print('detection du deni de service par udp flood {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum2), class_correct[1]*100/class_total[1] ,class_correct[1] ,class_total[1]))\n",
    "if(C_u_total!=0):\n",
    "    print('details udp classed normal :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_u_normal*100/class_total[1],C_u_pluies*100/class_total[1],C_u_jam*100/class_total[1],C_u_normal*100/C_u_total,C_u_pluies*100/C_u_total,C_u_jam*100/C_u_total))\n",
    "else:\n",
    "    print('detection udp flood 100')\n",
    "    \n",
    "#print('detection du deni naturel : pluies et orages : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum3), class_correct[2]*100/class_total[2] ,class_correct[2] ,class_total[2]))\n",
    "#if(C_p_total!=0):\n",
    "#    print('details pluies classed udp :{0:.5f}, normal {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_p_udp*100/class_total[2],C_p_normal*100/class_total[2],C_p_jam*100/class_total[2],C_p_udp*100/C_p_total,C_p_normal*100/C_p_total,C_p_jam*100/C_p_total))\n",
    "#else:\n",
    " #   print('detection pluies et orages 100')\n",
    "\n",
    "#print('detection du deni naturel : jam : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum4), class_correct[3]*100/class_total[3] ,class_correct[3] ,class_total[3]))\n",
    "#if(C_j_total!=0):\n",
    "#    print('details jam classed udp :{0:.5f}, pluies {1:.5f} , normal {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_j_udp*100/class_total[3],C_j_pluies*100/class_total[3],C_j_normal*100/class_total[3],C_j_udp*100/C_j_total,C_j_pluies*100/C_j_total,C_j_normal*100/C_j_total))\n",
    "#else:\n",
    "#    print('detection brouillage 100')\n",
    "print('=====================')\n",
    "\n",
    "print('<================================>')\n",
    "print('Total_time')\n",
    "print(time.time()-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T21:09:16.520619Z",
     "iopub.status.busy": "2021-08-29T21:09:16.517596Z",
     "iopub.status.idle": "2021-08-29T21:09:16.637496Z",
     "shell.execute_reply": "2021-08-29T21:09:16.636819Z"
    },
    "papermill": {
     "duration": 0.369842,
     "end_time": "2021-08-29T21:09:16.637663",
     "exception": false,
     "start_time": "2021-08-29T21:09:16.267821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "textfile = open(\"3rnn_B800_Train.txt\", \"w\")\n",
    "for element in tain_losses:\n",
    "    textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()\n",
    "\n",
    "textfile = open(\"3rnn_B800_Test.txt\", \"w\")\n",
    "for element in test_losses:\n",
    "    textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T21:09:17.178274Z",
     "iopub.status.busy": "2021-08-29T21:09:17.168822Z",
     "iopub.status.idle": "2021-08-29T21:10:24.229735Z",
     "shell.execute_reply": "2021-08-29T21:10:24.229175Z"
    },
    "papermill": {
     "duration": 67.336542,
     "end_time": "2021-08-29T21:10:24.229918",
     "exception": false,
     "start_time": "2021-08-29T21:09:16.893376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improt time 436.8660554885864\n",
      "test accuracy :87.21089935 with total prob : 98.23064423 and  test loss : -0.88857718 ,  time 451.51497340 \n",
      "test accuracy :97.05250549 with total prob : 98.95993042 and  test loss : -0.96950958 ,  time 461.73171234 \n",
      "test accuracy :95.03559875 with total prob : 98.78422546 and  test loss : -0.94117027 ,  time 472.04053998 \n",
      "test accuracy :100.00000000 with total prob : 98.80587769 and  test loss : -0.98805868 ,  time 479.46223712 \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path0+\"dataset-sat-on/FinaldatasetN.csv\")\n",
    "print('improt time '+str(time.time()-a))\n",
    "\n",
    "a=time.time()\n",
    "#df=df[['channel','Next_Current_diff','Next_Pre_diff','size', 'packet_type','DataQueueLen','lossRate','SNext_Current_diff','SNext_Pre_diff','snir','throughput','Flow Bytes_s','Flow Packets_s','meanT_b_2P','minT_b_2P','maxT_b_2P','label']]     \n",
    "#df=df[['channel','Next_Current_diff','Next_Pre_diff','size', 'packet_type','lossRate','SNext_Current_diff','SNext_Pre_diff','snir','throughput','Flow Bytes_s','Flow Packets_s','meanT_b_2P','minT_b_2P','maxT_b_2P','label']]     \n",
    "df=df[['channel','Next_Current_diff','Next_Pre_diff','size','snir','throughput','packet_type','SNext_Current_diff','SNext_Pre_diff','Flow Bytes_s','Flow Packets_s','meanT_b_2P','minT_b_2P','maxT_b_2P','label']]     \n",
    "\n",
    "\n",
    "#df=df.to_numpy()\n",
    "df_Normal=df[0:1000000].copy()\n",
    "#print(df_Normal[0][1])\n",
    "#print(df_Normal[-1][1])\n",
    "df_UDP1=df[1000000:2000000].copy()\n",
    "#print(df_UDP1[0][1])\n",
    "#print(df_UDP1[-1][1])\n",
    "df_UDP2=df[2000000:3000000].copy()\n",
    "#print(df_UDP2[0][1])\n",
    "#print(df_UDP2[-1][1])\n",
    "df_jam1=df[3000000:4000000].copy()\n",
    "#print(df_jam1[0][1])\n",
    "#print(df_jam1[-1][1])\n",
    "df_jam2=df[2000000:2500000].copy()\n",
    "#print(df_jam2[0][1])\n",
    "#print(df_jam2[-1][1])\n",
    "df_pluies=df[2500000:3000000].copy()\n",
    "#print(df_pluies[0][1])\n",
    "#print(df_pluies[-1][1])\n",
    "del(df)\n",
    "\n",
    "X=df_Normal.drop(columns = ['label']).copy()\n",
    "y=df_Normal[['label']].copy()\n",
    "del(df_Normal)\n",
    "X=X.values\n",
    "y=y.values\n",
    "X = torch.tensor(X)\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "def mttest(X,y):\n",
    "    t=[]\n",
    "    for j in y:\n",
    "        i=j[0]\n",
    "    #    print(i)\n",
    "        if (i=='Normal'):\n",
    "            t.append(int(0))\n",
    "        #t.append(int(1))\n",
    "        if (i=='DDOS_UDP_FLOOD'):\n",
    "            t.append(int(1))\n",
    "        if (i=='PLUIES_ET_ORAGES'):\n",
    "            t.append(int(0))\n",
    "        if (i=='BROUILLAGE_Trafic'):\n",
    "            t.append(int(1))\n",
    "    y = torch.LongTensor(t)\n",
    "    model.eval()\n",
    "    output = torch.exp(model(X))\n",
    "\n",
    "    test_loss=Fonction_de_perte(output, y)\n",
    "    top_p , top_c = output.topk(1, dim=1)\n",
    "    del(output)\n",
    "    model.eval()\n",
    "    propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "    equals = top_c==y.view(*top_c.shape)\n",
    "    accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "    print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.8f} '.format(accuracy*100 , time.time()-b ,test_loss ,propabilities))\n",
    "    del(X)\n",
    "    del(y)\n",
    "####\n",
    "\n",
    "mttest(X,y)\n",
    "del(X);del(y)\n",
    "X1=df_UDP1.drop(columns = ['label']).copy()\n",
    "y1=df_UDP1[['label']].copy()\n",
    "del(df_UDP1)\n",
    "X1=X1.values\n",
    "y1=y1.values\n",
    "X1 = torch.tensor(X1)\n",
    "mttest(X1,y1)\n",
    "del(X1);del(y1)\n",
    "\n",
    "X2=df_UDP2.drop(columns = ['label']).copy()\n",
    "y2=df_UDP2[['label']].copy()\n",
    "del(df_UDP2)\n",
    "X2=X2.values\n",
    "y2=y2.values\n",
    "X2 = torch.tensor(X2)\n",
    "mttest(X2,y2)\n",
    "del(X2);del(y2)\n",
    "\n",
    "X3=df_jam1.drop(columns = ['label']).copy()\n",
    "y3=df_jam1[['label']].copy()\n",
    "del(df_jam1)\n",
    "X3=X3.values\n",
    "y3=y3.values\n",
    "X3 = torch.tensor(X3)\n",
    "mttest(X3,y3)\n",
    "del(X3);del(y3)\n",
    "\n",
    "#X4=df_jam2.drop(columns = ['label']).copy()\n",
    "#y4=df_jam2[['label']].copy()\n",
    "#X5=df_pluies.drop(columns = ['label']).copy()\n",
    "#y5=df_pluies[['label']].copy()\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.248515,
     "end_time": "2021-08-29T21:10:24.730251",
     "exception": false,
     "start_time": "2021-08-29T21:10:24.481736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.243568,
     "end_time": "2021-08-29T21:10:25.222979",
     "exception": false,
     "start_time": "2021-08-29T21:10:24.979411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22925.890544,
   "end_time": "2021-08-29T21:10:26.676673",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-29T14:48:20.786129",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
