{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T11:26:30.861955Z",
     "iopub.status.busy": "2021-08-22T11:26:30.861227Z",
     "iopub.status.idle": "2021-08-22T11:26:31.352720Z",
     "shell.execute_reply": "2021-08-22T11:26:31.351664Z",
     "shell.execute_reply.started": "2021-08-21T19:57:46.585733Z"
    },
    "papermill": {
     "duration": 0.52077,
     "end_time": "2021-08-22T11:26:31.352923",
     "exception": false,
     "start_time": "2021-08-22T11:26:30.832153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30497\n",
      "tensor([0, 0, 0,  ..., 0, 3, 0])\n",
      "190988\n",
      "143243\n",
      "143244\n",
      "0.8400425910949707\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "path0 ='../'\n",
    "df = pd.read_csv(path0+\"Dataset_S022Final.csv\")\n",
    "\n",
    "a=time.time()\n",
    "df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','packet_type','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromHL','rcvdPKFromLL','sentDownPK','DropPKByQueue','snir','throughput','label']]         \n",
    "\n",
    "\n",
    "df_Normal=df[0:76064].copy()\n",
    "#print(df_Normal)\n",
    "df_UDP=df[76064:214037].copy()\n",
    "#print(df_UDP)\n",
    "df_pluies=df[214037:426866].copy()\n",
    "\n",
    "#print(df_Normal2)\n",
    "df_jam=df[462481:-1].copy()\n",
    "\n",
    "X=df_Normal.drop(columns = ['label']).copy()\n",
    "y=df_Normal[['label']].copy()\n",
    "#print(y.columns)\n",
    "X1=df_UDP.drop(columns = ['label']).copy()\n",
    "y1=df_UDP[['label']].copy()\n",
    "X2=df_pluies.drop(columns = ['label']).copy()\n",
    "y2=df_pluies[['label']].copy()\n",
    "X3=df_jam.drop(columns = ['label']).copy()\n",
    "y3=df_jam[['label']].copy()\n",
    "\n",
    "train=0.4\n",
    "\n",
    "\n",
    "xcol=X.columns\n",
    "ycol=y.columns\n",
    "\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=train,shuffle=False)\n",
    "X_train1, X_rem1, y_train1, y_rem1 = train_test_split(X1,y1, train_size=train,shuffle=False)\n",
    "X_train2, X_rem2, y_train2, y_rem2 = train_test_split(X2,y2, train_size=train,shuffle=False)\n",
    "X_train3, X_rem3, y_train3, y_rem3 = train_test_split(X3,y3, train_size=train,shuffle=False)\n",
    "\n",
    "validation=0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,shuffle=False)\n",
    "X_valid1, X_test1, y_valid1, y_test1 = train_test_split(X_rem1,y_rem1, test_size=0.5,shuffle=False)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_rem2,y_rem2, test_size=0.5,shuffle=False)\n",
    "X_valid3, X_test3, y_valid3, y_test3 = train_test_split(X_rem3,y_rem3, test_size=0.5,shuffle=False)\n",
    "\n",
    "\n",
    "X_train=np.concatenate((X_train, X_train1, X_train2,X_train3))\n",
    "X_valid=np.concatenate((X_valid, X_valid1, X_valid2,X_valid3))\n",
    "X_test=np.concatenate((X_test, X_test1, X_test2,X_test3))\n",
    "\n",
    "y_train=np.concatenate((y_train, y_train1, y_train2,y_train3))\n",
    "y_valid=np.concatenate((y_valid, y_valid1, y_valid2,y_valid3))\n",
    "y_test=np.concatenate((y_test, y_test1, y_test2,y_test3))\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns= xcol)\n",
    "X_valid = pd.DataFrame(X_valid, columns= xcol)\n",
    "X_test = pd.DataFrame(X_test, columns= xcol)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= ycol)\n",
    "y_valid = pd.DataFrame(y_valid, columns= ycol)\n",
    "y_test = pd.DataFrame(y_test, columns= ycol)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a-time.time()\n",
    "X_train1=X_train.values\n",
    "y_train1=y_train.values\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "torch_tensor = torch.tensor(X_train1)\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "t=[]\n",
    "test=0\n",
    "test0=0\n",
    "\n",
    "for j in y_train1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        test0+=1\n",
    "    #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(2))\n",
    "        test+=1\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(3))\n",
    "\n",
    "labels = torch.LongTensor(t)\n",
    "\n",
    "bigX = X_valid\n",
    "#[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','throughput']]  ,'channel'       \n",
    "bigY = y_valid['label']\n",
    "#print(bigY)\n",
    "X_valid1=bigX.values\n",
    "y_valid1=bigY.values\n",
    "\n",
    "vtorch_tensor = torch.tensor(X_valid1)\n",
    "v=[]\n",
    "\n",
    "for i in y_valid1:\n",
    "    #i=j[0]\n",
    "    #print(i)\n",
    "    if (i=='Normal'):\n",
    "        v.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        v.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        v.append(int(2))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        v.append(int(3))\n",
    "\n",
    "vlabels = torch.LongTensor(v)\n",
    "\n",
    "\n",
    "X_test1=X_test.values\n",
    "y_test1=y_test.values\n",
    "\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "ttorch_tensor = torch.tensor(X_test1)\n",
    "t=[]\n",
    "\n",
    "for j in y_test1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(2))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(3))\n",
    "\n",
    "tlabels = torch.LongTensor(t)\n",
    "#print(torch_tensor[-1])\n",
    "#print(labels[-1])\n",
    "print(len(labels))\n",
    "print(len(vlabels))\n",
    "print(len(tlabels))\n",
    "\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T11:26:31.394749Z",
     "iopub.status.busy": "2021-08-22T11:26:31.393860Z",
     "iopub.status.idle": "2021-08-22T11:26:31.407870Z",
     "shell.execute_reply": "2021-08-22T11:26:31.407270Z",
     "shell.execute_reply.started": "2021-08-21T19:56:44.432193Z"
    },
    "papermill": {
     "duration": 0.046422,
     "end_time": "2021-08-22T11:26:31.408008",
     "exception": false,
     "start_time": "2021-08-22T11:26:31.361586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 4\n",
    "#num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.02\n",
    "\n",
    "input_size = 19\n",
    "sequence_length = 28\n",
    "hidden_size = 132\n",
    "num_layers = 2\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers,batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        x=x.view(-1,1,19)\n",
    "        #print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, (h0,c0) )  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        #out = self.fc(out)\n",
    "        x = F.log_softmax(self.fc(out), dim=1)\n",
    "        # out: (n, 10)\n",
    "        return x\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "\n",
    "class My_module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1,8,3,padding=1)\n",
    "        self.conv2=nn.Conv2d(8,12,3,padding=1)\n",
    "        self.conv3=nn.Conv2d(12,18,3,padding=1)\n",
    "        self.fc1 = nn.Linear(18*6*3,350)\n",
    "        self.fc2 = nn.Linear(350,400)\n",
    "        self.fc3 = nn.Linear(56, 64)\n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "        self.fc5 = nn.Linear(400, 4)\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.pool=nn.MaxPool2d(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        #x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.shape)\n",
    "\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=x.view(-1,18*6*3)\n",
    "        #print(x.shape)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        #x = self.dropout(F.relu(self.fc3(x))) \n",
    "        #x = self.dropout(F.relu(self.fc4(x))) \n",
    "    \n",
    "        x = F.log_softmax(self.fc5(x), dim=1)        #print(x.shape)        \n",
    "        return x\n",
    "Fonction_de_perte = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "#indices = [0,3, 299:303]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T11:26:31.440930Z",
     "iopub.status.busy": "2021-08-22T11:26:31.435602Z",
     "iopub.status.idle": "2021-08-22T17:10:24.787076Z",
     "shell.execute_reply": "2021-08-22T17:10:24.787601Z",
     "shell.execute_reply.started": "2021-08-21T19:57:54.687822Z"
    },
    "papermill": {
     "duration": 20633.369289,
     "end_time": "2021-08-22T17:10:24.787795",
     "exception": false,
     "start_time": "2021-08-22T11:26:31.418506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190988\n",
      "190988\n",
      "Epoch  : valid accuracy :15.94493198 with total prob : 26.37909889 \n",
      "Epoch 0 : Training loss 0.19419755 and valid loss : -0.63190191 :  \n",
      "Epoch 0 : valid accuracy :62.87427521 with total prob : 91.07614136 \n",
      "412.74151968955994\n",
      "validation loss decreased , saving model (inf ==> -0.63190191)\n",
      "Epoch 1 : Training loss 0.02461937 and valid loss : -0.74962582 :  \n",
      "Epoch 1 : valid accuracy :74.24655914 with total prob : 93.10474396 \n",
      "409.82932019233704\n",
      "validation loss decreased , saving model (-0.63190191 ==> -0.74962582)\n",
      "Epoch 2 : Training loss 0.01329628 and valid loss : -0.86454940 :  \n",
      "Epoch 2 : valid accuracy :88.47483063 with total prob : 93.32664490 \n",
      "414.2958724498749\n",
      "validation loss decreased , saving model (-0.74962582 ==> -0.86454940)\n",
      "Epoch 3 : Training loss 0.00922967 and valid loss : -0.93254144 :  \n",
      "Epoch 3 : valid accuracy :94.23706818 with total prob : 97.75609589 \n",
      "410.9073030948639\n",
      "validation loss decreased , saving model (-0.86454940 ==> -0.93254144)\n",
      "Epoch 4 : Training loss 0.00727796 and valid loss : -0.94569259 :  \n",
      "Epoch 4 : valid accuracy :94.60357666 with total prob : 98.86429596 \n",
      "410.53767585754395\n",
      "validation loss decreased , saving model (-0.93254144 ==> -0.94569259)\n",
      "Epoch 5 : Training loss 0.00611483 and valid loss : -0.95206014 :  \n",
      "Epoch 5 : valid accuracy :95.32543182 with total prob : 99.36832428 \n",
      "413.04346656799316\n",
      "validation loss decreased , saving model (-0.94569259 ==> -0.95206014)\n",
      "Epoch 6 : Training loss 0.00529959 and valid loss : -0.95376362 :  \n",
      "Epoch 6 : valid accuracy :95.39035034 with total prob : 99.56951141 \n",
      "407.48223876953125\n",
      "validation loss decreased , saving model (-0.95206014 ==> -0.95376362)\n",
      "Epoch 7 : Training loss 0.00476080 and valid loss : -0.95418805 :  \n",
      "Epoch 7 : valid accuracy :95.39662933 with total prob : 99.59397888 \n",
      "416.2825062274933\n",
      "validation loss decreased , saving model (-0.95376362 ==> -0.95418805)\n",
      "Epoch 8 : Training loss 0.00446885 and valid loss : -0.95465425 :  \n",
      "Epoch 8 : valid accuracy :95.41129303 with total prob : 99.56289673 \n",
      "410.5143654346466\n",
      "validation loss decreased , saving model (-0.95418805 ==> -0.95465425)\n",
      "Epoch 9 : Training loss 0.00430271 and valid loss : -0.95550320 :  \n",
      "Epoch 9 : valid accuracy :95.47203064 with total prob : 99.48716736 \n",
      "415.01561522483826\n",
      "validation loss decreased , saving model (-0.95465425 ==> -0.95550320)\n",
      "Epoch 10 : Training loss 0.00422141 and valid loss : -0.95708261 :  \n",
      "Epoch 10 : valid accuracy :95.65982056 with total prob : 99.37265778 \n",
      "413.22523498535156\n",
      "validation loss decreased , saving model (-0.95550320 ==> -0.95708261)\n",
      "Epoch 11 : Training loss 0.00412334 and valid loss : -0.95927012 :  \n",
      "Epoch 11 : valid accuracy :96.08148193 with total prob : 99.34355927 \n",
      "411.064510345459\n",
      "validation loss decreased , saving model (-0.95708261 ==> -0.95927012)\n",
      "Epoch 12 : Training loss 0.00392985 and valid loss : -0.96140753 :  \n",
      "Epoch 12 : valid accuracy :96.28882599 with total prob : 99.40852356 \n",
      "411.65972566604614\n",
      "validation loss decreased , saving model (-0.95927012 ==> -0.96140753)\n",
      "Epoch 13 : Training loss 0.00363981 and valid loss : -0.96325806 :  \n",
      "Epoch 13 : valid accuracy :96.42286682 with total prob : 99.42566681 \n",
      "414.6227433681488\n",
      "validation loss decreased , saving model (-0.96140753 ==> -0.96325806)\n",
      "Epoch 14 : Training loss 0.00336012 and valid loss : -0.96541531 :  \n",
      "Epoch 14 : valid accuracy :96.63509369 with total prob : 99.38636017 \n",
      "415.5852417945862\n",
      "validation loss decreased , saving model (-0.96325806 ==> -0.96541531)\n",
      "Epoch 15 : Training loss 0.00315533 and valid loss : -0.96821682 :  \n",
      "Epoch 15 : valid accuracy :96.95272827 with total prob : 99.33097839 \n",
      "419.9569616317749\n",
      "validation loss decreased , saving model (-0.96541531 ==> -0.96821682)\n",
      "Epoch 16 : Training loss 0.00298185 and valid loss : -0.97104312 :  \n",
      "Epoch 16 : valid accuracy :97.40161896 with total prob : 99.41918182 \n",
      "412.89900183677673\n",
      "validation loss decreased , saving model (-0.96821682 ==> -0.97104312)\n",
      "Epoch 17 : Training loss 0.00282433 and valid loss : -0.97308025 :  \n",
      "Epoch 17 : valid accuracy :97.56847382 with total prob : 99.57140350 \n",
      "413.31172919273376\n",
      "validation loss decreased , saving model (-0.97104312 ==> -0.97308025)\n",
      "Epoch 18 : Training loss 0.00269686 and valid loss : -0.97431783 :  \n",
      "Epoch 18 : valid accuracy :97.60198212 with total prob : 99.66191864 \n",
      "414.7417197227478\n",
      "validation loss decreased , saving model (-0.97308025 ==> -0.97431783)\n",
      "Epoch 19 : Training loss 0.00261325 and valid loss : -0.97526852 :  \n",
      "Epoch 19 : valid accuracy :97.61872864 with total prob : 99.68312073 \n",
      "408.8083083629608\n",
      "validation loss decreased , saving model (-0.97431783 ==> -0.97526852)\n",
      "Epoch 20 : Training loss 0.00259138 and valid loss : -0.97637451 :  \n",
      "Epoch 20 : valid accuracy :97.66062164 with total prob : 99.63883972 \n",
      "411.037810087204\n",
      "validation loss decreased , saving model (-0.97526852 ==> -0.97637451)\n",
      "Epoch 21 : Training loss 0.00218528 and valid loss : -0.97792026 :  \n",
      "Epoch 21 : valid accuracy :97.87702942 with total prob : 99.58831024 \n",
      "410.2945919036865\n",
      "validation loss decreased , saving model (-0.97637451 ==> -0.97792026)\n",
      "Epoch 22 : Training loss 0.00209782 and valid loss : -0.97960404 :  \n",
      "Epoch 22 : valid accuracy :98.13254547 with total prob : 99.63593292 \n",
      "412.87259554862976\n",
      "validation loss decreased , saving model (-0.97792026 ==> -0.97960404)\n",
      "Epoch 23 : Training loss 0.00196834 and valid loss : -0.98068556 :  \n",
      "Epoch 23 : valid accuracy :98.22190094 with total prob : 99.69512177 \n",
      "411.4304084777832\n",
      "validation loss decreased , saving model (-0.97960404 ==> -0.98068556)\n",
      "Epoch 24 : Training loss 0.00180833 and valid loss : -0.98137305 :  \n",
      "Epoch 24 : valid accuracy :98.28263855 with total prob : 99.72567749 \n",
      "408.7037115097046\n",
      "validation loss decreased , saving model (-0.98068556 ==> -0.98137305)\n",
      "Epoch 25 : Training loss 0.00176356 and valid loss : -0.98187465 :  \n",
      "Epoch 25 : valid accuracy :98.33290863 with total prob : 99.75042725 \n",
      "419.5733094215393\n",
      "validation loss decreased , saving model (-0.98137305 ==> -0.98187465)\n",
      "Epoch 26 : Training loss 0.00173195 and valid loss : -0.98224155 :  \n",
      "Epoch 26 : valid accuracy :98.37129974 with total prob : 99.77282715 \n",
      "411.5514466762543\n",
      "validation loss decreased , saving model (-0.98187465 ==> -0.98224155)\n",
      "Epoch 27 : Training loss 0.00169252 and valid loss : -0.98250806 :  \n",
      "Epoch 27 : valid accuracy :98.38596344 with total prob : 99.78781891 \n",
      "408.79111409187317\n",
      "validation loss decreased , saving model (-0.98224155 ==> -0.98250806)\n",
      "Epoch 28 : Training loss 0.00166627 and valid loss : -0.98275958 :  \n",
      "Epoch 28 : valid accuracy :98.39643097 with total prob : 99.79916382 \n",
      "411.2686502933502\n",
      "validation loss decreased , saving model (-0.98250806 ==> -0.98275958)\n",
      "Epoch 29 : Training loss 0.00168526 and valid loss : -0.98295511 :  \n",
      "Epoch 29 : valid accuracy :98.39922333 with total prob : 99.80260468 \n",
      "412.56160712242126\n",
      "validation loss decreased , saving model (-0.98275958 ==> -0.98295511)\n",
      "Epoch 30 : Training loss 0.00165231 and valid loss : -0.98316880 :  \n",
      "Epoch 30 : valid accuracy :98.41108704 with total prob : 99.80274200 \n",
      "407.7806146144867\n",
      "validation loss decreased , saving model (-0.98295511 ==> -0.98316880)\n",
      "Epoch 31 : Training loss 0.00161195 and valid loss : -0.98339100 :  \n",
      "Epoch 31 : valid accuracy :98.43203735 with total prob : 99.80081940 \n",
      "411.51070070266724\n",
      "validation loss decreased , saving model (-0.98316880 ==> -0.98339100)\n",
      "Epoch 32 : Training loss 0.00158808 and valid loss : -0.98360068 :  \n",
      "Epoch 32 : valid accuracy :98.45646667 with total prob : 99.79794312 \n",
      "412.6667392253876\n",
      "validation loss decreased , saving model (-0.98339100 ==> -0.98360068)\n",
      "Epoch 33 : Training loss 0.00157738 and valid loss : -0.98384954 :  \n",
      "Epoch 33 : valid accuracy :98.48997498 with total prob : 99.79650116 \n",
      "416.24592876434326\n",
      "validation loss decreased , saving model (-0.98360068 ==> -0.98384954)\n",
      "Epoch 34 : Training loss 0.00155885 and valid loss : -0.98408422 :  \n",
      "Epoch 34 : valid accuracy :98.51511383 with total prob : 99.79641724 \n",
      "410.60966753959656\n",
      "validation loss decreased , saving model (-0.98384954 ==> -0.98408422)\n",
      "Epoch 35 : Training loss 0.00154219 and valid loss : -0.98434899 :  \n",
      "Epoch 35 : valid accuracy :98.54792023 with total prob : 99.79731750 \n",
      "410.55459213256836\n",
      "validation loss decreased , saving model (-0.98408422 ==> -0.98434899)\n",
      "Epoch 36 : Training loss 0.00147163 and valid loss : -0.98466325 :  \n",
      "Epoch 36 : valid accuracy :98.56886292 with total prob : 99.80738831 \n",
      "411.51841139793396\n",
      "validation loss decreased , saving model (-0.98434899 ==> -0.98466325)\n",
      "Epoch 37 : Training loss 0.00148775 and valid loss : -0.98491655 :  \n",
      "Epoch 37 : valid accuracy :98.58561707 with total prob : 99.80764008 \n",
      "410.35043358802795\n",
      "validation loss decreased , saving model (-0.98466325 ==> -0.98491655)\n",
      "Epoch 38 : Training loss 0.00139619 and valid loss : -0.98523693 :  \n",
      "Epoch 38 : valid accuracy :98.60237122 with total prob : 99.80429077 \n",
      "410.8084292411804\n",
      "validation loss decreased , saving model (-0.98491655 ==> -0.98523693)\n",
      "Epoch 39 : Training loss 0.00141266 and valid loss : -0.98551954 :  \n",
      "Epoch 39 : valid accuracy :98.61634064 with total prob : 99.80373383 \n",
      "407.51615595817566\n",
      "validation loss decreased , saving model (-0.98523693 ==> -0.98551954)\n",
      "Epoch 40 : Training loss 0.00140893 and valid loss : -0.98581275 :  \n",
      "Epoch 40 : valid accuracy :98.63099670 with total prob : 99.79934692 \n",
      "416.8305115699768\n",
      "validation loss decreased , saving model (-0.98551954 ==> -0.98581275)\n",
      "Epoch 41 : Training loss 0.00141271 and valid loss : -0.98616881 :  \n",
      "Epoch 41 : valid accuracy :98.64217377 with total prob : 99.78450775 \n",
      "411.9359369277954\n",
      "validation loss decreased , saving model (-0.98581275 ==> -0.98616881)\n",
      "Epoch 42 : Training loss 0.00138270 and valid loss : -0.98646619 :  \n",
      "Epoch 42 : valid accuracy :98.65473175 with total prob : 99.77665710 \n",
      "419.3928806781769\n",
      "validation loss decreased , saving model (-0.98616881 ==> -0.98646619)\n",
      "Epoch 43 : Training loss 0.00136121 and valid loss : -0.98675147 :  \n",
      "Epoch 43 : valid accuracy :98.67498016 with total prob : 99.76757050 \n",
      "411.2568531036377\n",
      "validation loss decreased , saving model (-0.98646619 ==> -0.98675147)\n",
      "Epoch 44 : Training loss 0.00133153 and valid loss : -0.98702837 :  \n",
      "Epoch 44 : valid accuracy :98.70011139 with total prob : 99.75469971 \n",
      "416.1308879852295\n",
      "validation loss decreased , saving model (-0.98675147 ==> -0.98702837)\n",
      "Epoch 45 : Training loss 0.00127921 and valid loss : -0.98726276 :  \n",
      "Epoch 45 : valid accuracy :98.72035217 with total prob : 99.74472046 \n",
      "413.49778842926025\n",
      "validation loss decreased , saving model (-0.98702837 ==> -0.98726276)\n",
      "Epoch 46 : Training loss 0.00122198 and valid loss : -0.98745677 :  \n",
      "Epoch 46 : valid accuracy :98.73571777 with total prob : 99.73744202 \n",
      "415.50177693367004\n",
      "validation loss decreased , saving model (-0.98726276 ==> -0.98745677)\n",
      "Epoch 47 : Training loss 0.00117489 and valid loss : -0.98765467 :  \n",
      "Epoch 47 : valid accuracy :98.75735474 with total prob : 99.72831726 \n",
      "411.76841139793396\n",
      "validation loss decreased , saving model (-0.98745677 ==> -0.98765467)\n",
      "Epoch 48 : Training loss 0.00114622 and valid loss : -0.98781557 :  \n",
      "Epoch 48 : valid accuracy :98.77899933 with total prob : 99.72587585 \n",
      "412.70538210868835\n",
      "validation loss decreased , saving model (-0.98765467 ==> -0.98781557)\n",
      "Epoch 49 : Training loss 0.00112662 and valid loss : -0.98800772 :  \n",
      "Epoch 49 : valid accuracy :98.82018280 with total prob : 99.72083282 \n",
      "413.51667761802673\n",
      "validation loss decreased , saving model (-0.98781557 ==> -0.98800772)\n",
      "20633.314098596573\n"
     ]
    }
   ],
   "source": [
    "#labels1=labels[loc]\n",
    "a=time.time()\n",
    "inputs=torch_tensor[:,:] \n",
    "labels1=labels[:]\n",
    "print(len(inputs))\n",
    "print(len(labels1))\n",
    "vinputs =vtorch_tensor[:,:] \n",
    "vlabels1=vlabels[:]\n",
    "\n",
    "epochs = 50\n",
    "valid_loss=0\n",
    "accuracy=0\n",
    "valid_loss_min=np.Inf\n",
    "\n",
    "####33  !!!!!!!!!! This shit cost alot of time ----> do not use it \n",
    "#b=time.time()\n",
    "#with torch.no_grad():\n",
    "   # for i, x in enumerate(vinputs):\n",
    "       # x2=x[None,:]\n",
    "       # output = torch.exp(model(x2))\n",
    "       # l2=vlabels1[i][None]\n",
    "       # test_loss+=Fonction_de_perte(output, l2)\n",
    "     #   output = torch.exp(output)\n",
    "      #  top_p , top_c = output.topk(1, dim=1)\n",
    "     #   equals = top_c==vlabels1[i].view(*top_c.shape)\n",
    "    #    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "   # tain_losses.append(running_loss/len(inputs))\n",
    "   # test_losses.append(test_loss/len(vinputs))\n",
    "   # print ('test accuracy :{0}, test loss : {2} ,  time {1} '.format(accuracy*100/len(vinputs) , time.time()-b ,test_loss/len(vinputs) ))\n",
    "\n",
    "######## ---> use this :) \n",
    "b=time.time()\n",
    "with torch.no_grad():\n",
    "    output = torch.exp(model(vinputs))\n",
    "    valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==vlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "#print ('valid accuracy :{0:.8f} with total prob : {3:.8f} and  valid loss : {2:.8f} ,  time {1:.6f} '.format(accuracy*100 , time.time()-b ,test_loss,propabilities))\n",
    "print ('Epoch  : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities))\n",
    "\n",
    "####\n",
    "#print(inputs.shape[0])\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "for e in range(epochs):\n",
    "    c=time.time()\n",
    "    running_loss = 0\n",
    "    for i, x in enumerate(inputs):\n",
    "        optimizer.zero_grad()\n",
    "        x2=x[None,:]\n",
    "        output = model.forward(x2)\n",
    "        l2=labels1[i][None]\n",
    "        #print(l2)\n",
    "        loss = Fonction_de_perte(output, l2)\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        accuracy=0\n",
    "        #print(l2)\n",
    "  \n",
    "        b=time.time()\n",
    "        with torch.no_grad():\n",
    "            ##\n",
    "            #with torch.no_grad():\n",
    "            #for i, x in enumerate(vinputs):\n",
    "             #   x2=x[None,:]\n",
    "              #  output = torch.exp(model(x2))\n",
    "               # l2=vlabels1[i][None]\n",
    "                #valid_loss1+=Fonction_de_perte(output, l2)\n",
    "            #test_loss=test_loss/len(vinputs)\n",
    "            ##\n",
    "                \n",
    "            model.eval()\n",
    "            output = torch.exp(model(vinputs))\n",
    "            valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "        top_p , top_c = output.topk(1, dim=1)\n",
    "        propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "        equals = top_c==vlabels1.view(*top_c.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        print('Epoch {2} : Training loss {0:.8f} and valid loss : {1:.8f} :  '.format(running_loss/len(inputs),valid_loss, e))\n",
    "   \n",
    "        print ('Epoch {2} : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities, e))\n",
    "        print(time.time()-c)\n",
    "        #print('validation loss with iterations {0}'.format(valid_loss1/len(vinputs) ) )   \n",
    "        train_losses.append(running_loss/len(inputs))\n",
    "        valid_losses.append(valid_loss)\n",
    "        if (valid_loss<valid_loss_min):\n",
    "            print('validation loss decreased , saving model ({:.8f} ==> {:.8f})'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(),'mod_temp6_50_LSTM.pth')\n",
    "            valid_loss_min=valid_loss\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T17:10:24.873199Z",
     "iopub.status.busy": "2021-08-22T17:10:24.840034Z",
     "iopub.status.idle": "2021-08-22T17:12:43.648241Z",
     "shell.execute_reply": "2021-08-22T17:12:43.647413Z",
     "shell.execute_reply.started": "2021-08-22T11:25:14.338990Z"
    },
    "papermill": {
     "duration": 138.836695,
     "end_time": "2021-08-22T17:12:43.648416",
     "exception": false,
     "start_time": "2021-08-22T17:10:24.811721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "test accuracy :98.71617889 with total prob : 99.65184021 and  test loss : -0.98714451 ,  time 5.68342543 \n",
      "la pr√©cision de detection globale: 98.7144510256901 \n",
      "detection des communication normal: 97.80467222 with accuracy 97.73304114 ( 78938/80769 )\n",
      "details normal classed udp :0.00000, pluies 2.06515 , jam 0.20181 (ou 0.00000,91.09776,8.90224) \n",
      "detection du deni de service par udp flood 99.99386580 with accuracy 99.99161426 ( 35772/35775 )\n",
      "details udp classed normal :0.00839, pluies 0.00000 , jam 0.00000 (ou 100.00000,0.00000,0.00000) \n",
      "detection du deni naturel : pluies et orages : 99.71147213 with accuracy 99.97806344 ( 22788/22793 )\n",
      "details pluies classed udp :0.00000, normal 0.02194 , jam 0.00000 (ou 0.00000,100.00000,0.00000) \n",
      "detection du deni naturel : jam : 99.99056030 with accuracy 100.00000000 ( 3907/3907 )\n",
      "detection brouillage 100\n",
      "=====================\n",
      "<================================>\n",
      "Total_time\n",
      "138.54505395889282\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "\n",
    "\n",
    "\n",
    "Tr=np.array(train_losses)\n",
    "Te=np.array(valid_losses)\n",
    "\n",
    "Tr=np.reshape(Tr, (len(Tr),1))\n",
    "Te=np.reshape(Te, (len(Te),1))\n",
    "\n",
    "# fit on training data column\n",
    "scale = StandardScaler().fit(Tr)\n",
    "tain_losses = scale.transform(Tr)\n",
    "scale = StandardScaler().fit(Te)\n",
    "test_losses = scale.transform(Te)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "plt.plot(tain_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='valid loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a=time.time()\n",
    "summm=[]\n",
    "sum1=[]\n",
    "sum2=[]\n",
    "sum3=[]\n",
    "sum4=[]\n",
    "\n",
    "tinputs =ttorch_tensor[:,:] \n",
    "tlabels1=tlabels[:]\n",
    "\n",
    "\n",
    "#tinputs =torch_tensor[:,:] \n",
    "#tlabels1=labels[:]\n",
    "\n",
    "print('=====================')\n",
    "b=time.time()\n",
    "output = torch.exp(model(tinputs))\n",
    "test_loss=Fonction_de_perte(output, tlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==tlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "model.train()\n",
    "print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.8f} '.format(accuracy*100 , time.time()-b ,test_loss ,propabilities))\n",
    "\n",
    "class_correct = list(0. for i in range (4))\n",
    "class_total = list(0. for i in range (4))\n",
    "\n",
    "C_n_udp=0\n",
    "C_n_pluies=0\n",
    "C_n_jam=0\n",
    "C_n_total=0\n",
    "\n",
    "\n",
    "C_u_normal=0\n",
    "C_u_jam=0\n",
    "C_u_pluies=0\n",
    "C_u_total=0\n",
    "\n",
    "C_p_normal=0\n",
    "C_p_udp=0\n",
    "C_p_jam=0\n",
    "C_p_total=0\n",
    "\n",
    "C_j_normal=0\n",
    "C_j_udp=0\n",
    "C_j_pluies=0\n",
    "C_j_total=0\n",
    "\n",
    "for i, x in enumerate(tinputs):\n",
    "    optimizer.zero_grad()\n",
    "    x2=x[None,:]\n",
    "    with torch.no_grad():\n",
    "        output = torch.exp(model(x2))\n",
    "    out=output.detach().numpy()*100\n",
    " \n",
    "    l3=tlabels1[i].item()\n",
    "  \n",
    "    if(l3==0):\n",
    "        summm.append(out[0][0])\n",
    "        sum1.append(out[0][0])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_n_udp+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_n_pluies+=1\n",
    "            if(top_c[i][0]==3):\n",
    "                C_n_jam +=1\n",
    "            \n",
    "            C_n_total +=1\n",
    "            \n",
    "    if(l3==1):\n",
    "        summm.append(out[0][1])\n",
    "        sum2.append(out[0][1])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==3):\n",
    "                C_u_jam+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_u_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_u_normal +=1\n",
    "            \n",
    "            C_u_total +=1\n",
    "\n",
    "    if(l3==2):\n",
    "        summm.append(out[0][2])\n",
    "        sum3.append(out[0][2])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_p_udp+=1\n",
    "            if(top_c[i][0]==3):\n",
    "                C_p_jam+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_p_normal +=1\n",
    "            \n",
    "            C_p_total +=1\n",
    "\n",
    "    if(l3==3):\n",
    "        summm.append(out[0][3])\n",
    "        sum4.append(out[0][3])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_j_udp+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_j_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_j_normal +=1\n",
    "            \n",
    "            C_j_total +=1\n",
    "\n",
    "    class_total[l3]+=1\n",
    "    class_correct[l3]+=equals[i][0]\n",
    "    #print(output)\n",
    "print('la pr√©cision de detection globale: {0} '.format(mean(summm)))\n",
    "print('detection des communication normal: {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum1), class_correct[0]*100/class_total[0] ,class_correct[0] ,class_total[0]))\n",
    "if(C_n_total!=0):\n",
    "    print('details normal classed udp :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_n_udp*100/class_total[0],C_n_pluies*100/class_total[0],C_n_jam*100/class_total[0],C_n_udp*100/C_n_total,C_n_pluies*100/C_n_total,C_n_jam*100/C_n_total))\n",
    "else:\n",
    "    print('detection normal 100')\n",
    "\n",
    "print('detection du deni de service par udp flood {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum2), class_correct[1]*100/class_total[1] ,class_correct[1] ,class_total[1]))\n",
    "if(C_u_total!=0):\n",
    "    print('details udp classed normal :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_u_normal*100/class_total[1],C_u_pluies*100/class_total[1],C_u_jam*100/class_total[1],C_u_normal*100/C_u_total,C_u_pluies*100/C_u_total,C_u_jam*100/C_u_total))\n",
    "else:\n",
    "    print('detection udp flood 100')\n",
    "    \n",
    "print('detection du deni naturel : pluies et orages : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum3), class_correct[2]*100/class_total[2] ,class_correct[2] ,class_total[2]))\n",
    "if(C_p_total!=0):\n",
    "    print('details pluies classed udp :{0:.5f}, normal {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_p_udp*100/class_total[2],C_p_normal*100/class_total[2],C_p_jam*100/class_total[2],C_p_udp*100/C_p_total,C_p_normal*100/C_p_total,C_p_jam*100/C_p_total))\n",
    "else:\n",
    "    print('detection pluies et orages 100')\n",
    "\n",
    "print('detection du deni naturel : jam : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum4), class_correct[3]*100/class_total[3] ,class_correct[3] ,class_total[3]))\n",
    "if(C_j_total!=0):\n",
    "    print('details jam classed udp :{0:.5f}, pluies {1:.5f} , normal {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_j_udp*100/class_total[3],C_j_pluies*100/class_total[3],C_j_normal*100/class_total[3],C_j_udp*100/C_j_total,C_j_pluies*100/C_j_total,C_j_normal*100/C_j_total))\n",
    "else:\n",
    "    print('detection brouillage 100')\n",
    "print('=====================')\n",
    "\n",
    "print('<================================>')\n",
    "print('Total_time')\n",
    "print(time.time()-a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20792.946093,
   "end_time": "2021-08-22T17:12:45.498638",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-22T11:26:12.552545",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
