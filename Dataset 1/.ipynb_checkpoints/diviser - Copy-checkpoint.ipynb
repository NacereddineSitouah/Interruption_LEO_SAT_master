{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import torch\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.12393593788147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#path=\"src/cvs/datasets1/small/\"\n",
    "a=time.time()\n",
    "path0 ='src/cvs/datasets1/'\n",
    "df = pd.read_csv(path0+\"small/Dataset_S022Final.csv\")\n",
    "print(time.time()-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5787215232849121\n"
     ]
    }
   ],
   "source": [
    "###ending results\n",
    "#df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','sentPK','duration(ms)','droppedPKWrongPort','size','throughput','label']]   #,'channel'      \n",
    "#df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','DataQueueLen','passedUpPk','sentDownPK','DropPKByQueue','snir','throughput','label']]  \n",
    "a=time.time()\n",
    "df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','packet_type','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromHL','rcvdPKFromLL','sentDownPK','DropPKByQueue','snir','throughput','label']]         \n",
    "#for cnn delete sentdownpk\n",
    "#df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','packet_type','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromHL','rcvdPKFromLL','DropPKByQueue','snir','throughput','label']]         \n",
    "\n",
    "#df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromLL','sentDownPK','DropPKByQueue','snir','throughput','label']]         \n",
    "\n",
    "\n",
    "df_Normal=df[0:76064].copy()\n",
    "#print(df_Normal)\n",
    "df_UDP=df[76064:214037].copy()\n",
    "#print(df_UDP)\n",
    "df_pluies=df[214037:426866].copy()\n",
    "\n",
    "#print(df_Normal2)\n",
    "df_jam=df[462481:-1].copy()\n",
    "\n",
    "X=df_Normal.drop(columns = ['label']).copy()\n",
    "y=df_Normal[['label']].copy()\n",
    "#print(y.columns)\n",
    "X1=df_UDP.drop(columns = ['label']).copy()\n",
    "y1=df_UDP[['label']].copy()\n",
    "X2=df_pluies.drop(columns = ['label']).copy()\n",
    "y2=df_pluies[['label']].copy()\n",
    "X3=df_jam.drop(columns = ['label']).copy()\n",
    "y3=df_jam[['label']].copy()\n",
    "\n",
    "train=0.4\n",
    "\n",
    "\n",
    "xcol=X.columns\n",
    "ycol=y.columns\n",
    "\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=train,shuffle=False)\n",
    "X_train1, X_rem1, y_train1, y_rem1 = train_test_split(X1,y1, train_size=train,shuffle=False)\n",
    "X_train2, X_rem2, y_train2, y_rem2 = train_test_split(X2,y2, train_size=train,shuffle=False)\n",
    "X_train3, X_rem3, y_train3, y_rem3 = train_test_split(X3,y3, train_size=train,shuffle=False)\n",
    "\n",
    "validation=0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,shuffle=False)\n",
    "X_valid1, X_test1, y_valid1, y_test1 = train_test_split(X_rem1,y_rem1, test_size=0.5,shuffle=False)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_rem2,y_rem2, test_size=0.5,shuffle=False)\n",
    "X_valid3, X_test3, y_valid3, y_test3 = train_test_split(X_rem3,y_rem3, test_size=0.5,shuffle=False)\n",
    "\n",
    "\n",
    "X_train=np.concatenate((X_train, X_train1, X_train2,X_train3))\n",
    "X_valid=np.concatenate((X_valid, X_valid1, X_valid2,X_valid3))\n",
    "X_test=np.concatenate((X_test, X_test1, X_test2,X_test3))\n",
    "\n",
    "y_train=np.concatenate((y_train, y_train1, y_train2,y_train3))\n",
    "y_valid=np.concatenate((y_valid, y_valid1, y_valid2,y_valid3))\n",
    "y_test=np.concatenate((y_test, y_test1, y_test2,y_test3))\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns= xcol)\n",
    "X_valid = pd.DataFrame(X_valid, columns= xcol)\n",
    "X_test = pd.DataFrame(X_test, columns= xcol)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= ycol)\n",
    "y_valid = pd.DataFrame(y_valid, columns= ycol)\n",
    "y_test = pd.DataFrame(y_test, columns= ycol)\n",
    "\n",
    "#X_train.to_csv(\"csv/datasets1/small/testbed3/Train_test2/X_train.csv\" ,index=False,header=True)\n",
    "#y_train.to_csv(\"csv/datasets1/small/testbed3/Train_test2/y_train.csv\" ,index=False,header=True)\n",
    "#X_valid.to_csv(\"csv/datasets1/small/testbed3/Train_test2/X_valid.csv\" ,index=False,header=True)\n",
    "#y_valid.to_csv(\"csv/datasets1/small/testbed3/Train_test2/y_valid.csv\" ,index=False,header=True)\n",
    "#X_test.to_csv(\"csv/datasets1/small/testbed3/Train_test2/X_test.csv\" ,index=False,header=True)\n",
    "#y_test.to_csv(\"csv/datasets1/small/testbed3/Train_test2/y_test.csv\" ,index=False,header=True)\n",
    "\n",
    "print(time.time()-a)\n",
    "\n",
    "#df1=df.to_numpy()\n",
    "#print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867353\n",
      "76064\n",
      "137973\n",
      "212829\n",
      "jam\n",
      "404871\n",
      "125010\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'csv/datasets1/small/testbed3/Train_test2/X_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1483b8440a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv/datasets1/small/testbed3/Train_test2/X_train.csv\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv/datasets1/small/testbed3/Train_test2/y_train.csv\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv/datasets1/small/testbed3/Train_test2/X_valid.csv\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'csv/datasets1/small/testbed3/Train_test2/X_train.csv'"
     ]
    }
   ],
   "source": [
    "df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromLL','sentDownPK','DropPKByQueue','snir','throughput','label']]         \n",
    "\n",
    "df_Normal=df[0:76064].copy()\n",
    "#print(df_Normal)\n",
    "df_UDP=df[76064:214037].copy()\n",
    "#print(df_UDP)\n",
    "df_pluies=df[214037:426866].copy()\n",
    "df_2Normal=df[426866:462481].copy()\n",
    "#print(df_Normal2)\n",
    "df_jam=df[462481:-1].copy()\n",
    "\n",
    "#print(df_jam)\n",
    "print(len(df))\n",
    "print(len(df_Normal))\n",
    "print(len(df_UDP))\n",
    "print(len(df_pluies))\n",
    "#print(len(df_Normal2))\n",
    "print('jam')\n",
    "print(len(df_jam))\n",
    "\n",
    "df_Normal1=df_Normal[0:20000].copy().to_numpy()\n",
    "#print(df_Normal1)\n",
    "df_Normal2=df_Normal[20000:30000].copy().to_numpy()\n",
    "df_Normal3=df_Normal[30000:60000].copy().to_numpy()\n",
    "\n",
    "df_UDP1=df_UDP[0:20000].copy().to_numpy()\n",
    "df_UDP2=df_UDP[20000:30000].copy().to_numpy()\n",
    "df_UDP3=df_UDP[35000:50000].copy().to_numpy()\n",
    "\n",
    "df_pluies1=df_pluies[0:20000].copy().to_numpy()\n",
    "df_pluies2=df_pluies[20000:30000].copy().to_numpy()\n",
    "df_pluies3=df_pluies[35000:50000].copy().to_numpy()\n",
    "\n",
    "df_2Normal1=df_2Normal[0:15].copy().to_numpy()\n",
    "df_2Normal2=df_2Normal[15:25].copy().to_numpy()\n",
    "df_2Normal3=df_2Normal[25:35].copy().to_numpy()\n",
    "\n",
    "df_jam1=df_jam[0:40000].copy().to_numpy()\n",
    "df_jam2=df_jam[40000:80000].copy().to_numpy()\n",
    "df_jam3=df_jam[80000:145000].copy().to_numpy()\n",
    "\n",
    "\n",
    "train=np.concatenate((df_Normal1, df_UDP1, df_pluies1,df_2Normal1,df_jam1))\n",
    "valid=np.concatenate((df_Normal2, df_UDP2, df_pluies2,df_2Normal2,df_jam2))\n",
    "test=np.concatenate((df_Normal3, df_UDP3, df_pluies3,df_2Normal3,df_jam3))\n",
    "#print(df1[214000:-1])\n",
    "#df = df.drop(columns = ['Unnamed: 0']).copy()\n",
    "col=df.columns\n",
    "\n",
    "train = pd.DataFrame(train, columns= col)\n",
    "valid = pd.DataFrame(valid, columns= col)\n",
    "test = pd.DataFrame(test, columns= col)\n",
    "print(len(test))\n",
    "\n",
    "X_train=train.drop(columns = ['label']).copy()\n",
    "y_train=train['label']\n",
    "X_valid=valid.drop(columns = ['label']).copy()\n",
    "y_valid=valid['label']\n",
    "X_test=test.drop(columns = ['label']).copy()\n",
    "y_test=test['label']\n",
    "\n",
    "X_train.to_csv(\"csv/datasets1/small/testbed3/Train_test2/X_train.csv\" ,index=False,header=True)\n",
    "y_train.to_csv(\"csv/datasets1/small/testbed3/Train_test2/y_train.csv\" ,index=False,header=True)\n",
    "X_valid.to_csv(\"csv/datasets1/small/testbed3/Train_test2/X_valid.csv\" ,index=False,header=True)\n",
    "y_valid.to_csv(\"csv/datasets1/small/testbed3/Train_test2/y_valid.csv\" ,index=False,header=True)\n",
    "X_test.to_csv(\"csv/datasets1/small/testbed3/Train_test2/X_test.csv\" ,index=False,header=True)\n",
    "y_test.to_csv(\"csv/datasets1/small/testbed3/Train_test2/y_test.csv\" ,index=False,header=True)\n",
    "\n",
    "\n",
    "#df1=df.to_numpy()\n",
    "#print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70010\n"
     ]
    }
   ],
   "source": [
    "print(len(valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Next_Current_diff  Next_Pre_diff  SNext_Current_diff  SNext_Pre_diff  \\\n",
      "0                0.000444       0.000936        1.876956e-03    4.409815e-03   \n",
      "1                0.002173       0.002595        2.338491e-03    4.585087e-03   \n",
      "2                0.000344       0.002496        5.425841e-07    3.699871e-03   \n",
      "3                0.000544       0.000881        8.570197e-07    5.305094e-07   \n",
      "4                0.004416       0.004917        6.957262e-06    2.962859e-06   \n",
      "...                   ...            ...                 ...             ...   \n",
      "867348           0.002137       0.002993        3.367043e-06    4.180037e-06   \n",
      "867349           0.010161       0.012193        1.600923e-05    7.346993e-06   \n",
      "867350           0.005054       0.015086        7.963321e-06    9.089832e-06   \n",
      "867351           0.024819       0.029618        3.910237e-05    1.784640e-05   \n",
      "867352           0.028664       0.053027        4.516109e-05    3.195124e-05   \n",
      "\n",
      "        rcvdPK  duration(ms)  droppedPKWrongPort    sentPK      size  \\\n",
      "0          0.0      0.023810                 0.0  0.001489  0.002017   \n",
      "1          0.0      0.238095                 0.0  0.002447  0.100020   \n",
      "2          0.0      0.023810                 0.0  0.003713  0.002017   \n",
      "3          0.0      0.190476                 0.0  0.003713  0.078040   \n",
      "4          0.0      0.238095                 0.0  0.003713  0.100020   \n",
      "...        ...           ...                 ...       ...       ...   \n",
      "867348     0.0      0.023810                 0.0  0.000000  0.001210   \n",
      "867349     0.0      0.011905                 0.0  0.000000  0.001210   \n",
      "867350     0.0      0.023810                 0.0  0.000000  0.001210   \n",
      "867351     0.0      0.011905                 0.0  0.000000  0.001210   \n",
      "867352     0.0      0.011905                 0.0  0.000000  0.001210   \n",
      "\n",
      "         channel  DataQueueLen  passedUpPk  rcvdPKFromHL  rcvdPKFromLL  \\\n",
      "0       0.225806           0.0    0.003384      0.009703      0.000138   \n",
      "1       0.161290           0.0    0.009138      0.016600      0.000194   \n",
      "2       0.225806           0.0    0.014891      0.025123      0.000424   \n",
      "3       0.032258           0.0    0.014891      0.025123      0.000424   \n",
      "4       0.161290           0.0    0.014891      0.025123      0.000424   \n",
      "...          ...           ...         ...           ...           ...   \n",
      "867348  0.161290           0.0    0.517466      0.000000      0.985788   \n",
      "867349  0.193548           0.0    0.517466      0.000000      0.985830   \n",
      "867350  0.161290           0.0    0.517466      0.000000      0.985830   \n",
      "867351  0.193548           0.0    0.517466      0.000000      0.986144   \n",
      "867352  0.193548           0.0    0.517466      0.000000      0.986208   \n",
      "\n",
      "        sentDownPK  DropPKByQueue      snir  throughput              label  \n",
      "0         0.008931            0.0  0.008506    0.000543             Normal  \n",
      "1         0.018672            0.0  0.024010    0.000861             Normal  \n",
      "2         0.026990            0.0  0.039448    0.001772             Normal  \n",
      "3         0.043846            0.0  0.132973    0.001772             Normal  \n",
      "4         0.060433            0.0  0.132973    0.001772             Normal  \n",
      "...            ...            ...       ...         ...                ...  \n",
      "867348    0.065733            0.0  0.992361    0.005397  BROUILLAGE_Trafic  \n",
      "867349    0.065733            0.0  0.992361    0.005397  BROUILLAGE_Trafic  \n",
      "867350    0.065291            0.0  0.992361    0.005397  BROUILLAGE_Trafic  \n",
      "867351    0.065291            0.0  0.992361    0.005397  BROUILLAGE_Trafic  \n",
      "867352    0.065291            0.0  0.992361    0.005397  BROUILLAGE_Trafic  \n",
      "\n",
      "[867353 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#keep usefull features only \n",
    "\n",
    "dff=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromHL','rcvdPKFromLL','sentDownPK','DropPKByQueue','snir','throughput','label']]         \n",
    "\n",
    "print(dff)\n",
    "dff.to_csv(path0+\"small/testbed3/Dataset_S03Filtrer.csv\" ,index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on 20 mb\n",
    "df = pd.read_csv(\"csv/datasets1/small/testbed3/Dataset_S03Filtrer.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Next_Current_diff  Next_Pre_diff  SNext_Current_diff  SNext_Pre_diff  \\\n",
      "214000           0.000465       0.002776        1.091942e-06    5.608772e-06   \n",
      "214001           0.000228       0.000687        3.896632e-06    3.149832e-06   \n",
      "214002           0.001699       0.001911        2.676349e-06    1.428680e-06   \n",
      "214003           0.000546       0.002226        2.088561e-05    8.934143e-06   \n",
      "214004           0.003609       0.004119        5.685520e-06    3.633209e-06   \n",
      "214005           0.000936       0.004506        1.474227e-06    2.714670e-06   \n",
      "214006           0.004324       0.005214        6.811819e-06    3.141745e-06   \n",
      "214007           0.000550       0.004832        8.668532e-07    2.911438e-06   \n",
      "214008           0.000796       0.001335        1.254025e-06    8.040060e-07   \n",
      "214009           0.002496       0.003264        6.712134e-06    3.020449e-06   \n",
      "214010           0.000061       0.002535        9.602839e-08    7.955724e-06   \n",
      "214011           0.001703       0.001749        1.534720e-05    5.855643e-06   \n",
      "214012           0.002512       0.004179        3.957736e-06    4.045656e-06   \n",
      "214013           0.003040       0.005505        4.789838e-06    3.316749e-06   \n",
      "214014           0.002386       0.005379        3.758575e-06    3.241231e-06   \n",
      "214015           0.000100       0.002465        2.431265e-05    1.064399e-05   \n",
      "214016           0.001483       0.001569        2.336244e-06    6.705099e-06   \n",
      "214017           0.000976       0.002438        1.537604e-06    1.468706e-06   \n",
      "214018           0.002037       0.002988        3.210053e-06    1.800041e-06   \n",
      "214019           0.002304       0.004305        3.630659e-06    2.593696e-06   \n",
      "214020           0.000154       0.002438        2.431893e-07    1.468706e-06   \n",
      "214021           0.002759       0.002889        4.347511e-06    1.740525e-06   \n",
      "214022           0.001332       0.004056        2.098398e-06    2.443993e-06   \n",
      "214023           0.003719       0.005008        5.860059e-06    3.017529e-06   \n",
      "214024           0.000566       0.004248        7.605638e-06    5.105792e-06   \n",
      "214025           0.003345       0.003877        5.269570e-06    1.121694e-05   \n",
      "214026           0.000917       0.004225        9.510425e-06    5.604153e-06   \n",
      "214027           0.000335       0.001241        5.277306e-07    3.083852e-06   \n",
      "214028           0.001609       0.001928        2.535676e-06    1.161399e-06   \n",
      "214029           0.001711       0.003292        2.695783e-06    1.983492e-06   \n",
      "214030           0.001464       0.003148        1.099227e-05    5.190105e-06   \n",
      "214031           0.001535       0.002974        1.694929e-05    1.003293e-05   \n",
      "214032           0.003978       0.005466        7.746023e-06    1.393895e-04   \n",
      "214033           0.000939       0.004875        6.602180e-06    6.671352e-06   \n",
      "214034           0.003252       0.004155        6.784392e-06    5.509516e-06   \n",
      "214035           0.000084       0.003307        1.318998e-07    2.553263e-06   \n",
      "\n",
      "          rcvdPK  duration(ms)  droppedPKWrongPort    sentPK      size  \\\n",
      "214000  0.012606      0.892857             0.08471  0.044810  0.857028   \n",
      "214001  0.012606      0.023810             0.08471  0.044810  0.000000   \n",
      "214002  0.012606      1.000000             0.08471  0.044810  0.975600   \n",
      "214003  0.012606      0.011905             0.08471  0.044810  0.870135   \n",
      "214004  0.012606      0.011905             0.08471  0.044810  0.000000   \n",
      "214005  0.012606      1.000000             0.08471  0.044810  0.844323   \n",
      "214006  0.012606      0.916667             0.08471  0.044810  0.872555   \n",
      "214007  0.012606      1.000000             0.08471  0.044810  0.925388   \n",
      "214008  0.012606      0.011905             0.08471  0.044810  0.802984   \n",
      "214009  0.012606      0.880952             0.08471  0.044810  0.851986   \n",
      "214010  0.012606      0.023810             0.08471  0.044810  0.002420   \n",
      "214011  0.012606      0.892857             0.08471  0.044810  0.857028   \n",
      "214012  0.012606      1.000000             0.08471  0.044810  0.925388   \n",
      "214013  0.012606      1.000000             0.08471  0.044810  0.844323   \n",
      "214014  0.012606      0.011905             0.08471  0.044810  0.802984   \n",
      "214015  0.012606      1.000000             0.08471  0.044810  0.925388   \n",
      "214016  0.012606      1.000000             0.08471  0.044810  0.975600   \n",
      "214017  0.012606      0.011905             0.08471  0.044810  0.870135   \n",
      "214018  0.012606      1.000000             0.08471  0.044810  0.981448   \n",
      "214019  0.012606      1.000000             0.08471  0.044810  0.975600   \n",
      "214020  0.012606      0.892857             0.08471  0.044810  0.857028   \n",
      "214021  0.012606      0.011905             0.08471  0.044810  0.814680   \n",
      "214022  0.012606      1.000000             0.08471  0.044810  0.981448   \n",
      "214023  0.012606      1.000000             0.08471  0.044810  0.975600   \n",
      "214024  0.012606      1.000000             0.08471  0.044810  0.981448   \n",
      "214025  0.012606      1.000000             0.08471  0.044810  0.925388   \n",
      "214026  0.012606      1.000000             0.08471  0.044810  0.844323   \n",
      "214027  0.012606      0.023810             0.08471  0.044810  0.002420   \n",
      "214028  0.012606      1.000000             0.08471  0.044810  0.981448   \n",
      "214029  0.012606      1.000000             0.08471  0.044810  0.975600   \n",
      "214030  0.012606      0.011905             0.08471  0.044810  0.870135   \n",
      "214031  0.012606      1.000000             0.08471  0.044810  0.925388   \n",
      "214032  0.012606      1.000000             0.08471  0.044810  0.927606   \n",
      "214033  0.012606      0.892857             0.08471  0.021777  0.857028   \n",
      "214034  0.012606      1.000000             0.08471  0.021777  0.927606   \n",
      "214035  0.012606      1.000000             0.08471  0.021777  0.981448   \n",
      "\n",
      "         channel  DataQueueLen  passedUpPk  rcvdPKFromHL  rcvdPKFromLL  \\\n",
      "214000  0.225806      0.000172    0.065245      0.243549      0.006454   \n",
      "214001  0.387097      0.000172    0.065245      0.243549      0.006454   \n",
      "214002  0.258065      0.000172    0.065245      0.243549      0.006454   \n",
      "214003  0.967742      0.000172    0.065245      0.243549      0.006454   \n",
      "214004  0.387097      0.000172    0.065245      0.243549      0.006454   \n",
      "214005  0.516129      0.000172    0.065245      0.243549      0.006454   \n",
      "214006  0.580645      0.017164    0.065245      0.304967      0.006454   \n",
      "214007  0.580645      0.017164    0.065245      0.304967      0.006454   \n",
      "214008  1.000000      0.000172    0.065245      0.243549      0.006454   \n",
      "214009  0.548387      0.000172    0.065245      0.243549      0.006454   \n",
      "214010  0.161290      0.000172    0.065245      0.243549      0.006454   \n",
      "214011  0.225806      0.000172    0.065245      0.243549      0.006454   \n",
      "214012  0.580645      0.000172    0.065245      0.243549      0.006454   \n",
      "214013  0.516129      0.000172    0.065245      0.243549      0.006454   \n",
      "214014  1.000000      0.000172    0.065245      0.243549      0.006454   \n",
      "214015  0.580645      0.000172    0.065245      0.243549      0.006454   \n",
      "214016  0.258065      0.000172    0.065245      0.243549      0.006454   \n",
      "214017  0.967742      0.000172    0.065245      0.243549      0.006454   \n",
      "214018  0.193548      0.017164    0.065245      0.304967      0.006454   \n",
      "214019  0.258065      0.034157    0.065245      0.366385      0.006454   \n",
      "214020  0.225806      0.017164    0.065245      0.304967      0.006454   \n",
      "214021  0.193548      0.016993    0.065245      0.254484      0.006454   \n",
      "214022  0.193548      0.016993    0.065245      0.254484      0.006454   \n",
      "214023  0.258065      0.000172    0.065245      0.243549      0.006454   \n",
      "214024  0.193548      0.000172    0.065245      0.243549      0.006454   \n",
      "214025  0.580645      0.000172    0.065245      0.243549      0.006454   \n",
      "214026  0.516129      0.000172    0.065245      0.243549      0.006454   \n",
      "214027  0.161290      0.000172    0.065245      0.243549      0.006454   \n",
      "214028  0.193548      0.000172    0.065245      0.243549      0.006454   \n",
      "214029  0.258065      0.000172    0.065245      0.243549      0.006454   \n",
      "214030  0.967742      0.000172    0.065245      0.243549      0.006454   \n",
      "214031  0.580645      0.068143    0.178476      0.243549      0.006694   \n",
      "214032  0.516129      0.068143    0.178476      0.247482      0.006695   \n",
      "214033  0.225806      0.084792    0.178476      0.186064      0.004892   \n",
      "214034  0.516129      0.084792    0.178476      0.186064      0.004893   \n",
      "214035  0.193548      0.084792    0.178476      0.182130      0.004892   \n",
      "\n",
      "        sentDownPK  DropPKByQueue      snir  throughput           label  \n",
      "214000    0.437408            0.0  0.675468    0.410344  DDOS_UDP_FLOOD  \n",
      "214001    0.436819            0.0  0.675468    0.410344          Normal  \n",
      "214002    0.381760            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214003    0.330724            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214004    0.330724            0.0  0.675468    0.410446          Normal  \n",
      "214005    0.380950            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214006    0.436009            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214007    0.328025            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214008    0.378447            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214009    0.378447            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214010    0.430072            0.0  0.675468    0.410446          Normal  \n",
      "214011    0.485131            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214012    0.539602            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214013    0.431716            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214014    0.434120            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214015    0.491584            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214016    0.491584            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214017    0.440549            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214018    0.498013            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214019    0.546643            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214020    0.491584            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214021    0.491584            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214022    0.498013            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214023    0.495608            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214024    0.495608            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214025    0.495608            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214026    0.495608            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214027    0.441138            0.0  0.675468    0.410446          Normal  \n",
      "214028    0.441138            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214029    0.440549            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214030    0.434120            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214031    0.377343            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214032    0.434807            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214033    0.377343            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214034    0.374939            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n",
      "214035    0.434807            0.0  0.675468    0.410446  DDOS_UDP_FLOOD  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "keep=0.2\n",
    "#X = df.drop(columns = ['label']).copy()\n",
    "y = df['label']\n",
    "#print(y)\n",
    "#X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=keep, shuffle=False)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "\n",
    "#X_train.to_csv(\"csv/datasets1/small/testbed3/Train_test/X.csv\" ,index=False,header=True)\n",
    "#y_train.to_csv(\"csv/datasets1/small/testbed3/Train_test/y.csv\" ,index=False,header=True)\n",
    "#print(len(X_rem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diviser en entrainement , test et validation \n",
    "X = pd.read_csv(\"csv/datasets1/small/testbed3/Train_test/X.csv\")\n",
    "y = pd.read_csv(\"csv/datasets1/small/testbed3/Train_test/y.csv\")\n",
    "\n",
    "train=0.6\n",
    "\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=train,shuffle=False)\n",
    "\n",
    "validation=0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,shuffle=False)\n",
    "\n",
    "\n",
    "X_train.to_csv(\"csv/datasets1/small/testbed3/Train_test/X_train.csv\" ,index=False,header=True)\n",
    "y_train.to_csv(\"csv/datasets1/small/testbed3/Train_test/y_train.csv\" ,index=False,header=True)\n",
    "X_valid.to_csv(\"csv/datasets1/small/testbed3/Train_test/X_valid.csv\" ,index=False,header=True)\n",
    "y_valid.to_csv(\"csv/datasets1/small/testbed3/Train_test/y_valid.csv\" ,index=False,header=True)\n",
    "X_test.to_csv(\"csv/datasets1/small/testbed3/Train_test/X_test.csv\" ,index=False,header=True)\n",
    "y_test.to_csv(\"csv/datasets1/small/testbed3/Train_test/y_test.csv\" ,index=False,header=True)\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####starting agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.set_default_dtype(torch.float64)\n",
    "path=path0+\"small/testbed3/Train_test2/\"\n",
    "\n",
    "X_train= pd.read_csv(path+\"X_train.csv\")\n",
    "y_train= pd.read_csv(path+\"y_train.csv\")\n",
    "X_valid= pd.read_csv(path+\"X_valid.csv\")\n",
    "y_valid= pd.read_csv(path+\"y_valid.csv\")\n",
    "X_test= pd.read_csv(path+\"X_test.csv\")\n",
    "y_test= pd.read_csv(path+\"y_test.csv\")\n",
    "\n",
    "#X_train=X_train[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','sentPK','duration(ms)','droppedPKWrongPort','size','throughput']]   #,'channel'      \n",
    "\n",
    "#X_test=X_test[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','sentPK','duration(ms)','droppedPKWrongPort','size','throughput']]   #,'channel'      \n",
    "#X_valid=X_valid[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','sentPK','duration(ms)','droppedPKWrongPort','size','throughput']]   #,'channel'      \n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-810a7c73b115>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#X_train1=X_train1.astype(float)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "a-time.time()\n",
    "X_train1=X_train.values\n",
    "y_train1=y_train.values\n",
    "#print(y_train1)\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "print(X_train1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30497\n",
      "tensor([0, 0, 0,  ..., 0, 3, 0])\n",
      "190988\n",
      "143243\n",
      "143244\n",
      "10.731038808822632\n"
     ]
    }
   ],
   "source": [
    "a-time.time()\n",
    "X_train1=X_train.values\n",
    "y_train1=y_train.values\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "torch_tensor = torch.tensor(X_train1)\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "t=[]\n",
    "test=0\n",
    "test0=0\n",
    "\n",
    "for j in y_train1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        test0+=1\n",
    "    #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(2))\n",
    "        test+=1\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(3))\n",
    "print(test)\n",
    "labels = torch.LongTensor(t)\n",
    "#print(torch_tensor[-1])\n",
    "#print(labels[-1])\n",
    "print(labels)\n",
    "#print(df_label)\n",
    "#print(labels.shape)\n",
    "\n",
    "#df00 = pd.read_csv(path0+\"small/testbed3/Dataset_S03Filtrer.csv\")\n",
    "#bigX = df00[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','channel','throughput']]         \n",
    "#bigY = df00['label']\n",
    "bigX = X_valid\n",
    "#[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','droppedPKWrongPort','sentPK','size','throughput']]  ,'channel'       \n",
    "bigY = y_valid['label']\n",
    "#print(bigY)\n",
    "X_valid1=bigX.values\n",
    "y_valid1=bigY.values\n",
    "\n",
    "#X_valid1=X_test.values\n",
    "#y_valid1=y_test.values\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "vtorch_tensor = torch.tensor(X_valid1)\n",
    "v=[]\n",
    "\n",
    "for i in y_valid1:\n",
    "    #i=j[0]\n",
    "    #print(i)\n",
    "    if (i=='Normal'):\n",
    "        v.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        v.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        v.append(int(2))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        v.append(int(3))\n",
    "\n",
    "vlabels = torch.LongTensor(v)\n",
    "\n",
    "\n",
    "X_test1=X_test.values\n",
    "y_test1=y_test.values\n",
    "\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "ttorch_tensor = torch.tensor(X_test1)\n",
    "\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "t=[]\n",
    "\n",
    "for j in y_test1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(2))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(3))\n",
    "\n",
    "tlabels = torch.LongTensor(t)\n",
    "#print(torch_tensor[-1])\n",
    "#print(labels[-1])\n",
    "print(len(labels))\n",
    "print(len(vlabels))\n",
    "print(len(tlabels))\n",
    "\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232338\n",
      "113.20638880497384\n",
      "14.859623649102975\n"
     ]
    }
   ],
   "source": [
    "print(test0)\n",
    "print(test0*100/len(X_train))\n",
    "print(test*100/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,i in enumerate(lll):\n",
    "    print(i[-1])\n",
    "    if (i[-1]==1):\n",
    "        print('llll')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class My_module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(19,36)\n",
    "        self.fc00 = nn.Linear(32,64)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(1,8,kernel_size=(3,3),stride=(1,1),padding=1)\n",
    "        self.conv2=nn.Conv2d(8,12,kernel_size=(3,3),stride=(1,1),padding=1)\n",
    "        self.conv3=nn.Conv2d(12,18,kernel_size=(3,3),stride=(1,1),padding=1)\n",
    "        self.fc1 = nn.Linear(18*6*6,350)\n",
    "        self.fc2 = nn.Linear(350,4)\n",
    "        \n",
    "        self.fc3 = nn.Linear(56, 64)\n",
    "        self.fc4 = nn.Linear(64, 4)\n",
    "        self.fc5 = nn.Linear(400, 4)\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.pool=nn.MaxPool2d(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        #x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        x = self.dropout(self.fc0(x))\n",
    "       # x = self.dropout(F.relu(self.fc00(x)))\n",
    "        #print(x.shape)\n",
    "        x=x.view(-1,1,6,6)\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.shape)\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=x.view(-1,18*6*6)\n",
    "        #print(x.shape)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    " #       x = self.dropout(F.relu(self.fc2(x)))\n",
    "        #x = self.dropout(F.relu(self.fc3(x))) \n",
    "        #x = self.dropout(F.relu(self.fc4(x))) \n",
    "    \n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = My_module()\n",
    "    \n",
    "#model = nn.Sequential(nn.Linear(11, 28),\n",
    " #                     #nn.GELU(),\n",
    "  #                    #nn.ELU(),\n",
    "   #                   nn.ReLU(),\n",
    "    #                  nn.Dropout(p=0.3),                      \n",
    "     #                 #nn.LeakyReLU(),\n",
    "      #                #nn.Linear(64, 140),\n",
    "       #               #nn.ReLU(),\n",
    "                      #nn.Linear(140, 200),\n",
    "                      #nn.ReLU(),\n",
    "        #              nn.Linear(28,32),                      \n",
    "                      #nn.LeakyReLU(),\n",
    "                      #nn.ELU(),\n",
    "                      #nn.GELU(),\n",
    "         #             nn.ReLU(),\n",
    "          #            nn.Dropout(p=0.3),\n",
    "           #           nn.Linear(32, 40),\n",
    "            #          nn.ReLU(),\n",
    "             #         nn.Dropout(p=0.3),\n",
    "       #               nn.Linear(40, 56),\n",
    "        #              nn.ReLU(),\n",
    "         #             nn.Dropout(p=0.3),\n",
    "          #            nn.Linear(56, 4),\n",
    "           #           nn.LogSoftmax(dim=1)\n",
    "                      #nn.LogSoftmax(dim=1)\n",
    "            #         )\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "Fonction_de_perte = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "#indices = [0,3, 299:303]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([143243, 18])\n",
      "torch.Size([143244, 18])\n",
      "torch.Size([190988, 18])\n",
      "torch.Size([190988, 1, 6, 3])\n",
      "tensor([[[2.1728e-03, 2.5947e-03, 2.3385e-03],\n",
      "         [4.5851e-03, 0.0000e+00, 2.3810e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 2.4473e-03],\n",
      "         [1.0002e-01, 1.6129e-01, 0.0000e+00],\n",
      "         [9.1377e-03, 1.6600e-02, 1.9384e-04],\n",
      "         [0.0000e+00, 2.4010e-02, 8.6110e-04]]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.empty((6,3))\n",
    "\n",
    "print(vtorch_tensor.shape)\n",
    "print(ttorch_tensor.shape)\n",
    "print(torch_tensor.shape)\n",
    "vtorch_tensor=torch.reshape(vtorch_tensor,(143243,1,6,3))\n",
    "ttorch_tensor=torch.reshape(ttorch_tensor,(143244,1,6,3))\n",
    "\n",
    "torch_tensor=torch.reshape(torch_tensor,(190988,1,6,3))\n",
    "print(torch_tensor.shape)\n",
    "\n",
    "#for i, x in enumerate(torch_tensor):\n",
    " #   a[i]=torch.reshape(x,(6,3))\n",
    "print(torch_tensor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190988\n",
      "190988\n",
      "Epoch  : valid accuracy :56.49630356 with total prob : 26.09871292 \n",
      "Epoch 0 : Training loss 0.02338144 and valid loss : -0.54306138 :  \n",
      "Epoch 0 : valid accuracy :54.33423996 with total prob : 97.06684875 \n",
      "1052.6695187091827\n",
      "validation loss decreased , saving model (inf ==> -0.54306138)\n",
      "Epoch 1 : Training loss 0.00588092 and valid loss : -0.61324191 :  \n",
      "Epoch 1 : valid accuracy :61.71471024 with total prob : 92.76026917 \n",
      "1064.6429071426392\n",
      "validation loss decreased , saving model (-0.54306138 ==> -0.61324191)\n",
      "Epoch 2 : Training loss 0.00296172 and valid loss : -0.70436369 :  \n",
      "Epoch 2 : valid accuracy :69.99853516 with total prob : 94.24800873 \n",
      "1060.7163219451904\n",
      "validation loss decreased , saving model (-0.61324191 ==> -0.70436369)\n",
      "Epoch 3 : Training loss 0.00229805 and valid loss : -0.82467191 :  \n",
      "Epoch 3 : valid accuracy :82.22391510 with total prob : 97.39118958 \n",
      "1020.7206881046295\n",
      "validation loss decreased , saving model (-0.70436369 ==> -0.82467191)\n",
      "Epoch 4 : Training loss 0.00220016 and valid loss : -0.83180645 :  \n",
      "Epoch 4 : valid accuracy :83.28504944 with total prob : 97.58514404 \n",
      "1026.4521329402924\n",
      "validation loss decreased , saving model (-0.82467191 ==> -0.83180645)\n",
      "Epoch 5 : Training loss 0.00210430 and valid loss : -0.87117230 :  \n",
      "Epoch 5 : valid accuracy :87.45767212 with total prob : 97.46473694 \n",
      "1016.4045996665955\n",
      "validation loss decreased , saving model (-0.83180645 ==> -0.87117230)\n",
      "Epoch 6 : Training loss 0.00191306 and valid loss : -0.91865764 :  \n",
      "Epoch 6 : valid accuracy :92.19089508 with total prob : 98.36977386 \n",
      "1039.6101734638214\n",
      "validation loss decreased , saving model (-0.87117230 ==> -0.91865764)\n",
      "Epoch 7 : Training loss 0.00192969 and valid loss : -0.93798841 :  \n",
      "Epoch 7 : valid accuracy :94.07579803 with total prob : 99.15029144 \n",
      "923.4185161590576\n",
      "validation loss decreased , saving model (-0.91865764 ==> -0.93798841)\n",
      "Epoch 8 : Training loss 0.00147111 and valid loss : -0.93170868 :  \n",
      "Epoch 8 : valid accuracy :93.07749939 with total prob : 99.63709259 \n",
      "8761.237612485886\n",
      "Epoch 9 : Training loss 0.00086031 and valid loss : -0.94103797 :  \n",
      "Epoch 9 : valid accuracy :94.38716125 with total prob : 99.29341125 \n",
      "979.2254660129547\n",
      "validation loss decreased , saving model (-0.93798841 ==> -0.94103797)\n",
      "Epoch 10 : Training loss 0.00084622 and valid loss : -0.94501156 :  \n",
      "Epoch 10 : valid accuracy :94.55261230 with total prob : 99.79159546 \n",
      "915.0214290618896\n",
      "validation loss decreased , saving model (-0.94103797 ==> -0.94501156)\n",
      "Epoch 11 : Training loss 0.00090417 and valid loss : -0.94567909 :  \n",
      "Epoch 11 : valid accuracy :94.59589386 with total prob : 99.82992554 \n",
      "913.8393297195435\n",
      "validation loss decreased , saving model (-0.94501156 ==> -0.94567909)\n",
      "Epoch 12 : Training loss 0.00075867 and valid loss : -0.94574991 :  \n",
      "Epoch 12 : valid accuracy :94.59799194 with total prob : 99.78526306 \n",
      "910.9115519523621\n",
      "validation loss decreased , saving model (-0.94567909 ==> -0.94574991)\n",
      "Epoch 13 : Training loss 0.00092189 and valid loss : -0.94598755 :  \n",
      "Epoch 13 : valid accuracy :94.65523529 with total prob : 99.78415680 \n",
      "961.089884519577\n",
      "validation loss decreased , saving model (-0.94574991 ==> -0.94598755)\n",
      "Epoch 14 : Training loss 0.00034616 and valid loss : -0.94770756 :  \n",
      "Epoch 14 : valid accuracy :94.80672455 with total prob : 99.94471741 \n",
      "1019.4962174892426\n",
      "validation loss decreased , saving model (-0.94598755 ==> -0.94770756)\n",
      "Epoch 15 : Training loss 0.00023841 and valid loss : -0.94798986 :  \n",
      "Epoch 15 : valid accuracy :94.80951691 with total prob : 99.97833252 \n",
      "1023.1284811496735\n",
      "validation loss decreased , saving model (-0.94770756 ==> -0.94798986)\n",
      "Epoch 16 : Training loss 0.00021518 and valid loss : -0.94813945 :  \n",
      "Epoch 16 : valid accuracy :94.81161499 with total prob : 99.97979736 \n",
      "1035.8213183879852\n",
      "validation loss decreased , saving model (-0.94798986 ==> -0.94813945)\n",
      "Epoch 17 : Training loss 0.00019707 and valid loss : -0.94833217 :  \n",
      "Epoch 17 : valid accuracy :94.81440735 with total prob : 99.96838379 \n",
      "1112.9112062454224\n",
      "validation loss decreased , saving model (-0.94813945 ==> -0.94833217)\n",
      "Epoch 18 : Training loss 0.00018455 and valid loss : -0.94864412 :  \n",
      "Epoch 18 : valid accuracy :94.83953857 with total prob : 99.94953918 \n",
      "1057.6294305324554\n",
      "validation loss decreased , saving model (-0.94833217 ==> -0.94864412)\n",
      "Epoch 19 : Training loss 0.00017182 and valid loss : -0.94899112 :  \n",
      "Epoch 19 : valid accuracy :94.86327362 with total prob : 99.93212891 \n",
      "1097.415113210678\n",
      "validation loss decreased , saving model (-0.94864412 ==> -0.94899112)\n",
      "Epoch 20 : Training loss 0.00016091 and valid loss : -0.94926549 :  \n",
      "Epoch 20 : valid accuracy :94.88840485 with total prob : 99.91803741 \n",
      "971.978330373764\n",
      "validation loss decreased , saving model (-0.94899112 ==> -0.94926549)\n",
      "Epoch 21 : Training loss 0.00015249 and valid loss : -0.94954921 :  \n",
      "Epoch 21 : valid accuracy :94.91493988 with total prob : 99.90194702 \n",
      "954.2122621536255\n",
      "validation loss decreased , saving model (-0.94926549 ==> -0.94954921)\n",
      "Epoch 22 : Training loss 0.00014867 and valid loss : -0.94994709 :  \n",
      "Epoch 22 : valid accuracy :94.94495392 with total prob : 99.88465881 \n",
      "1075.1024560928345\n",
      "validation loss decreased , saving model (-0.94954921 ==> -0.94994709)\n",
      "Epoch 23 : Training loss 0.00014410 and valid loss : -0.95034317 :  \n",
      "Epoch 23 : valid accuracy :94.96659851 with total prob : 99.86183929 \n",
      "1119.2393252849579\n",
      "validation loss decreased , saving model (-0.94994709 ==> -0.95034317)\n",
      "Epoch 24 : Training loss 0.00014004 and valid loss : -0.95072945 :  \n",
      "Epoch 24 : valid accuracy :94.98404694 with total prob : 99.83706665 \n",
      "1079.8747506141663\n",
      "validation loss decreased , saving model (-0.95034317 ==> -0.95072945)\n",
      "Epoch 25 : Training loss 0.00013509 and valid loss : -0.95119597 :  \n",
      "Epoch 25 : valid accuracy :95.00010681 with total prob : 99.79921722 \n",
      "21694.675014972687\n",
      "validation loss decreased , saving model (-0.95072945 ==> -0.95119597)\n",
      "Epoch 26 : Training loss 0.00013134 and valid loss : -0.95175858 :  \n",
      "Epoch 26 : valid accuracy :95.03292084 with total prob : 99.75947571 \n",
      "1109.5533435344696\n",
      "validation loss decreased , saving model (-0.95119597 ==> -0.95175858)\n",
      "Epoch 27 : Training loss 0.00012607 and valid loss : -0.95207149 :  \n",
      "Epoch 27 : valid accuracy :95.04268646 with total prob : 99.72756195 \n",
      "1015.1365876197815\n",
      "validation loss decreased , saving model (-0.95175858 ==> -0.95207149)\n",
      "Epoch 28 : Training loss 0.00012248 and valid loss : -0.95214448 :  \n",
      "Epoch 28 : valid accuracy :95.03501129 with total prob : 99.71820068 \n",
      "1040.2486588954926\n",
      "validation loss decreased , saving model (-0.95207149 ==> -0.95214448)\n",
      "Epoch 29 : Training loss 0.00011776 and valid loss : -0.95217969 :  \n",
      "Epoch 29 : valid accuracy :95.04967499 with total prob : 99.71407318 \n",
      "1007.784827709198\n",
      "validation loss decreased , saving model (-0.95214448 ==> -0.95217969)\n",
      "Epoch 30 : Training loss 0.00011288 and valid loss : -0.95206429 :  \n",
      "Epoch 30 : valid accuracy :95.04827118 with total prob : 99.72542572 \n",
      "1047.4961495399475\n",
      "Epoch 31 : Training loss 0.00010829 and valid loss : -0.95217161 :  \n",
      "Epoch 31 : valid accuracy :95.06991577 with total prob : 99.71867371 \n",
      "1110.8230385780334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8e10e17039db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mx2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0ml2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m#print(l2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-b2668a296d10>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;31m#print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[0;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                             self.return_indices)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#labels1=labels[loc]\n",
    "a=time.time()\n",
    "inputs=torch_tensor[:,:] \n",
    "labels1=labels[:]\n",
    "print(len(inputs))\n",
    "print(len(labels1))\n",
    "vinputs =vtorch_tensor[:,:] \n",
    "vlabels1=vlabels[:]\n",
    "\n",
    "epochs = 50\n",
    "valid_loss=0\n",
    "accuracy=0\n",
    "valid_loss_min=np.Inf\n",
    "\n",
    "####33  !!!!!!!!!! This shit cost alot of time ----> do not use it \n",
    "#b=time.time()\n",
    "#with torch.no_grad():\n",
    "   # for i, x in enumerate(vinputs):\n",
    "       # x2=x[None,:]\n",
    "       # output = torch.exp(model(x2))\n",
    "       # l2=vlabels1[i][None]\n",
    "       # test_loss+=Fonction_de_perte(output, l2)\n",
    "     #   output = torch.exp(output)\n",
    "      #  top_p , top_c = output.topk(1, dim=1)\n",
    "     #   equals = top_c==vlabels1[i].view(*top_c.shape)\n",
    "    #    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "   # tain_losses.append(running_loss/len(inputs))\n",
    "   # test_losses.append(test_loss/len(vinputs))\n",
    "   # print ('test accuracy :{0}, test loss : {2} ,  time {1} '.format(accuracy*100/len(vinputs) , time.time()-b ,test_loss/len(vinputs) ))\n",
    "\n",
    "######## ---> use this :) \n",
    "b=time.time()\n",
    "with torch.no_grad():\n",
    "    output = torch.exp(model(vinputs))\n",
    "    valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==vlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "#print ('valid accuracy :{0:.8f} with total prob : {3:.8f} and  valid loss : {2:.8f} ,  time {1:.6f} '.format(accuracy*100 , time.time()-b ,test_loss,propabilities))\n",
    "print ('Epoch  : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities))\n",
    "\n",
    "####\n",
    "#print(inputs.shape[0])\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "for e in range(epochs):\n",
    "    temp_t=time.time()\n",
    "    running_loss = 0\n",
    "    for i, x in enumerate(inputs):\n",
    "        optimizer.zero_grad()\n",
    "        x2=x[None,:]\n",
    "        output = model.forward(x2)\n",
    "        l2=labels1[i][None]\n",
    "        #print(l2)\n",
    "        loss = Fonction_de_perte(output, l2)\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        accuracy=0\n",
    "        #print(l2)\n",
    "  \n",
    "        b=time.time()\n",
    "        with torch.no_grad():\n",
    "            ##\n",
    "            #with torch.no_grad():\n",
    "            #for i, x in enumerate(vinputs):\n",
    "             #   x2=x[None,:]\n",
    "              #  output = torch.exp(model(x2))\n",
    "               # l2=vlabels1[i][None]\n",
    "                #valid_loss1+=Fonction_de_perte(output, l2)\n",
    "            #test_loss=test_loss/len(vinputs)\n",
    "            ##\n",
    "                \n",
    "            model.eval()\n",
    "            output = torch.exp(model(vinputs))\n",
    "            valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "        top_p , top_c = output.topk(1, dim=1)\n",
    "        propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "        equals = top_c==vlabels1.view(*top_c.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        print('Epoch {2} : Training loss {0:.8f} and valid loss : {1:.8f} :  '.format(running_loss/len(inputs),valid_loss, e))\n",
    "   \n",
    "        print ('Epoch {2} : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities, e))\n",
    "        #print('validation loss with iterations {0}'.format(valid_loss1/len(vinputs) ) ) \n",
    "        print(time.time()-temp_t)\n",
    "        train_losses.append(running_loss/len(inputs))\n",
    "        valid_losses.append(valid_loss)\n",
    "        if (valid_loss<valid_loss_min):\n",
    "            print('validation loss decreased , saving model ({:.8f} ==> {:.8f})'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(),'src\\\\models\\\\mod_temp5_50_CNN.pth')\n",
    "            valid_loss_min=valid_loss\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.2875e-22, 5.7888e-24, 5.0594e-18],\n",
      "        [9.9997e-01, 3.7156e-07, 9.8159e-06, 2.3688e-05],\n",
      "        [1.0000e+00, 1.1895e-22, 5.5642e-24, 4.8054e-18],\n",
      "        ...,\n",
      "        [1.0000e+00, 3.1381e-25, 1.4856e-27, 2.7625e-19],\n",
      "        [1.0000e+00, 2.9208e-25, 1.3790e-27, 2.6328e-19],\n",
      "        [1.0000e+00, 1.9552e-25, 3.5239e-28, 2.5324e-19]])\n",
      "torch.Size([143243, 4])\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18047999df0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "plt.plot(train_losses, label='train loss ')\n",
    "plt.plot(valid_losses, label='valid loss ')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr=np.array(train_losses)\n",
    "Te=np.array(valid_losses)\n",
    "\n",
    "Tr=np.reshape(Tr, (len(Tr),1))\n",
    "Te=np.reshape(Te, (len(Te),1))\n",
    "\n",
    "# fit on training data column\n",
    "scale = StandardScaler().fit(Tr)\n",
    "tain_losses = scale.transform(Tr)\n",
    "scale = StandardScaler().fit(Te)\n",
    "test_losses = scale.transform(Te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17e6c3b8640>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "plt.plot(tain_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='valid loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('src\\\\models\\\\mod_temp5_50_CNN.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "test accuracy :97.31716156 with total prob : 99.06803131 and  test loss : -0.97013336 ,  time 12.49005532 \n",
      "la prcision de detection globale: 97.0133355854194 \n",
      "detection des communication normal: 95.07817954 with accuracy 95.45493940 ( 77098/80769 )\n",
      "details normal classed udp :0.00990, pluies 4.49554 , jam 0.03962 (ou 0.21792,98.91038,0.87170) \n",
      "detection du deni de service par udp flood 99.97203121 with accuracy 99.96925227 ( 35764/35775 )\n",
      "details udp classed normal :0.02516, pluies 0.00000 , jam 0.00559 (ou 81.81818,0.00000,18.18182) \n",
      "detection du deni naturel : pluies et orages : 98.99945758 with accuracy 99.44281139 ( 22666/22793 )\n",
      "details pluies classed udp :0.00000, normal 0.55719 , jam 0.00000 (ou 0.00000,100.00000,0.00000) \n",
      "detection du deni naturel : jam : 98.34008346 with accuracy 99.12976708 ( 3873/3907 )\n",
      "details jam classed udp :0.00000, pluies 0.02560 , normal 0.84464 (ou 0.00000,2.94118,97.05882) \n",
      "=====================\n",
      "<================================>\n",
      "Total_time\n",
      "157.95221281051636\n"
     ]
    }
   ],
   "source": [
    "a=time.time()\n",
    "summm=[]\n",
    "sum1=[]\n",
    "sum2=[]\n",
    "sum3=[]\n",
    "sum4=[]\n",
    "\n",
    "tinputs =ttorch_tensor[:,:] \n",
    "tlabels1=tlabels[:]\n",
    "\n",
    "\n",
    "#tinputs =torch_tensor[:,:] \n",
    "#tlabels1=labels[:]\n",
    "\n",
    "print('=====================')\n",
    "b=time.time()\n",
    "output = torch.exp(model(tinputs))\n",
    "test_loss=Fonction_de_perte(output, tlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==tlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "model.train()\n",
    "print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.8f} '.format(accuracy*100 , time.time()-b ,test_loss ,propabilities))\n",
    "\n",
    "class_correct = list(0. for i in range (4))\n",
    "class_total = list(0. for i in range (4))\n",
    "\n",
    "C_n_udp=0\n",
    "C_n_pluies=0\n",
    "C_n_jam=0\n",
    "C_n_total=0\n",
    "\n",
    "\n",
    "C_u_normal=0\n",
    "C_u_jam=0\n",
    "C_u_pluies=0\n",
    "C_u_total=0\n",
    "\n",
    "C_p_normal=0\n",
    "C_p_udp=0\n",
    "C_p_jam=0\n",
    "C_p_total=0\n",
    "\n",
    "C_j_normal=0\n",
    "C_j_udp=0\n",
    "C_j_pluies=0\n",
    "C_j_total=0\n",
    "\n",
    "for i, x in enumerate(tinputs):\n",
    "    optimizer.zero_grad()\n",
    "    x2=x[None,:]\n",
    "    with torch.no_grad():\n",
    "        output = torch.exp(model(x2))\n",
    "    out=output.detach().numpy()*100\n",
    " \n",
    "    l3=tlabels1[i].item()\n",
    "  \n",
    "    if(l3==0):\n",
    "        summm.append(out[0][0])\n",
    "        sum1.append(out[0][0])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_n_udp+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_n_pluies+=1\n",
    "            if(top_c[i][0]==3):\n",
    "                C_n_jam +=1\n",
    "            \n",
    "            C_n_total +=1\n",
    "            \n",
    "    if(l3==1):\n",
    "        summm.append(out[0][1])\n",
    "        sum2.append(out[0][1])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==3):\n",
    "                C_u_jam+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_u_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_u_normal +=1\n",
    "            \n",
    "            C_u_total +=1\n",
    "\n",
    "    if(l3==2):\n",
    "        summm.append(out[0][2])\n",
    "        sum3.append(out[0][2])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_p_udp+=1\n",
    "            if(top_c[i][0]==3):\n",
    "                C_p_jam+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_p_normal +=1\n",
    "            \n",
    "            C_p_total +=1\n",
    "\n",
    "    if(l3==3):\n",
    "        summm.append(out[0][3])\n",
    "        sum4.append(out[0][3])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_j_udp+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_j_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_j_normal +=1\n",
    "            \n",
    "            C_j_total +=1\n",
    "\n",
    "    class_total[l3]+=1\n",
    "    class_correct[l3]+=equals[i][0]\n",
    "    #print(output)\n",
    "print('la prcision de detection globale: {0} '.format(mean(summm)))\n",
    "print('detection des communication normal: {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum1), class_correct[0]*100/class_total[0] ,class_correct[0] ,class_total[0]))\n",
    "if(C_n_total!=0):\n",
    "    print('details normal classed udp :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_n_udp*100/class_total[0],C_n_pluies*100/class_total[0],C_n_jam*100/class_total[0],C_n_udp*100/C_n_total,C_n_pluies*100/C_n_total,C_n_jam*100/C_n_total))\n",
    "else:\n",
    "    print('detection normal 100')\n",
    "\n",
    "print('detection du deni de service par udp flood {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum2), class_correct[1]*100/class_total[1] ,class_correct[1] ,class_total[1]))\n",
    "if(C_u_total!=0):\n",
    "    print('details udp classed normal :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_u_normal*100/class_total[1],C_u_pluies*100/class_total[1],C_u_jam*100/class_total[1],C_u_normal*100/C_u_total,C_u_pluies*100/C_u_total,C_u_jam*100/C_u_total))\n",
    "else:\n",
    "    print('detection udp flood 100')\n",
    "    \n",
    "print('detection du deni naturel : pluies et orages : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum3), class_correct[2]*100/class_total[2] ,class_correct[2] ,class_total[2]))\n",
    "if(C_p_total!=0):\n",
    "    print('details pluies classed udp :{0:.5f}, normal {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_p_udp*100/class_total[2],C_p_normal*100/class_total[2],C_p_jam*100/class_total[2],C_p_udp*100/C_p_total,C_p_normal*100/C_p_total,C_p_jam*100/C_p_total))\n",
    "else:\n",
    "    print('detection pluies et orages 100')\n",
    "\n",
    "print('detection du deni naturel : jam : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum4), class_correct[3]*100/class_total[3] ,class_correct[3] ,class_total[3]))\n",
    "if(C_j_total!=0):\n",
    "    print('details jam classed udp :{0:.5f}, pluies {1:.5f} , normal {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_j_udp*100/class_total[3],C_j_pluies*100/class_total[3],C_j_normal*100/class_total[3],C_j_udp*100/C_j_total,C_j_pluies*100/C_j_total,C_j_normal*100/C_j_total))\n",
    "else:\n",
    "    print('detection brouillage 100')\n",
    "print('=====================')\n",
    "\n",
    "print('<================================>')\n",
    "print('Total_time')\n",
    "print(time.time()-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16915.0\n"
     ]
    }
   ],
   "source": [
    "print(class_total[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_module(\n",
      "  (fc1): Linear(in_features=15, out_features=30, bias=True)\n",
      "  (fc5): Linear(in_features=30, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig = plt.figure(figsize=(32, 8))\n",
    "#plt.legend(loc='best')\n",
    "#ax3 = plt.subplot2grid((2,4), (0,2)) \n",
    "#plt.set_title(\"Bar Chart\")\n",
    "print(model)\n",
    "N = 6\n",
    "x=['somme des probabilites','Normal','udp flood','pluies et orages','jam ','Taux de detection']\n",
    "n = np.array([mean(summm),mean(sum1),mean(sum2),mean(sum3),mean(sum4),accuracy*100])\n",
    "n2 = np.array([mean(summm)-50,mean(sum1)-50,mean(sum2)-50,mean(sum3)-50,mean(sum4)-50,(accuracy*100)-50])\n",
    "#y_pos = range(len(x))\n",
    "#plt.bar(y_pos, n)\n",
    "# Rotation of the bars names\n",
    "#plt.xticks(y_pos, x, rotation=90)\n",
    "plt.figure(figsize=(32, 8))\n",
    "plt.subplot2grid((2,4), (0,2)) \n",
    "\n",
    "#print(np.arange(0, 101, 10))\n",
    "\n",
    "menStd = (0, 0, 0, 0, 0,0)\n",
    "womenStd = (3, 5, 2, 3, 3,5)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "p1 = plt.bar(ind, n, width, yerr=menStd)\n",
    "#p2 = plt.bar(ind, n2, width, bottom=n, yerr=womenStd)\n",
    "plt.ylabel('Pourcentage %')\n",
    "plt.title('Performance du modele')\n",
    "plt.xticks(ind, x,rotation=50)\n",
    "plt.yticks(np.arange(0, 101, 10))\n",
    "#plt.legend((p1[0], p2[0]), ('', ''))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[1.]])\n",
      "tensor([[0]])\n",
      "tensor(0)\n",
      "1\n",
      "tensor([[0.8926]])\n",
      "tensor([[3]])\n",
      "tensor(3)\n",
      "2\n",
      "tensor([[0.9845]])\n",
      "tensor([[3]])\n",
      "tensor(3)\n",
      "3\n",
      "tensor([[0.9392]])\n",
      "tensor([[0]])\n",
      "tensor(0)\n",
      "4\n",
      "tensor([[0.9845]])\n",
      "tensor([[3]])\n",
      "tensor(3)\n",
      "5\n",
      "tensor([[1.]])\n",
      "tensor([[1]])\n",
      "tensor(1)\n",
      "6\n",
      "tensor([[0.9973]])\n",
      "tensor([[2]])\n",
      "tensor(2)\n",
      "7\n",
      "tensor([[0.8937]])\n",
      "tensor([[3]])\n",
      "tensor(3)\n",
      "8\n",
      "tensor([[1.]])\n",
      "tensor([[1]])\n",
      "tensor(1)\n",
      "9\n",
      "tensor([[0.7371]])\n",
      "tensor([[0]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "vinputs =vtorch_tensor[0:10, :] \n",
    "vlabels1=vlabels[0:10]\n",
    "\n",
    "for i, x in enumerate(vinputs):\n",
    "    #print(i)\n",
    "    optimizer.zero_grad()\n",
    "    x2=x[None,:]\n",
    "    with torch.no_grad():\n",
    "        output = torch.exp(model(x2))\n",
    "        top_p , top_c = output.topk(1, dim=1)\n",
    "        print (i)\n",
    "        print(top_p)\n",
    "        print(top_c)\n",
    "        print(vlabels1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000],\n",
      "        [0.6282],\n",
      "        [0.7119],\n",
      "        ...,\n",
      "        [0.9976],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<TopkBackward>)\n",
      "tensor([[0],\n",
      "        [3],\n",
      "        [3],\n",
      "        ...,\n",
      "        [2],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor(0.9808, dtype=torch.float32, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9793, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "vinputs =vtorch_tensor[:, :] \n",
    "vlabels1=vlabels[:]\n",
    "\n",
    "output = torch.exp(model(vinputs))\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "print(top_p)\n",
    "print(top_c)\n",
    "equals = top_c==vlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))\n",
    "print(propabilities)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentge du trafic normal :59.453586205955666\n",
      "pourcentge du trafic udp_flood :23.12923048737943\n",
      "pourcentge du trafic dans un mauvais temps :14.837523947993631\n",
      "pourcentge du trafic vicitme d' brouillage :2.579659358671269\n"
     ]
    }
   ],
   "source": [
    "#tester la qualite du dataset en terme de quantite\n",
    "df00 = pd.read_csv(\"src/cvs/datasets1/small/Dataset_S02Final.csv\")\n",
    "#df00 = pd.read_csv(\"src/cvs/datasets1/small/testbed/Train_test/y.csv\")\n",
    "\n",
    "#print(df)\n",
    "df111=df00.to_numpy()\n",
    "total=len(df111)\n",
    "n=0\n",
    "u=0\n",
    "p=0\n",
    "j=0\n",
    "for i in enumerate(df111):\n",
    "    if(i[1][-1]=='Normal'):\n",
    "        n+=1\n",
    "\n",
    "    if(i[1][-1]=='PLUIES_ET_ORAGES'):\n",
    "        p+=1\n",
    "    if(i[1][-1]=='DDOS_UDP_FLOOD'):\n",
    "        u+=1\n",
    "    if(i[1][-1]=='BROUILLAGE_Trafic'):\n",
    "        j+=1\n",
    "print('pourcentge du trafic normal :'+str(n/total *100))\n",
    "print('pourcentge du trafic udp_flood :'+str(u/total *100))\n",
    "print('pourcentge du trafic dans un mauvais temps :'+str(p/total *100))\n",
    "print('pourcentge du trafic vicitme d\\' brouillage :'+str(j/total *100))\n",
    "\n",
    "#print(n+u+p+j)\n",
    "#print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-70-b734b4a253c9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-70-b734b4a253c9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pourcentge du trafic normal :21.765924563089197\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pourcentge du trafic normal :21.765924563089197\n",
    "pourcentge du trafic udp_flood :26.890551578569884\n",
    "pourcentge du trafic dans un mauvais temps :41.47977649188935\n",
    "pourcentge du trafic vicitme d' brouillage :9.863747366451566\n",
    "\n",
    "pourcentge du trafic normal :52.16949819817537\n",
    "pourcentge du trafic udp_flood :23.12923048737943\n",
    "pourcentge du trafic dans un mauvais temps :14.837523947993631\n",
    "pourcentge du trafic vicitme d' brouillage :9.863747366451566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.000421818582\n",
      "487.2262257424459\n"
     ]
    }
   ],
   "source": [
    "#df2=df1[462481:-1].copy()\n",
    "minn=df2[0][1]\n",
    "maxx=df2[-1][1]\n",
    "print(minn)\n",
    "print(maxx)\n",
    "#print(len(df2))\n",
    "df3=df2.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.000421818582\n",
      "694.4520296663097\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(df3):\n",
    "    i[1][1]=i[1][1]-minn+maxx\n",
    "    i[1][2]=i[1][2]-minn+maxx\n",
    "    i[1][3]=i[1][3]-minn+maxx\n",
    "    \n",
    "df4=np.concatenate((df2,df3))\n",
    "minn=df4[0][1]\n",
    "maxx=df4[-1][1]\n",
    "print(minn)\n",
    "print(maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003650631698\n",
      "694.4520296663097\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=df1[0:462481].copy()\n",
    "df=np.concatenate((df,df2))\n",
    "minn=df[0][1]\n",
    "maxx=df[-1][1]\n",
    "print(minn)\n",
    "print(maxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns= col)\n",
    "\n",
    "df.to_csv ('src/cvs/datasets1/Dataset_03Final.csv', index=False , header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " My_module(\n",
      "  (fc1): Linear(in_features=11, out_features=28, bias=True)\n",
      "  (fc2): Linear(in_features=28, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=40, bias=True)\n",
      "  (fc4): Linear(in_features=40, out_features=56, bias=True)\n",
      "  (fc5): Linear(in_features=56, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias'])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1deeb4733dce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m torch.save({\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;34m'optimizer_state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n",
    "\n",
    "\n",
    "\n",
    "torch.save({\n",
    "            'epochs': epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'loss': loss\n",
    "            },  'models\\\\mod1.pth')\n",
    "\n",
    "\n",
    "#checkpoint = {'input_size': 11,\n",
    "#              'output_size': 4,\n",
    " #             'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "#              'state_dict': model.state_dict()}\n",
    "\n",
    "#torch.save(checkpoint, 'models\\\\mod1.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " My_module(\n",
      "  (fc1): Linear(in_features=11, out_features=28, bias=True)\n",
      "  (fc2): Linear(in_features=28, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=40, bias=True)\n",
      "  (fc4): Linear(in_features=40, out_features=56, bias=True)\n",
      "  (fc5): Linear(in_features=56, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ") \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "My_module(\n",
       "  (fc1): Linear(in_features=11, out_features=28, bias=True)\n",
       "  (fc2): Linear(in_features=28, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=40, bias=True)\n",
       "  (fc4): Linear(in_features=40, out_features=56, bias=True)\n",
       "  (fc5): Linear(in_features=56, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = My_module()\n",
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
    "\n",
    "Loaded = torch.load('models\\\\mod1.pth')\n",
    "model.load_state_dict(Loaded['model_state_dict'])\n",
    "optimizer.load_state_dict(Loaded['optimizer_state_dict'])\n",
    "epochs = Loaded['epochs']\n",
    "#loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy :97.25601196 with total prob : 96.81060028 and  test loss : -0.95929247 ,  time 0.334789 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-9b7f90a010eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.6f} '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpropabilities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mclear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;31m####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#print(inputs.shape[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clear' is not defined"
     ]
    }
   ],
   "source": [
    "#labels1=labels[loc]\n",
    "a=time.time()\n",
    "inputs=torch_tensor[:,:] \n",
    "labels1=labels[:]\n",
    "\n",
    "vinputs =vtorch_tensor[:,:] \n",
    "vlabels1=vlabels[:]\n",
    "\n",
    "epochs = 5\n",
    "test_loss=0\n",
    "accuracy=0\n",
    "\n",
    "####33  !!!!!!!!!! This shit cost alot of time ----> do not use it \n",
    "#b=time.time()\n",
    "#with torch.no_grad():\n",
    "   # for i, x in enumerate(vinputs):\n",
    "       # x2=x[None,:]\n",
    "       # output = torch.exp(model(x2))\n",
    "       # l2=vlabels1[i][None]\n",
    "       # test_loss+=Fonction_de_perte(output, l2)\n",
    "     #   output = torch.exp(output)\n",
    "      #  top_p , top_c = output.topk(1, dim=1)\n",
    "     #   equals = top_c==vlabels1[i].view(*top_c.shape)\n",
    "    #    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "   # tain_losses.append(running_loss/len(inputs))\n",
    "   # test_losses.append(test_loss/len(vinputs))\n",
    "   # print ('test accuracy :{0}, test loss : {2} ,  time {1} '.format(accuracy*100/len(vinputs) , time.time()-b ,test_loss/len(vinputs) ))\n",
    "\n",
    "######## ---> use this :) \n",
    "b=time.time()\n",
    "with torch.no_grad():\n",
    "    output = torch.exp(model(vinputs))\n",
    "    test_loss=Fonction_de_perte(output, vlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==vlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.6f} '.format(accuracy*100 , time.time()-b ,test_loss,propabilities))\n",
    "\n",
    "\n",
    "####\n",
    "#print(inputs.shape[0])\n",
    "tain_losses=[]\n",
    "test_losses=[]\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i, x in enumerate(inputs):\n",
    "        optimizer.zero_grad()\n",
    "        x2=x[None,:]\n",
    "        output = model.forward(x2)\n",
    "        l2=labels1[i][None]\n",
    "        #print(l2)\n",
    "        loss = Fonction_de_perte(output, l2)\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        #print(l2)\n",
    "        print(f\"Training loss: {running_loss/len(inputs)}\")\n",
    "   \n",
    "        b=time.time()\n",
    "        with torch.no_grad():\n",
    "            ##\n",
    "            #with torch.no_grad():\n",
    "            for i, x in enumerate(vinputs):\n",
    "                x2=x[None,:]\n",
    "                output = torch.exp(model(x2))\n",
    "                l2=vlabels1[i][None]\n",
    "                #test_loss+=Fonction_de_perte(output, l2)\n",
    "            #test_loss=test_loss/len(vinputs)\n",
    "            ##\n",
    "                \n",
    "            model.eval()\n",
    "            output = torch.exp(model(vinputs))\n",
    "            test_loss=Fonction_de_perte(output, vlabels1)\n",
    "        top_p , top_c = output.topk(1, dim=1)\n",
    "        propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "        equals = top_c==vlabels1.view(*top_c.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.8f} '.format(accuracy*100 , time.time()-b ,test_loss ,propabilities))\n",
    "            \n",
    "        tain_losses.append(running_loss/len(inputs))\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
